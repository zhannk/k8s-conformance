I0805 14:12:37.049560      18 e2e.go:129] Starting e2e run "f63a3d34-4434-4abc-b295-94ed0110f62c" on Ginkgo node 1
{"msg":"Test Suite starting","total":356,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1659708756 - Will randomize all specs
Will run 356 of 6971 specs

Aug  5 14:12:38.470: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:12:38.471: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug  5 14:12:38.483: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug  5 14:12:38.495: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug  5 14:12:38.495: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Aug  5 14:12:38.495: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug  5 14:12:38.498: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug  5 14:12:38.498: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-vultr-node' (0 seconds elapsed)
Aug  5 14:12:38.498: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
Aug  5 14:12:38.498: INFO: e2e test version: v1.24.3
Aug  5 14:12:38.499: INFO: kube-apiserver version: v1.24.3
Aug  5 14:12:38.499: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:12:38.503: INFO: Cluster IP family: ipv4
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:12:38.503: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
Aug  5 14:12:38.521: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
W0805 14:12:38.521072      18 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 14:12:38.529: INFO: Waiting up to 5m0s for pod "downwardapi-volume-588d6c1a-63cc-493e-ae1c-ca409c5ceca2" in namespace "downward-api-8139" to be "Succeeded or Failed"
Aug  5 14:12:38.531: INFO: Pod "downwardapi-volume-588d6c1a-63cc-493e-ae1c-ca409c5ceca2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.528509ms
Aug  5 14:12:40.537: INFO: Pod "downwardapi-volume-588d6c1a-63cc-493e-ae1c-ca409c5ceca2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007440878s
Aug  5 14:12:42.544: INFO: Pod "downwardapi-volume-588d6c1a-63cc-493e-ae1c-ca409c5ceca2": Phase="Running", Reason="", readiness=true. Elapsed: 4.014973268s
Aug  5 14:12:44.551: INFO: Pod "downwardapi-volume-588d6c1a-63cc-493e-ae1c-ca409c5ceca2": Phase="Running", Reason="", readiness=false. Elapsed: 6.021651956s
Aug  5 14:12:46.558: INFO: Pod "downwardapi-volume-588d6c1a-63cc-493e-ae1c-ca409c5ceca2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.028494931s
STEP: Saw pod success
Aug  5 14:12:46.558: INFO: Pod "downwardapi-volume-588d6c1a-63cc-493e-ae1c-ca409c5ceca2" satisfied condition "Succeeded or Failed"
Aug  5 14:12:46.560: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-588d6c1a-63cc-493e-ae1c-ca409c5ceca2 container client-container: <nil>
STEP: delete the pod
Aug  5 14:12:46.589: INFO: Waiting for pod downwardapi-volume-588d6c1a-63cc-493e-ae1c-ca409c5ceca2 to disappear
Aug  5 14:12:46.591: INFO: Pod downwardapi-volume-588d6c1a-63cc-493e-ae1c-ca409c5ceca2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 14:12:46.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8139" for this suite.

â€¢ [SLOW TEST:8.092 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":1,"skipped":10,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:12:46.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug  5 14:12:46.611: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  5 14:12:46.615: INFO: Waiting for terminating namespaces to be deleted...
Aug  5 14:12:46.616: INFO: 
Logging pods the apiserver thinks is on node vke-automated-test-82a4b3cb9b0e before test
Aug  5 14:12:46.620: INFO: calico-node-2jtxk from kube-system started at 2022-08-05 14:11:50 +0000 UTC (1 container statuses recorded)
Aug  5 14:12:46.620: INFO: 	Container calico-node ready: true, restart count 0
Aug  5 14:12:46.620: INFO: csi-vultr-node-kn67c from kube-system started at 2022-08-05 14:12:12 +0000 UTC (2 container statuses recorded)
Aug  5 14:12:46.620: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 14:12:46.620: INFO: 	Container driver-registrar ready: true, restart count 0
Aug  5 14:12:46.620: INFO: konnectivity-agent-z6dpf from kube-system started at 2022-08-05 14:12:12 +0000 UTC (1 container statuses recorded)
Aug  5 14:12:46.620: INFO: 	Container konnectivity-agent ready: true, restart count 0
Aug  5 14:12:46.620: INFO: sonobuoy from sonobuoy started at 2022-08-05 14:12:25 +0000 UTC (1 container statuses recorded)
Aug  5 14:12:46.620: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  5 14:12:46.620: INFO: sonobuoy-e2e-job-5437b3f59c524af6 from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 14:12:46.620: INFO: 	Container e2e ready: true, restart count 0
Aug  5 14:12:46.620: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 14:12:46.620: INFO: sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-vnb9h from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 14:12:46.620: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 14:12:46.620: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  5 14:12:46.620: INFO: 
Logging pods the apiserver thinks is on node vke-automated-test-b1f24d775249 before test
Aug  5 14:12:46.624: INFO: calico-kube-controllers-56cdb7c587-zstqt from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 14:12:46.624: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug  5 14:12:46.624: INFO: calico-node-bc7zg from kube-system started at 2022-08-05 14:11:50 +0000 UTC (1 container statuses recorded)
Aug  5 14:12:46.624: INFO: 	Container calico-node ready: true, restart count 0
Aug  5 14:12:46.624: INFO: cluster-autoscaler-595d485b76-4kzzf from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 14:12:46.624: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Aug  5 14:12:46.624: INFO: coredns-75c8969664-pdxjk from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 14:12:46.624: INFO: 	Container coredns ready: true, restart count 0
Aug  5 14:12:46.624: INFO: coredns-75c8969664-xvmdn from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 14:12:46.624: INFO: 	Container coredns ready: true, restart count 0
Aug  5 14:12:46.624: INFO: csi-vultr-controller-0 from kube-system started at 2022-08-05 14:12:02 +0000 UTC (3 container statuses recorded)
Aug  5 14:12:46.624: INFO: 	Container csi-attacher ready: true, restart count 0
Aug  5 14:12:46.624: INFO: 	Container csi-provisioner ready: true, restart count 0
Aug  5 14:12:46.624: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 14:12:46.624: INFO: csi-vultr-node-5xrgd from kube-system started at 2022-08-05 14:12:02 +0000 UTC (2 container statuses recorded)
Aug  5 14:12:46.624: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 14:12:46.624: INFO: 	Container driver-registrar ready: true, restart count 0
Aug  5 14:12:46.624: INFO: konnectivity-agent-c72gb from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 14:12:46.624: INFO: 	Container konnectivity-agent ready: true, restart count 0
Aug  5 14:12:46.624: INFO: sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-zqktm from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 14:12:46.624: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 14:12:46.624: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
STEP: verifying the node has the label node vke-automated-test-82a4b3cb9b0e
STEP: verifying the node has the label node vke-automated-test-b1f24d775249
Aug  5 14:12:46.648: INFO: Pod calico-kube-controllers-56cdb7c587-zstqt requesting resource cpu=0m on Node vke-automated-test-b1f24d775249
Aug  5 14:12:46.648: INFO: Pod calico-node-2jtxk requesting resource cpu=250m on Node vke-automated-test-82a4b3cb9b0e
Aug  5 14:12:46.648: INFO: Pod calico-node-bc7zg requesting resource cpu=250m on Node vke-automated-test-b1f24d775249
Aug  5 14:12:46.648: INFO: Pod cluster-autoscaler-595d485b76-4kzzf requesting resource cpu=100m on Node vke-automated-test-b1f24d775249
Aug  5 14:12:46.648: INFO: Pod coredns-75c8969664-pdxjk requesting resource cpu=100m on Node vke-automated-test-b1f24d775249
Aug  5 14:12:46.649: INFO: Pod coredns-75c8969664-xvmdn requesting resource cpu=100m on Node vke-automated-test-b1f24d775249
Aug  5 14:12:46.649: INFO: Pod csi-vultr-controller-0 requesting resource cpu=0m on Node vke-automated-test-b1f24d775249
Aug  5 14:12:46.649: INFO: Pod csi-vultr-node-5xrgd requesting resource cpu=0m on Node vke-automated-test-b1f24d775249
Aug  5 14:12:46.649: INFO: Pod csi-vultr-node-kn67c requesting resource cpu=0m on Node vke-automated-test-82a4b3cb9b0e
Aug  5 14:12:46.649: INFO: Pod konnectivity-agent-c72gb requesting resource cpu=0m on Node vke-automated-test-b1f24d775249
Aug  5 14:12:46.649: INFO: Pod konnectivity-agent-z6dpf requesting resource cpu=0m on Node vke-automated-test-82a4b3cb9b0e
Aug  5 14:12:46.649: INFO: Pod sonobuoy requesting resource cpu=0m on Node vke-automated-test-82a4b3cb9b0e
Aug  5 14:12:46.649: INFO: Pod sonobuoy-e2e-job-5437b3f59c524af6 requesting resource cpu=0m on Node vke-automated-test-82a4b3cb9b0e
Aug  5 14:12:46.650: INFO: Pod sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-vnb9h requesting resource cpu=0m on Node vke-automated-test-82a4b3cb9b0e
Aug  5 14:12:46.650: INFO: Pod sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-zqktm requesting resource cpu=0m on Node vke-automated-test-b1f24d775249
STEP: Starting Pods to consume most of the cluster CPU.
Aug  5 14:12:46.650: INFO: Creating a pod which consumes cpu=1085m on Node vke-automated-test-82a4b3cb9b0e
Aug  5 14:12:46.654: INFO: Creating a pod which consumes cpu=875m on Node vke-automated-test-b1f24d775249
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-75b65fd0-772f-484f-93ec-d6357b7515ba.17087854534224c7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4934/filler-pod-75b65fd0-772f-484f-93ec-d6357b7515ba to vke-automated-test-82a4b3cb9b0e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-75b65fd0-772f-484f-93ec-d6357b7515ba.170878548da80da2], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.7"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-75b65fd0-772f-484f-93ec-d6357b7515ba.17087854af70343f], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.7" in 566.751072ms]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-75b65fd0-772f-484f-93ec-d6357b7515ba.17087854b1ed75fc], Reason = [Created], Message = [Created container filler-pod-75b65fd0-772f-484f-93ec-d6357b7515ba]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-75b65fd0-772f-484f-93ec-d6357b7515ba.17087854b820c79c], Reason = [Started], Message = [Started container filler-pod-75b65fd0-772f-484f-93ec-d6357b7515ba]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c22e0ff1-56c4-486f-997a-cb57459543e4.17087854536cc1ba], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4934/filler-pod-c22e0ff1-56c4-486f-997a-cb57459543e4 to vke-automated-test-b1f24d775249]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c22e0ff1-56c4-486f-997a-cb57459543e4.17087854925baf9f], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.7"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c22e0ff1-56c4-486f-997a-cb57459543e4.17087854b89dd95c], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.7" in 641.856748ms]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c22e0ff1-56c4-486f-997a-cb57459543e4.17087854bb32874a], Reason = [Created], Message = [Created container filler-pod-c22e0ff1-56c4-486f-997a-cb57459543e4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c22e0ff1-56c4-486f-997a-cb57459543e4.17087854c0defd7a], Reason = [Started], Message = [Started container filler-pod-c22e0ff1-56c4-486f-997a-cb57459543e4]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1708785542d82153], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.]
STEP: removing the label node off the node vke-automated-test-82a4b3cb9b0e
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node vke-automated-test-b1f24d775249
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Aug  5 14:12:51.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4934" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83

â€¢ [SLOW TEST:5.103 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":356,"completed":2,"skipped":25,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:12:51.701: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 14:12:51.715: INFO: Waiting up to 5m0s for pod "downwardapi-volume-de17c37d-a57a-46b1-b979-6ae0415a8d2a" in namespace "downward-api-6260" to be "Succeeded or Failed"
Aug  5 14:12:51.716: INFO: Pod "downwardapi-volume-de17c37d-a57a-46b1-b979-6ae0415a8d2a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.384497ms
Aug  5 14:12:53.723: INFO: Pod "downwardapi-volume-de17c37d-a57a-46b1-b979-6ae0415a8d2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007819389s
Aug  5 14:12:55.729: INFO: Pod "downwardapi-volume-de17c37d-a57a-46b1-b979-6ae0415a8d2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014378436s
STEP: Saw pod success
Aug  5 14:12:55.729: INFO: Pod "downwardapi-volume-de17c37d-a57a-46b1-b979-6ae0415a8d2a" satisfied condition "Succeeded or Failed"
Aug  5 14:12:55.731: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-de17c37d-a57a-46b1-b979-6ae0415a8d2a container client-container: <nil>
STEP: delete the pod
Aug  5 14:12:55.744: INFO: Waiting for pod downwardapi-volume-de17c37d-a57a-46b1-b979-6ae0415a8d2a to disappear
Aug  5 14:12:55.747: INFO: Pod downwardapi-volume-de17c37d-a57a-46b1-b979-6ae0415a8d2a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 14:12:55.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6260" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":3,"skipped":43,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:12:55.765: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:12:55.778: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug  5 14:12:55.782: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug  5 14:13:00.787: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  5 14:13:00.787: INFO: Creating deployment "test-rolling-update-deployment"
Aug  5 14:13:00.789: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug  5 14:13:00.792: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug  5 14:13:02.801: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug  5 14:13:02.803: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug  5 14:13:02.810: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-6685  421f8ca9-b370-462b-9abe-1287a2388c9a 1140 1 2022-08-05 14:13:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2022-08-05 14:13:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:13:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a068c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-05 14:13:00 +0000 UTC,LastTransitionTime:2022-08-05 14:13:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-67c8f74c6c" has successfully progressed.,LastUpdateTime:2022-08-05 14:13:02 +0000 UTC,LastTransitionTime:2022-08-05 14:13:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug  5 14:13:02.812: INFO: New ReplicaSet "test-rolling-update-deployment-67c8f74c6c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-67c8f74c6c  deployment-6685  e2abdb31-e299-486d-b996-d8d08d9d32a0 1130 1 2022-08-05 14:13:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 421f8ca9-b370-462b-9abe-1287a2388c9a 0xc0039aa9e7 0xc0039aa9e8}] []  [{kube-controller-manager Update apps/v1 2022-08-05 14:13:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"421f8ca9-b370-462b-9abe-1287a2388c9a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:13:02 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67c8f74c6c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039aaa98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug  5 14:13:02.812: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug  5 14:13:02.812: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-6685  d59cd1ac-4847-4f01-a35d-62ebc4bfcca7 1139 2 2022-08-05 14:12:55 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 421f8ca9-b370-462b-9abe-1287a2388c9a 0xc0039aa8c7 0xc0039aa8c8}] []  [{e2e.test Update apps/v1 2022-08-05 14:12:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:13:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"421f8ca9-b370-462b-9abe-1287a2388c9a\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:13:02 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0039aa988 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug  5 14:13:02.815: INFO: Pod "test-rolling-update-deployment-67c8f74c6c-752vh" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-67c8f74c6c-752vh test-rolling-update-deployment-67c8f74c6c- deployment-6685  ccda3e59-a11c-4905-abec-1161b648ef84 1129 0 2022-08-05 14:13:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[cni.projectcalico.org/containerID:58ca0d95329d41b175a4e449a3b71c7471d5646175cb55f4025d13cd3126a404 cni.projectcalico.org/podIP:10.244.18.136/32 cni.projectcalico.org/podIPs:10.244.18.136/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-67c8f74c6c e2abdb31-e299-486d-b996-d8d08d9d32a0 0xc003a06c97 0xc003a06c98}] []  [{kube-controller-manager Update v1 2022-08-05 14:13:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e2abdb31-e299-486d-b996-d8d08d9d32a0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:13:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:13:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.18.136\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tvlks,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tvlks,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:13:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:13:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:13:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:13:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:10.244.18.136,StartTime:2022-08-05 14:13:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:13:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:containerd://78f71292a474018499ead2d4e1550c7e8abef760fdf3efeba52d25927a9d1188,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.18.136,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Aug  5 14:13:02.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6685" for this suite.

â€¢ [SLOW TEST:7.055 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":4,"skipped":55,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] HostPort 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:13:02.820: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename hostport
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
Aug  5 14:13:02.846: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:13:04.851: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:13:06.853: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.1.96.5 on the node which pod1 resides and expect scheduled
Aug  5 14:13:06.858: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:13:08.862: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.1.96.5 but use UDP protocol on the node which pod2 resides
Aug  5 14:13:08.867: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:13:10.872: INFO: The status of Pod pod3 is Running (Ready = false)
Aug  5 14:13:12.872: INFO: The status of Pod pod3 is Running (Ready = true)
Aug  5 14:13:12.876: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:13:14.883: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
Aug  5 14:13:14.884: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.1.96.5 http://127.0.0.1:54323/hostname] Namespace:hostport-8383 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:13:14.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:13:14.885: INFO: ExecWithOptions: Clientset creation
Aug  5 14:13:14.885: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8383/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.1.96.5+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.1.96.5, port: 54323
Aug  5 14:13:14.947: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.1.96.5:54323/hostname] Namespace:hostport-8383 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:13:14.947: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:13:14.947: INFO: ExecWithOptions: Clientset creation
Aug  5 14:13:14.947: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8383/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.1.96.5%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.1.96.5, port: 54323 UDP
Aug  5 14:13:15.014: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 10.1.96.5 54323] Namespace:hostport-8383 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:13:15.014: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:13:15.015: INFO: ExecWithOptions: Clientset creation
Aug  5 14:13:15.015: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8383/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=nc+-vuz+-w+5+10.1.96.5+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:188
Aug  5 14:13:20.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-8383" for this suite.

â€¢ [SLOW TEST:17.264 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":356,"completed":5,"skipped":66,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:13:20.085: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with configMap that has name projected-configmap-test-upd-8a0f9f94-0564-4132-b4b1-36eacc5abc58
STEP: Creating the pod
Aug  5 14:13:20.111: INFO: The status of Pod pod-projected-configmaps-122d63a9-1b34-4a31-ab31-985b50013214 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:13:22.118: INFO: The status of Pod pod-projected-configmaps-122d63a9-1b34-4a31-ab31-985b50013214 is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-8a0f9f94-0564-4132-b4b1-36eacc5abc58
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Aug  5 14:13:26.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3669" for this suite.

â€¢ [SLOW TEST:6.062 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":6,"skipped":91,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:13:26.148: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-eaf056ef-f3db-4750-9cf5-19e399cf208c
STEP: Creating a pod to test consume secrets
Aug  5 14:13:26.167: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-203c68e2-1102-46e9-b6da-fbae17b976bd" in namespace "projected-9612" to be "Succeeded or Failed"
Aug  5 14:13:26.169: INFO: Pod "pod-projected-secrets-203c68e2-1102-46e9-b6da-fbae17b976bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029496ms
Aug  5 14:13:28.183: INFO: Pod "pod-projected-secrets-203c68e2-1102-46e9-b6da-fbae17b976bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016634231s
Aug  5 14:13:30.188: INFO: Pod "pod-projected-secrets-203c68e2-1102-46e9-b6da-fbae17b976bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021502626s
STEP: Saw pod success
Aug  5 14:13:30.188: INFO: Pod "pod-projected-secrets-203c68e2-1102-46e9-b6da-fbae17b976bd" satisfied condition "Succeeded or Failed"
Aug  5 14:13:30.190: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-secrets-203c68e2-1102-46e9-b6da-fbae17b976bd container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  5 14:13:30.199: INFO: Waiting for pod pod-projected-secrets-203c68e2-1102-46e9-b6da-fbae17b976bd to disappear
Aug  5 14:13:30.200: INFO: Pod pod-projected-secrets-203c68e2-1102-46e9-b6da-fbae17b976bd no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Aug  5 14:13:30.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9612" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":7,"skipped":92,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:13:30.206: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
Aug  5 14:13:34.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8153" for this suite.
â€¢{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":8,"skipped":110,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:13:34.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Aug  5 14:13:34.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:13:36.204: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:13:44.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2641" for this suite.

â€¢ [SLOW TEST:10.337 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":356,"completed":9,"skipped":111,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:13:44.582: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
Aug  5 14:13:44.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1188" for this suite.
â€¢{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":10,"skipped":122,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:13:44.622: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug  5 14:13:44.634: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Aug  5 14:13:49.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3319" for this suite.

â€¢ [SLOW TEST:5.200 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":356,"completed":11,"skipped":136,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:13:49.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
Aug  5 14:13:51.847: INFO: pods: 0 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Aug  5 14:13:57.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5563" for this suite.

â€¢ [SLOW TEST:8.106 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":356,"completed":12,"skipped":150,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:13:57.930: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug  5 14:13:57.950: INFO: Waiting up to 5m0s for pod "pod-afe36828-2bf1-419a-a452-34b8fd0401e8" in namespace "emptydir-8036" to be "Succeeded or Failed"
Aug  5 14:13:57.951: INFO: Pod "pod-afe36828-2bf1-419a-a452-34b8fd0401e8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.319083ms
Aug  5 14:13:59.954: INFO: Pod "pod-afe36828-2bf1-419a-a452-34b8fd0401e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004063861s
Aug  5 14:14:01.956: INFO: Pod "pod-afe36828-2bf1-419a-a452-34b8fd0401e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005949055s
STEP: Saw pod success
Aug  5 14:14:01.956: INFO: Pod "pod-afe36828-2bf1-419a-a452-34b8fd0401e8" satisfied condition "Succeeded or Failed"
Aug  5 14:14:01.959: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-afe36828-2bf1-419a-a452-34b8fd0401e8 container test-container: <nil>
STEP: delete the pod
Aug  5 14:14:01.977: INFO: Waiting for pod pod-afe36828-2bf1-419a-a452-34b8fd0401e8 to disappear
Aug  5 14:14:01.979: INFO: Pod pod-afe36828-2bf1-419a-a452-34b8fd0401e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 14:14:01.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8036" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":13,"skipped":154,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:14:01.984: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Aug  5 14:14:18.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9268" for this suite.

â€¢ [SLOW TEST:16.052 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":356,"completed":14,"skipped":157,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:14:18.036: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Deleting RuntimeClass runtimeclass-7394-delete-me
STEP: Waiting for the RuntimeClass to disappear
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Aug  5 14:14:18.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7394" for this suite.
â€¢{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":15,"skipped":194,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:14:18.070: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service multi-endpoint-test in namespace services-6836
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6836 to expose endpoints map[]
Aug  5 14:14:18.089: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Aug  5 14:14:19.096: INFO: successfully validated that service multi-endpoint-test in namespace services-6836 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-6836
Aug  5 14:14:19.102: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:14:21.107: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6836 to expose endpoints map[pod1:[100]]
Aug  5 14:14:21.115: INFO: successfully validated that service multi-endpoint-test in namespace services-6836 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-6836
Aug  5 14:14:21.121: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:14:23.124: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6836 to expose endpoints map[pod1:[100] pod2:[101]]
Aug  5 14:14:23.132: INFO: successfully validated that service multi-endpoint-test in namespace services-6836 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
Aug  5 14:14:23.132: INFO: Creating new exec pod
Aug  5 14:14:26.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6836 exec execpodjt8rv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Aug  5 14:14:26.297: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Aug  5 14:14:26.297: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 14:14:26.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6836 exec execpodjt8rv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.11.108 80'
Aug  5 14:14:26.408: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.11.108 80\nConnection to 10.100.11.108 80 port [tcp/http] succeeded!\n"
Aug  5 14:14:26.408: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 14:14:26.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6836 exec execpodjt8rv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Aug  5 14:14:26.526: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Aug  5 14:14:26.526: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 14:14:26.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6836 exec execpodjt8rv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.11.108 81'
Aug  5 14:14:26.639: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.11.108 81\nConnection to 10.100.11.108 81 port [tcp/*] succeeded!\n"
Aug  5 14:14:26.639: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-6836
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6836 to expose endpoints map[pod2:[101]]
Aug  5 14:14:28.657: INFO: successfully validated that service multi-endpoint-test in namespace services-6836 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-6836
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6836 to expose endpoints map[]
Aug  5 14:14:28.665: INFO: successfully validated that service multi-endpoint-test in namespace services-6836 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 14:14:28.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6836" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:10.607 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":356,"completed":16,"skipped":237,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:14:28.678: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-d8761c66-b155-447d-a1ed-c8e39e1788eb
STEP: Creating a pod to test consume secrets
Aug  5 14:14:28.701: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6889691e-a4fd-47a3-afc6-b5681fdb85e6" in namespace "projected-45" to be "Succeeded or Failed"
Aug  5 14:14:28.703: INFO: Pod "pod-projected-secrets-6889691e-a4fd-47a3-afc6-b5681fdb85e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.260284ms
Aug  5 14:14:30.708: INFO: Pod "pod-projected-secrets-6889691e-a4fd-47a3-afc6-b5681fdb85e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007356109s
Aug  5 14:14:32.714: INFO: Pod "pod-projected-secrets-6889691e-a4fd-47a3-afc6-b5681fdb85e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012798947s
STEP: Saw pod success
Aug  5 14:14:32.714: INFO: Pod "pod-projected-secrets-6889691e-a4fd-47a3-afc6-b5681fdb85e6" satisfied condition "Succeeded or Failed"
Aug  5 14:14:32.715: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-secrets-6889691e-a4fd-47a3-afc6-b5681fdb85e6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  5 14:14:32.730: INFO: Waiting for pod pod-projected-secrets-6889691e-a4fd-47a3-afc6-b5681fdb85e6 to disappear
Aug  5 14:14:32.732: INFO: Pod pod-projected-secrets-6889691e-a4fd-47a3-afc6-b5681fdb85e6 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Aug  5 14:14:32.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-45" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":17,"skipped":248,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:14:32.736: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-projected-sf2x
STEP: Creating a pod to test atomic-volume-subpath
Aug  5 14:14:32.756: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-sf2x" in namespace "subpath-7302" to be "Succeeded or Failed"
Aug  5 14:14:32.757: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Pending", Reason="", readiness=false. Elapsed: 1.403061ms
Aug  5 14:14:34.765: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=true. Elapsed: 2.009412899s
Aug  5 14:14:36.771: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=true. Elapsed: 4.015386374s
Aug  5 14:14:38.776: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=true. Elapsed: 6.020010917s
Aug  5 14:14:40.781: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=true. Elapsed: 8.024879601s
Aug  5 14:14:42.787: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=true. Elapsed: 10.030522994s
Aug  5 14:14:44.791: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=true. Elapsed: 12.03487209s
Aug  5 14:14:46.797: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=true. Elapsed: 14.040987735s
Aug  5 14:14:48.803: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=true. Elapsed: 16.046518368s
Aug  5 14:14:50.807: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=true. Elapsed: 18.050855173s
Aug  5 14:14:53.222: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=true. Elapsed: 20.057580453s
Aug  5 14:14:55.229: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Running", Reason="", readiness=false. Elapsed: 22.064226711s
Aug  5 14:14:57.236: INFO: Pod "pod-subpath-test-projected-sf2x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.071129858s
STEP: Saw pod success
Aug  5 14:14:57.236: INFO: Pod "pod-subpath-test-projected-sf2x" satisfied condition "Succeeded or Failed"
Aug  5 14:14:57.237: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-subpath-test-projected-sf2x container test-container-subpath-projected-sf2x: <nil>
STEP: delete the pod
Aug  5 14:14:57.247: INFO: Waiting for pod pod-subpath-test-projected-sf2x to disappear
Aug  5 14:14:57.248: INFO: Pod pod-subpath-test-projected-sf2x no longer exists
STEP: Deleting pod pod-subpath-test-projected-sf2x
Aug  5 14:14:57.248: INFO: Deleting pod "pod-subpath-test-projected-sf2x" in namespace "subpath-7302"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Aug  5 14:14:57.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7302" for this suite.

â€¢ [SLOW TEST:24.110 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","total":356,"completed":18,"skipped":269,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:14:57.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:14:57.266: INFO: Creating pod...
Aug  5 14:14:59.276: INFO: Creating service...
Aug  5 14:14:59.280: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/pods/agnhost/proxy?method=DELETE
Aug  5 14:14:59.285: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug  5 14:14:59.285: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/pods/agnhost/proxy?method=OPTIONS
Aug  5 14:14:59.287: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug  5 14:14:59.287: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/pods/agnhost/proxy?method=PATCH
Aug  5 14:14:59.289: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug  5 14:14:59.289: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/pods/agnhost/proxy?method=POST
Aug  5 14:14:59.292: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug  5 14:14:59.292: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/pods/agnhost/proxy?method=PUT
Aug  5 14:14:59.294: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug  5 14:14:59.294: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/services/e2e-proxy-test-service/proxy?method=DELETE
Aug  5 14:14:59.296: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug  5 14:14:59.296: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/services/e2e-proxy-test-service/proxy?method=OPTIONS
Aug  5 14:14:59.299: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug  5 14:14:59.299: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/services/e2e-proxy-test-service/proxy?method=PATCH
Aug  5 14:14:59.302: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug  5 14:14:59.302: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/services/e2e-proxy-test-service/proxy?method=POST
Aug  5 14:14:59.305: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug  5 14:14:59.305: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/services/e2e-proxy-test-service/proxy?method=PUT
Aug  5 14:14:59.307: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug  5 14:14:59.307: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/pods/agnhost/proxy?method=GET
Aug  5 14:14:59.309: INFO: http.Client request:GET StatusCode:301
Aug  5 14:14:59.309: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/services/e2e-proxy-test-service/proxy?method=GET
Aug  5 14:14:59.311: INFO: http.Client request:GET StatusCode:301
Aug  5 14:14:59.311: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/pods/agnhost/proxy?method=HEAD
Aug  5 14:14:59.312: INFO: http.Client request:HEAD StatusCode:301
Aug  5 14:14:59.312: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6111/services/e2e-proxy-test-service/proxy?method=HEAD
Aug  5 14:14:59.314: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Aug  5 14:14:59.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6111" for this suite.
â€¢{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","total":356,"completed":19,"skipped":296,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:14:59.320: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:14:59.618: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:15:02.631: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:15:02.636: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5774-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:15:05.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9693" for this suite.
STEP: Destroying namespace "webhook-9693-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

â€¢ [SLOW TEST:6.430 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":356,"completed":20,"skipped":317,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:15:05.751: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-b1ebfedf-9a7a-4c3a-a209-160d77cc0f8d
STEP: Creating a pod to test consume secrets
Aug  5 14:15:05.793: INFO: Waiting up to 5m0s for pod "pod-secrets-fc52c252-fdf4-49a6-b430-4f234e9ccd9e" in namespace "secrets-6012" to be "Succeeded or Failed"
Aug  5 14:15:05.802: INFO: Pod "pod-secrets-fc52c252-fdf4-49a6-b430-4f234e9ccd9e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.175074ms
Aug  5 14:15:07.809: INFO: Pod "pod-secrets-fc52c252-fdf4-49a6-b430-4f234e9ccd9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015352141s
Aug  5 14:15:09.817: INFO: Pod "pod-secrets-fc52c252-fdf4-49a6-b430-4f234e9ccd9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023567655s
STEP: Saw pod success
Aug  5 14:15:09.817: INFO: Pod "pod-secrets-fc52c252-fdf4-49a6-b430-4f234e9ccd9e" satisfied condition "Succeeded or Failed"
Aug  5 14:15:09.823: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-secrets-fc52c252-fdf4-49a6-b430-4f234e9ccd9e container secret-volume-test: <nil>
STEP: delete the pod
Aug  5 14:15:09.831: INFO: Waiting for pod pod-secrets-fc52c252-fdf4-49a6-b430-4f234e9ccd9e to disappear
Aug  5 14:15:09.835: INFO: Pod pod-secrets-fc52c252-fdf4-49a6-b430-4f234e9ccd9e no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:15:09.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6012" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":21,"skipped":373,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:15:09.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  5 14:15:09.866: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:15:09.866: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:15:10.873: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:15:10.873: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:15:11.875: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:15:11.875: INFO: Node vke-automated-test-b1f24d775249 is running 0 daemon pod, expected 1
Aug  5 14:15:12.871: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:15:12.871: INFO: Node vke-automated-test-b1f24d775249 is running 0 daemon pod, expected 1
Aug  5 14:15:13.874: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:15:13.874: INFO: Node vke-automated-test-b1f24d775249 is running 0 daemon pod, expected 1
Aug  5 14:15:14.872: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug  5 14:15:14.872: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: listing all DeamonSets
STEP: DeleteCollection of the DaemonSets
STEP: Verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Aug  5 14:15:14.892: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2302"},"items":null}

Aug  5 14:15:14.905: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2304"},"items":[{"metadata":{"name":"daemon-set-b6bmw","generateName":"daemon-set-","namespace":"daemonsets-4471","uid":"bb32be97-e40f-44d0-bb08-ec60d6b2b0d2","resourceVersion":"2302","creationTimestamp":"2022-08-05T14:15:09Z","deletionTimestamp":"2022-08-05T14:15:44Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"d2fc1e615c75c59a0d4a63af947858c0488a0e101c3ae75f62e937701467c3fb","cni.projectcalico.org/podIP":"10.244.18.152/32","cni.projectcalico.org/podIPs":"10.244.18.152/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"ccc63a19-c105-4929-89f7-e36200eaf056","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-05T14:15:09Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ccc63a19-c105-4929-89f7-e36200eaf056\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-08-05T14:15:10Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-05T14:15:11Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.18.152\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-kkkzl","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-kkkzl","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"vke-automated-test-82a4b3cb9b0e","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["vke-automated-test-82a4b3cb9b0e"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-05T14:15:09Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-05T14:15:11Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-05T14:15:11Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-05T14:15:09Z"}],"hostIP":"10.1.96.4","podIP":"10.244.18.152","podIPs":[{"ip":"10.244.18.152"}],"startTime":"2022-08-05T14:15:09Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-05T14:15:10Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://4f5612737daa7c5a5dfb833aa254dfbccaf6118fd2305f513b9d035f2acd51cf","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-s5hqj","generateName":"daemon-set-","namespace":"daemonsets-4471","uid":"563daa2e-6e81-4bf7-868b-9dff8402f937","resourceVersion":"2301","creationTimestamp":"2022-08-05T14:15:09Z","deletionTimestamp":"2022-08-05T14:15:44Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"857a595642d7213747f1dcc9da709931a96fdc918404676f07f0d1d98f696284","cni.projectcalico.org/podIP":"10.244.107.141/32","cni.projectcalico.org/podIPs":"10.244.107.141/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"ccc63a19-c105-4929-89f7-e36200eaf056","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-05T14:15:09Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ccc63a19-c105-4929-89f7-e36200eaf056\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-08-05T14:15:10Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-05T14:15:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.107.141\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-82rxm","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-82rxm","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"vke-automated-test-b1f24d775249","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["vke-automated-test-b1f24d775249"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-05T14:15:09Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-05T14:15:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-05T14:15:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-05T14:15:09Z"}],"hostIP":"10.1.96.5","podIP":"10.244.107.141","podIPs":[{"ip":"10.244.107.141"}],"startTime":"2022-08-05T14:15:09Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-05T14:15:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://ed0587d9a779a9f65e5c0d788369aa44dfb6a9c9c2349bb74510f9d066e79c17","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Aug  5 14:15:14.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4471" for this suite.

â€¢ [SLOW TEST:5.074 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","total":356,"completed":22,"skipped":386,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:15:14.914: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1334
STEP: creating the pod
Aug  5 14:15:14.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8335 create -f -'
Aug  5 14:15:15.587: INFO: stderr: ""
Aug  5 14:15:15.587: INFO: stdout: "pod/pause created\n"
Aug  5 14:15:15.587: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug  5 14:15:15.587: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8335" to be "running and ready"
Aug  5 14:15:15.590: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.626579ms
Aug  5 14:15:17.596: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.008892637s
Aug  5 14:15:17.596: INFO: Pod "pause" satisfied condition "running and ready"
Aug  5 14:15:17.596: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
STEP: adding the label testing-label with value testing-label-value to a pod
Aug  5 14:15:17.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8335 label pods pause testing-label=testing-label-value'
Aug  5 14:15:17.658: INFO: stderr: ""
Aug  5 14:15:17.658: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug  5 14:15:17.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8335 get pod pause -L testing-label'
Aug  5 14:15:17.702: INFO: stderr: ""
Aug  5 14:15:17.702: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug  5 14:15:17.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8335 label pods pause testing-label-'
Aug  5 14:15:17.751: INFO: stderr: ""
Aug  5 14:15:17.751: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug  5 14:15:17.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8335 get pod pause -L testing-label'
Aug  5 14:15:17.797: INFO: stderr: ""
Aug  5 14:15:17.797: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1340
STEP: using delete to clean up resources
Aug  5 14:15:17.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8335 delete --grace-period=0 --force -f -'
Aug  5 14:15:17.844: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  5 14:15:17.844: INFO: stdout: "pod \"pause\" force deleted\n"
Aug  5 14:15:17.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8335 get rc,svc -l name=pause --no-headers'
Aug  5 14:15:17.926: INFO: stderr: "No resources found in kubectl-8335 namespace.\n"
Aug  5 14:15:17.926: INFO: stdout: ""
Aug  5 14:15:17.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8335 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  5 14:15:17.970: INFO: stderr: ""
Aug  5 14:15:17.970: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:15:17.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8335" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":356,"completed":23,"skipped":394,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:15:17.975: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Aug  5 14:15:28.022: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0805 14:15:28.022882      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Aug  5 14:15:28.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7685" for this suite.

â€¢ [SLOW TEST:10.052 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":356,"completed":24,"skipped":425,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:15:28.031: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:15:28.053: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-5a892e20-1c15-4c3f-96b2-264ff6c532f4" in namespace "security-context-test-4857" to be "Succeeded or Failed"
Aug  5 14:15:28.055: INFO: Pod "busybox-privileged-false-5a892e20-1c15-4c3f-96b2-264ff6c532f4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.469616ms
Aug  5 14:15:30.061: INFO: Pod "busybox-privileged-false-5a892e20-1c15-4c3f-96b2-264ff6c532f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008124242s
Aug  5 14:15:32.065: INFO: Pod "busybox-privileged-false-5a892e20-1c15-4c3f-96b2-264ff6c532f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01165466s
Aug  5 14:15:32.065: INFO: Pod "busybox-privileged-false-5a892e20-1c15-4c3f-96b2-264ff6c532f4" satisfied condition "Succeeded or Failed"
Aug  5 14:15:32.070: INFO: Got logs for pod "busybox-privileged-false-5a892e20-1c15-4c3f-96b2-264ff6c532f4": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Aug  5 14:15:32.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4857" for this suite.
â€¢{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":25,"skipped":450,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:15:32.075: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-flk6
STEP: Creating a pod to test atomic-volume-subpath
Aug  5 14:15:32.094: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-flk6" in namespace "subpath-6556" to be "Succeeded or Failed"
Aug  5 14:15:32.096: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.590923ms
Aug  5 14:15:34.102: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=true. Elapsed: 2.00729344s
Aug  5 14:15:36.108: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=true. Elapsed: 4.013233639s
Aug  5 14:15:38.112: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=true. Elapsed: 6.01726567s
Aug  5 14:15:40.117: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=true. Elapsed: 8.022947698s
Aug  5 14:15:42.124: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=true. Elapsed: 10.029814051s
Aug  5 14:15:44.132: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=true. Elapsed: 12.037246588s
Aug  5 14:15:46.139: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=true. Elapsed: 14.044523902s
Aug  5 14:15:48.143: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=true. Elapsed: 16.048685698s
Aug  5 14:15:50.150: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=true. Elapsed: 18.055475674s
Aug  5 14:15:52.157: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=true. Elapsed: 20.062378173s
Aug  5 14:15:54.163: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Running", Reason="", readiness=false. Elapsed: 22.068995326s
Aug  5 14:15:56.170: INFO: Pod "pod-subpath-test-configmap-flk6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.075858479s
STEP: Saw pod success
Aug  5 14:15:56.170: INFO: Pod "pod-subpath-test-configmap-flk6" satisfied condition "Succeeded or Failed"
Aug  5 14:15:56.172: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-subpath-test-configmap-flk6 container test-container-subpath-configmap-flk6: <nil>
STEP: delete the pod
Aug  5 14:15:56.184: INFO: Waiting for pod pod-subpath-test-configmap-flk6 to disappear
Aug  5 14:15:56.187: INFO: Pod pod-subpath-test-configmap-flk6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-flk6
Aug  5 14:15:56.187: INFO: Deleting pod "pod-subpath-test-configmap-flk6" in namespace "subpath-6556"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Aug  5 14:15:56.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6556" for this suite.

â€¢ [SLOW TEST:24.118 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","total":356,"completed":26,"skipped":491,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:15:56.196: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Aug  5 14:15:56.216: INFO: Waiting up to 5m0s for pod "downward-api-05564c76-f1b1-4056-bbf7-39509e15d794" in namespace "downward-api-2355" to be "Succeeded or Failed"
Aug  5 14:15:56.217: INFO: Pod "downward-api-05564c76-f1b1-4056-bbf7-39509e15d794": Phase="Pending", Reason="", readiness=false. Elapsed: 1.792808ms
Aug  5 14:15:58.221: INFO: Pod "downward-api-05564c76-f1b1-4056-bbf7-39509e15d794": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005137127s
Aug  5 14:16:00.227: INFO: Pod "downward-api-05564c76-f1b1-4056-bbf7-39509e15d794": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010995331s
STEP: Saw pod success
Aug  5 14:16:00.227: INFO: Pod "downward-api-05564c76-f1b1-4056-bbf7-39509e15d794" satisfied condition "Succeeded or Failed"
Aug  5 14:16:00.228: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downward-api-05564c76-f1b1-4056-bbf7-39509e15d794 container dapi-container: <nil>
STEP: delete the pod
Aug  5 14:16:00.239: INFO: Waiting for pod downward-api-05564c76-f1b1-4056-bbf7-39509e15d794 to disappear
Aug  5 14:16:00.241: INFO: Pod downward-api-05564c76-f1b1-4056-bbf7-39509e15d794 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Aug  5 14:16:00.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2355" for this suite.
â€¢{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":356,"completed":27,"skipped":507,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:16:00.246: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8757
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8757
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8757
Aug  5 14:16:00.267: INFO: Found 0 stateful pods, waiting for 1
Aug  5 14:16:10.274: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug  5 14:16:10.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-8757 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug  5 14:16:10.403: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug  5 14:16:10.403: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug  5 14:16:10.403: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug  5 14:16:10.406: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug  5 14:16:20.410: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  5 14:16:20.410: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:16:20.418: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999781s
Aug  5 14:16:21.423: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997464138s
Aug  5 14:16:22.428: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993100358s
Aug  5 14:16:23.431: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988363128s
Aug  5 14:16:24.436: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.984636934s
Aug  5 14:16:25.441: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.979748697s
Aug  5 14:16:26.445: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.975319048s
Aug  5 14:16:27.450: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.970239718s
Aug  5 14:16:28.454: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.965023613s
Aug  5 14:16:29.460: INFO: Verifying statefulset ss doesn't scale past 1 for another 961.597793ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8757
Aug  5 14:16:30.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-8757 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug  5 14:16:30.577: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug  5 14:16:30.577: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug  5 14:16:30.577: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug  5 14:16:30.580: INFO: Found 1 stateful pods, waiting for 3
Aug  5 14:16:40.588: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:16:40.588: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:16:40.588: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug  5 14:16:40.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-8757 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug  5 14:16:40.700: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug  5 14:16:40.700: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug  5 14:16:40.700: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug  5 14:16:40.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-8757 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug  5 14:16:40.834: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug  5 14:16:40.834: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug  5 14:16:40.834: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug  5 14:16:40.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-8757 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug  5 14:16:40.933: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug  5 14:16:40.933: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug  5 14:16:40.933: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug  5 14:16:40.934: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:16:40.936: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug  5 14:16:50.942: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  5 14:16:50.942: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug  5 14:16:50.942: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug  5 14:16:50.951: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999801s
Aug  5 14:16:51.956: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998045218s
Aug  5 14:16:52.961: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992584515s
Aug  5 14:16:53.966: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987685222s
Aug  5 14:16:54.971: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983065532s
Aug  5 14:16:55.976: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978068171s
Aug  5 14:16:56.981: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972829489s
Aug  5 14:16:57.986: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968156646s
Aug  5 14:16:58.990: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963458549s
Aug  5 14:16:59.994: INFO: Verifying statefulset ss doesn't scale past 3 for another 958.969891ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8757
Aug  5 14:17:00.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-8757 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug  5 14:17:01.116: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug  5 14:17:01.116: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug  5 14:17:01.116: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug  5 14:17:01.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-8757 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug  5 14:17:01.242: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug  5 14:17:01.242: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug  5 14:17:01.242: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug  5 14:17:01.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-8757 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug  5 14:17:01.350: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug  5 14:17:01.350: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug  5 14:17:01.350: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug  5 14:17:01.350: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug  5 14:17:11.366: INFO: Deleting all statefulset in ns statefulset-8757
Aug  5 14:17:11.368: INFO: Scaling statefulset ss to 0
Aug  5 14:17:11.373: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:17:11.375: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Aug  5 14:17:11.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8757" for this suite.

â€¢ [SLOW TEST:71.139 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":356,"completed":28,"skipped":516,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:17:11.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-650
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating stateful set ss in namespace statefulset-650
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-650
Aug  5 14:17:11.412: INFO: Found 0 stateful pods, waiting for 1
Aug  5 14:17:21.417: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug  5 14:17:21.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-650 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug  5 14:17:21.618: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug  5 14:17:21.618: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug  5 14:17:21.618: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug  5 14:17:21.620: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug  5 14:17:31.625: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  5 14:17:31.626: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:17:31.634: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Aug  5 14:17:31.634: INFO: ss-0  vke-automated-test-82a4b3cb9b0e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:11 +0000 UTC  }]
Aug  5 14:17:31.634: INFO: 
Aug  5 14:17:31.634: INFO: StatefulSet ss has not reached scale 3, at 1
Aug  5 14:17:32.640: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997414276s
Aug  5 14:17:33.644: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992254383s
Aug  5 14:17:34.647: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987789111s
Aug  5 14:17:35.652: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984713966s
Aug  5 14:17:36.657: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.97990641s
Aug  5 14:17:37.662: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97421489s
Aug  5 14:17:38.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.969675646s
Aug  5 14:17:39.671: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.965476813s
Aug  5 14:17:40.673: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.821053ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-650
Aug  5 14:17:41.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-650 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug  5 14:17:41.785: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug  5 14:17:41.785: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug  5 14:17:41.785: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug  5 14:17:41.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-650 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug  5 14:17:41.917: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug  5 14:17:41.917: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug  5 14:17:41.917: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug  5 14:17:41.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-650 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug  5 14:17:42.015: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug  5 14:17:42.015: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug  5 14:17:42.015: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug  5 14:17:42.018: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug  5 14:17:52.027: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:17:52.027: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:17:52.027: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug  5 14:17:52.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-650 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug  5 14:17:52.138: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug  5 14:17:52.138: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug  5 14:17:52.138: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug  5 14:17:52.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-650 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug  5 14:17:52.242: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug  5 14:17:52.242: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug  5 14:17:52.242: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug  5 14:17:52.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-650 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug  5 14:17:52.350: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug  5 14:17:52.350: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug  5 14:17:52.350: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug  5 14:17:52.350: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:17:52.352: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Aug  5 14:18:02.363: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  5 14:18:02.363: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug  5 14:18:02.363: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug  5 14:18:02.371: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Aug  5 14:18:02.371: INFO: ss-0  vke-automated-test-82a4b3cb9b0e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:11 +0000 UTC  }]
Aug  5 14:18:02.371: INFO: ss-1  vke-automated-test-b1f24d775249  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:31 +0000 UTC  }]
Aug  5 14:18:02.371: INFO: ss-2  vke-automated-test-82a4b3cb9b0e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:31 +0000 UTC  }]
Aug  5 14:18:02.371: INFO: 
Aug  5 14:18:02.371: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  5 14:18:03.376: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Aug  5 14:18:03.376: INFO: ss-0  vke-automated-test-82a4b3cb9b0e  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:11 +0000 UTC  }]
Aug  5 14:18:03.376: INFO: ss-2  vke-automated-test-82a4b3cb9b0e  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 14:17:31 +0000 UTC  }]
Aug  5 14:18:03.376: INFO: 
Aug  5 14:18:03.376: INFO: StatefulSet ss has not reached scale 0, at 2
Aug  5 14:18:04.379: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.99258439s
Aug  5 14:18:05.384: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.98804901s
Aug  5 14:18:06.389: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.983822228s
Aug  5 14:18:07.393: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.979302113s
Aug  5 14:18:08.397: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.974911899s
Aug  5 14:18:09.401: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.971407534s
Aug  5 14:18:10.406: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.966958325s
Aug  5 14:18:11.409: INFO: Verifying statefulset ss doesn't scale past 0 for another 962.591768ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-650
Aug  5 14:18:12.414: INFO: Scaling statefulset ss to 0
Aug  5 14:18:12.421: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug  5 14:18:12.423: INFO: Deleting all statefulset in ns statefulset-650
Aug  5 14:18:12.424: INFO: Scaling statefulset ss to 0
Aug  5 14:18:12.429: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:18:12.430: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Aug  5 14:18:12.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-650" for this suite.

â€¢ [SLOW TEST:61.056 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":356,"completed":29,"skipped":556,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:18:12.442: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Service
STEP: watching for the Service to be added
Aug  5 14:18:12.461: INFO: Found Service test-service-zrqq2 in namespace services-1347 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Aug  5 14:18:12.461: INFO: Service test-service-zrqq2 created
STEP: Getting /status
Aug  5 14:18:12.463: INFO: Service test-service-zrqq2 has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
Aug  5 14:18:12.468: INFO: observed Service test-service-zrqq2 in namespace services-1347 with annotations: map[] & LoadBalancer: {[]}
Aug  5 14:18:12.468: INFO: Found Service test-service-zrqq2 in namespace services-1347 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Aug  5 14:18:12.468: INFO: Service test-service-zrqq2 has service status patched
STEP: updating the ServiceStatus
Aug  5 14:18:12.472: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
Aug  5 14:18:12.473: INFO: Observed Service test-service-zrqq2 in namespace services-1347 with annotations: map[] & Conditions: {[]}
Aug  5 14:18:12.473: INFO: Observed event: &Service{ObjectMeta:{test-service-zrqq2  services-1347  751f7a9e-e659-4c26-ab24-d4bbe0163c2b 3391 0 2022-08-05 14:18:12 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-08-05 14:18:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-08-05 14:18:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.101.13.125,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.101.13.125],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Aug  5 14:18:12.473: INFO: Found Service test-service-zrqq2 in namespace services-1347 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug  5 14:18:12.473: INFO: Service test-service-zrqq2 has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
Aug  5 14:18:12.483: INFO: observed Service test-service-zrqq2 in namespace services-1347 with labels: map[test-service-static:true]
Aug  5 14:18:12.483: INFO: observed Service test-service-zrqq2 in namespace services-1347 with labels: map[test-service-static:true]
Aug  5 14:18:12.483: INFO: observed Service test-service-zrqq2 in namespace services-1347 with labels: map[test-service-static:true]
Aug  5 14:18:12.483: INFO: Found Service test-service-zrqq2 in namespace services-1347 with labels: map[test-service:patched test-service-static:true]
Aug  5 14:18:12.483: INFO: Service test-service-zrqq2 patched
STEP: deleting the service
STEP: watching for the Service to be deleted
Aug  5 14:18:12.489: INFO: Observed event: ADDED
Aug  5 14:18:12.489: INFO: Observed event: MODIFIED
Aug  5 14:18:12.489: INFO: Observed event: MODIFIED
Aug  5 14:18:12.489: INFO: Observed event: MODIFIED
Aug  5 14:18:12.489: INFO: Found Service test-service-zrqq2 in namespace services-1347 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Aug  5 14:18:12.489: INFO: Service test-service-zrqq2 deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 14:18:12.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1347" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
â€¢{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":356,"completed":30,"skipped":567,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:18:12.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 14:18:12.513: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ded149b-c940-49bc-80e7-3b5f0120c015" in namespace "projected-4587" to be "Succeeded or Failed"
Aug  5 14:18:12.514: INFO: Pod "downwardapi-volume-9ded149b-c940-49bc-80e7-3b5f0120c015": Phase="Pending", Reason="", readiness=false. Elapsed: 1.413786ms
Aug  5 14:18:14.520: INFO: Pod "downwardapi-volume-9ded149b-c940-49bc-80e7-3b5f0120c015": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007276519s
Aug  5 14:18:16.526: INFO: Pod "downwardapi-volume-9ded149b-c940-49bc-80e7-3b5f0120c015": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013200406s
STEP: Saw pod success
Aug  5 14:18:16.526: INFO: Pod "downwardapi-volume-9ded149b-c940-49bc-80e7-3b5f0120c015" satisfied condition "Succeeded or Failed"
Aug  5 14:18:16.528: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-9ded149b-c940-49bc-80e7-3b5f0120c015 container client-container: <nil>
STEP: delete the pod
Aug  5 14:18:16.549: INFO: Waiting for pod downwardapi-volume-9ded149b-c940-49bc-80e7-3b5f0120c015 to disappear
Aug  5 14:18:16.550: INFO: Pod downwardapi-volume-9ded149b-c940-49bc-80e7-3b5f0120c015 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 14:18:16.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4587" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":31,"skipped":602,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:18:16.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Aug  5 14:18:16.576: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6048  0eb7cebb-ce13-4dd8-92e1-a40008a34baa 3431 0 2022-08-05 14:18:16 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2022-08-05 14:18:16 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q26xw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q26xw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:18:16.578: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:18:18.581: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Aug  5 14:18:18.581: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6048 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:18:18.581: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:18:18.582: INFO: ExecWithOptions: Clientset creation
Aug  5 14:18:18.582: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-6048/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod...
Aug  5 14:18:18.654: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6048 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:18:18.655: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:18:18.655: INFO: ExecWithOptions: Clientset creation
Aug  5 14:18:18.655: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-6048/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug  5 14:18:18.731: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Aug  5 14:18:18.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6048" for this suite.
â€¢{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":356,"completed":32,"skipped":619,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:18:18.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:18:19.156: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:18:22.168: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:18:22.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7833" for this suite.
STEP: Destroying namespace "webhook-7833-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":356,"completed":33,"skipped":694,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:18:22.280: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Aug  5 14:24:00.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2192" for this suite.

â€¢ [SLOW TEST:338.056 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":356,"completed":34,"skipped":713,"failed":0}
SS
------------------------------
[sig-node] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:24:00.337: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
Aug  5 14:24:00.359: INFO: The status of Pod pod-update-activedeadlineseconds-5eca93cf-26c2-4efa-9ed2-9fde643037e7 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:24:02.367: INFO: The status of Pod pod-update-activedeadlineseconds-5eca93cf-26c2-4efa-9ed2-9fde643037e7 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug  5 14:24:02.881: INFO: Successfully updated pod "pod-update-activedeadlineseconds-5eca93cf-26c2-4efa-9ed2-9fde643037e7"
Aug  5 14:24:02.881: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-5eca93cf-26c2-4efa-9ed2-9fde643037e7" in namespace "pods-5430" to be "terminated due to deadline exceeded"
Aug  5 14:24:02.883: INFO: Pod "pod-update-activedeadlineseconds-5eca93cf-26c2-4efa-9ed2-9fde643037e7": Phase="Running", Reason="", readiness=true. Elapsed: 1.603789ms
Aug  5 14:24:04.889: INFO: Pod "pod-update-activedeadlineseconds-5eca93cf-26c2-4efa-9ed2-9fde643037e7": Phase="Running", Reason="", readiness=true. Elapsed: 2.007960374s
Aug  5 14:24:06.896: INFO: Pod "pod-update-activedeadlineseconds-5eca93cf-26c2-4efa-9ed2-9fde643037e7": Phase="Running", Reason="", readiness=false. Elapsed: 4.014392732s
Aug  5 14:24:08.900: INFO: Pod "pod-update-activedeadlineseconds-5eca93cf-26c2-4efa-9ed2-9fde643037e7": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.019122626s
Aug  5 14:24:08.900: INFO: Pod "pod-update-activedeadlineseconds-5eca93cf-26c2-4efa-9ed2-9fde643037e7" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Aug  5 14:24:08.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5430" for this suite.

â€¢ [SLOW TEST:8.568 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":356,"completed":35,"skipped":715,"failed":0}
SS
------------------------------
[sig-node] Variable Expansion 
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:24:08.907: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
Aug  5 14:24:10.929: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-6732 PodName:var-expansion-442e6723-a70f-40f9-95e0-e4a44b7ff370 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:24:10.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:24:10.930: INFO: ExecWithOptions: Clientset creation
Aug  5 14:24:10.930: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-6732/pods/var-expansion-442e6723-a70f-40f9-95e0-e4a44b7ff370/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path
Aug  5 14:24:11.002: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-6732 PodName:var-expansion-442e6723-a70f-40f9-95e0-e4a44b7ff370 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:24:11.002: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:24:11.002: INFO: ExecWithOptions: Clientset creation
Aug  5 14:24:11.002: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-6732/pods/var-expansion-442e6723-a70f-40f9-95e0-e4a44b7ff370/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value
Aug  5 14:24:11.576: INFO: Successfully updated pod "var-expansion-442e6723-a70f-40f9-95e0-e4a44b7ff370"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
Aug  5 14:24:11.579: INFO: Deleting pod "var-expansion-442e6723-a70f-40f9-95e0-e4a44b7ff370" in namespace "var-expansion-6732"
Aug  5 14:24:11.583: INFO: Wait up to 5m0s for pod "var-expansion-442e6723-a70f-40f9-95e0-e4a44b7ff370" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Aug  5 14:24:45.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6732" for this suite.

â€¢ [SLOW TEST:36.689 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":356,"completed":36,"skipped":717,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:24:45.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:24:45.608: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:24:46.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9511" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":356,"completed":37,"skipped":722,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:24:46.135: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
Aug  5 14:24:46.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8084" for this suite.
â€¢{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":38,"skipped":737,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:24:46.152: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-907d94bf-e8e9-47cf-ae41-f94101c96ea7
STEP: Creating a pod to test consume secrets
Aug  5 14:24:46.166: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-237c4a0b-b464-4134-951b-e287ecae5ab4" in namespace "projected-5872" to be "Succeeded or Failed"
Aug  5 14:24:46.167: INFO: Pod "pod-projected-secrets-237c4a0b-b464-4134-951b-e287ecae5ab4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.510161ms
Aug  5 14:24:48.171: INFO: Pod "pod-projected-secrets-237c4a0b-b464-4134-951b-e287ecae5ab4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005065461s
Aug  5 14:24:50.178: INFO: Pod "pod-projected-secrets-237c4a0b-b464-4134-951b-e287ecae5ab4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012011345s
STEP: Saw pod success
Aug  5 14:24:50.178: INFO: Pod "pod-projected-secrets-237c4a0b-b464-4134-951b-e287ecae5ab4" satisfied condition "Succeeded or Failed"
Aug  5 14:24:50.180: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-secrets-237c4a0b-b464-4134-951b-e287ecae5ab4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  5 14:24:50.203: INFO: Waiting for pod pod-projected-secrets-237c4a0b-b464-4134-951b-e287ecae5ab4 to disappear
Aug  5 14:24:50.204: INFO: Pod pod-projected-secrets-237c4a0b-b464-4134-951b-e287ecae5ab4 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Aug  5 14:24:50.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5872" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":39,"skipped":763,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:24:50.209: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Aug  5 14:25:50.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8878" for this suite.

â€¢ [SLOW TEST:60.023 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":356,"completed":40,"skipped":773,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:25:50.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Aug  5 14:25:52.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-775" for this suite.
â€¢{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","total":356,"completed":41,"skipped":799,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:25:52.266: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Aug  5 14:25:52.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8619 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Aug  5 14:25:52.328: INFO: stderr: ""
Aug  5 14:25:52.328: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
Aug  5 14:25:52.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8619 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Aug  5 14:25:52.985: INFO: stderr: ""
Aug  5 14:25:52.985: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Aug  5 14:25:52.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8619 delete pods e2e-test-httpd-pod'
Aug  5 14:25:54.596: INFO: stderr: ""
Aug  5 14:25:54.596: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:25:54.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8619" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":356,"completed":42,"skipped":826,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:25:54.603: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:25:55.346: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:25:58.361: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:25:58.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1747" for this suite.
STEP: Destroying namespace "webhook-1747-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":356,"completed":43,"skipped":866,"failed":0}
SS
------------------------------
[sig-apps] CronJob 
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:25:58.421: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Aug  5 14:27:00.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-118" for this suite.

â€¢ [SLOW TEST:62.083 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":356,"completed":44,"skipped":868,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:00.504: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:27:00.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Aug  5 14:27:02.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-217 --namespace=crd-publish-openapi-217 create -f -'
Aug  5 14:27:03.031: INFO: stderr: ""
Aug  5 14:27:03.031: INFO: stdout: "e2e-test-crd-publish-openapi-2092-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug  5 14:27:03.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-217 --namespace=crd-publish-openapi-217 delete e2e-test-crd-publish-openapi-2092-crds test-cr'
Aug  5 14:27:03.078: INFO: stderr: ""
Aug  5 14:27:03.078: INFO: stdout: "e2e-test-crd-publish-openapi-2092-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Aug  5 14:27:03.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-217 --namespace=crd-publish-openapi-217 apply -f -'
Aug  5 14:27:03.211: INFO: stderr: ""
Aug  5 14:27:03.211: INFO: stdout: "e2e-test-crd-publish-openapi-2092-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug  5 14:27:03.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-217 --namespace=crd-publish-openapi-217 delete e2e-test-crd-publish-openapi-2092-crds test-cr'
Aug  5 14:27:03.262: INFO: stderr: ""
Aug  5 14:27:03.262: INFO: stdout: "e2e-test-crd-publish-openapi-2092-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Aug  5 14:27:03.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-217 explain e2e-test-crd-publish-openapi-2092-crds'
Aug  5 14:27:03.387: INFO: stderr: ""
Aug  5 14:27:03.387: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2092-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:27:06.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-217" for this suite.

â€¢ [SLOW TEST:5.861 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":356,"completed":45,"skipped":892,"failed":0}
S
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:06.366: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Aug  5 14:27:06.388: INFO: Waiting up to 5m0s for pod "downward-api-463f4749-6702-411f-ba25-43ccb1203036" in namespace "downward-api-9924" to be "Succeeded or Failed"
Aug  5 14:27:06.390: INFO: Pod "downward-api-463f4749-6702-411f-ba25-43ccb1203036": Phase="Pending", Reason="", readiness=false. Elapsed: 2.140904ms
Aug  5 14:27:08.401: INFO: Pod "downward-api-463f4749-6702-411f-ba25-43ccb1203036": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013468043s
Aug  5 14:27:10.407: INFO: Pod "downward-api-463f4749-6702-411f-ba25-43ccb1203036": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018835097s
STEP: Saw pod success
Aug  5 14:27:10.407: INFO: Pod "downward-api-463f4749-6702-411f-ba25-43ccb1203036" satisfied condition "Succeeded or Failed"
Aug  5 14:27:10.409: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downward-api-463f4749-6702-411f-ba25-43ccb1203036 container dapi-container: <nil>
STEP: delete the pod
Aug  5 14:27:10.435: INFO: Waiting for pod downward-api-463f4749-6702-411f-ba25-43ccb1203036 to disappear
Aug  5 14:27:10.437: INFO: Pod downward-api-463f4749-6702-411f-ba25-43ccb1203036 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Aug  5 14:27:10.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9924" for this suite.
â€¢{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":356,"completed":46,"skipped":893,"failed":0}
SSSS
------------------------------
[sig-network] EndpointSlice 
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:10.441: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug  5 14:27:10.467: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Aug  5 14:27:10.470: INFO: starting watch
STEP: patching
STEP: updating
Aug  5 14:27:10.477: INFO: waiting for watch events with expected annotations
Aug  5 14:27:10.477: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Aug  5 14:27:10.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5926" for this suite.
â€¢{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":356,"completed":47,"skipped":897,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:10.495: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:27:10.505: INFO: Creating simple deployment test-new-deployment
Aug  5 14:27:10.512: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug  5 14:27:12.537: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-3558  f14f9325-09ef-4401-956e-55bd9688e4c5 5364 3 2022-08-05 14:27:10 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-08-05 14:27:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:27:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e35e28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-05 14:27:11 +0000 UTC,LastTransitionTime:2022-08-05 14:27:11 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-55df494869" has successfully progressed.,LastUpdateTime:2022-08-05 14:27:11 +0000 UTC,LastTransitionTime:2022-08-05 14:27:10 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug  5 14:27:12.540: INFO: New ReplicaSet "test-new-deployment-55df494869" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-55df494869  deployment-3558  70cd8bd7-b6c4-41af-97b8-77f68981e9b0 5363 2 2022-08-05 14:27:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment f14f9325-09ef-4401-956e-55bd9688e4c5 0xc004eaa360 0xc004eaa361}] []  [{kube-controller-manager Update apps/v1 2022-08-05 14:27:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f14f9325-09ef-4401-956e-55bd9688e4c5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:27:11 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004eaa3e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug  5 14:27:12.543: INFO: Pod "test-new-deployment-55df494869-2bgc7" is not available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-2bgc7 test-new-deployment-55df494869- deployment-3558  82b62f71-2411-48a9-8e2e-38ae214fbc4b 5367 0 2022-08-05 14:27:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet test-new-deployment-55df494869 70cd8bd7-b6c4-41af-97b8-77f68981e9b0 0xc004e078b0 0xc004e078b1}] []  [{kube-controller-manager Update v1 2022-08-05 14:27:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"70cd8bd7-b6c4-41af-97b8-77f68981e9b0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mhsb4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mhsb4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:27:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:27:12.543: INFO: Pod "test-new-deployment-55df494869-ltjj5" is available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-ltjj5 test-new-deployment-55df494869- deployment-3558  b68b4de5-a96d-4bc4-bcf0-1312b69b233d 5358 0 2022-08-05 14:27:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:3f7396486a5a549c0f4ecea1724b1e188e1ef824677ec0b322d07779d1398b3c cni.projectcalico.org/podIP:10.244.18.175/32 cni.projectcalico.org/podIPs:10.244.18.175/32] [{apps/v1 ReplicaSet test-new-deployment-55df494869 70cd8bd7-b6c4-41af-97b8-77f68981e9b0 0xc004e07ac0 0xc004e07ac1}] []  [{kube-controller-manager Update v1 2022-08-05 14:27:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"70cd8bd7-b6c4-41af-97b8-77f68981e9b0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:27:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:27:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.18.175\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rrctn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rrctn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:27:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:27:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:27:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:27:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:10.244.18.175,StartTime:2022-08-05 14:27:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:27:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d0b186f1607526c78d8880c352efd7351f167d2a2af9fe39c6b5d06f0f2389b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.18.175,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Aug  5 14:27:12.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3558" for this suite.
â€¢{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":356,"completed":48,"skipped":919,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:12.549: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
Aug  5 14:27:12.561: INFO: namespace kubectl-7102
Aug  5 14:27:12.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-7102 create -f -'
Aug  5 14:27:13.091: INFO: stderr: ""
Aug  5 14:27:13.091: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Aug  5 14:27:14.095: INFO: Selector matched 1 pods for map[app:agnhost]
Aug  5 14:27:14.095: INFO: Found 0 / 1
Aug  5 14:27:15.094: INFO: Selector matched 1 pods for map[app:agnhost]
Aug  5 14:27:15.094: INFO: Found 1 / 1
Aug  5 14:27:15.094: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  5 14:27:15.095: INFO: Selector matched 1 pods for map[app:agnhost]
Aug  5 14:27:15.095: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  5 14:27:15.095: INFO: wait on agnhost-primary startup in kubectl-7102 
Aug  5 14:27:15.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-7102 logs agnhost-primary-d2nqm agnhost-primary'
Aug  5 14:27:15.145: INFO: stderr: ""
Aug  5 14:27:15.145: INFO: stdout: "Paused\n"
STEP: exposing RC
Aug  5 14:27:15.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-7102 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Aug  5 14:27:15.195: INFO: stderr: ""
Aug  5 14:27:15.195: INFO: stdout: "service/rm2 exposed\n"
Aug  5 14:27:15.197: INFO: Service rm2 in namespace kubectl-7102 found.
STEP: exposing service
Aug  5 14:27:17.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-7102 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Aug  5 14:27:17.254: INFO: stderr: ""
Aug  5 14:27:17.254: INFO: stdout: "service/rm3 exposed\n"
Aug  5 14:27:17.256: INFO: Service rm3 in namespace kubectl-7102 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:27:19.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7102" for this suite.

â€¢ [SLOW TEST:6.718 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1249
    should create services for rc  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":356,"completed":49,"skipped":946,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:19.268: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:27:19.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7965" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":356,"completed":50,"skipped":958,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:19.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 14:27:19.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8993" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":356,"completed":51,"skipped":960,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:19.337: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on node default medium
Aug  5 14:27:19.352: INFO: Waiting up to 5m0s for pod "pod-d19bb090-2bf2-4de7-99f7-846c8420a51d" in namespace "emptydir-9168" to be "Succeeded or Failed"
Aug  5 14:27:19.354: INFO: Pod "pod-d19bb090-2bf2-4de7-99f7-846c8420a51d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.55587ms
Aug  5 14:27:21.360: INFO: Pod "pod-d19bb090-2bf2-4de7-99f7-846c8420a51d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00786162s
Aug  5 14:27:23.364: INFO: Pod "pod-d19bb090-2bf2-4de7-99f7-846c8420a51d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010973211s
STEP: Saw pod success
Aug  5 14:27:23.364: INFO: Pod "pod-d19bb090-2bf2-4de7-99f7-846c8420a51d" satisfied condition "Succeeded or Failed"
Aug  5 14:27:23.365: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-d19bb090-2bf2-4de7-99f7-846c8420a51d container test-container: <nil>
STEP: delete the pod
Aug  5 14:27:23.374: INFO: Waiting for pod pod-d19bb090-2bf2-4de7-99f7-846c8420a51d to disappear
Aug  5 14:27:23.375: INFO: Pod pod-d19bb090-2bf2-4de7-99f7-846c8420a51d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 14:27:23.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9168" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":52,"skipped":985,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:23.381: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
Aug  5 14:27:23.393: INFO: Pod name sample-pod: Found 0 pods out of 3
Aug  5 14:27:28.396: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
Aug  5 14:27:28.398: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Aug  5 14:27:28.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5132" for this suite.

â€¢ [SLOW TEST:5.028 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":356,"completed":53,"skipped":1007,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:28.410: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching services
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 14:27:28.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9829" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
â€¢{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":356,"completed":54,"skipped":1012,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:28.469: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:27:29.176: INFO: Checking APIGroup: apiregistration.k8s.io
Aug  5 14:27:29.177: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Aug  5 14:27:29.177: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Aug  5 14:27:29.177: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Aug  5 14:27:29.177: INFO: Checking APIGroup: apps
Aug  5 14:27:29.178: INFO: PreferredVersion.GroupVersion: apps/v1
Aug  5 14:27:29.178: INFO: Versions found [{apps/v1 v1}]
Aug  5 14:27:29.178: INFO: apps/v1 matches apps/v1
Aug  5 14:27:29.178: INFO: Checking APIGroup: events.k8s.io
Aug  5 14:27:29.179: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Aug  5 14:27:29.179: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
Aug  5 14:27:29.179: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Aug  5 14:27:29.179: INFO: Checking APIGroup: authentication.k8s.io
Aug  5 14:27:29.180: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Aug  5 14:27:29.180: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Aug  5 14:27:29.180: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Aug  5 14:27:29.180: INFO: Checking APIGroup: authorization.k8s.io
Aug  5 14:27:29.181: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Aug  5 14:27:29.181: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Aug  5 14:27:29.181: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Aug  5 14:27:29.181: INFO: Checking APIGroup: autoscaling
Aug  5 14:27:29.181: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Aug  5 14:27:29.181: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
Aug  5 14:27:29.181: INFO: autoscaling/v2 matches autoscaling/v2
Aug  5 14:27:29.181: INFO: Checking APIGroup: batch
Aug  5 14:27:29.182: INFO: PreferredVersion.GroupVersion: batch/v1
Aug  5 14:27:29.182: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
Aug  5 14:27:29.182: INFO: batch/v1 matches batch/v1
Aug  5 14:27:29.182: INFO: Checking APIGroup: certificates.k8s.io
Aug  5 14:27:29.183: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Aug  5 14:27:29.183: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Aug  5 14:27:29.183: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Aug  5 14:27:29.183: INFO: Checking APIGroup: networking.k8s.io
Aug  5 14:27:29.184: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Aug  5 14:27:29.184: INFO: Versions found [{networking.k8s.io/v1 v1}]
Aug  5 14:27:29.184: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Aug  5 14:27:29.184: INFO: Checking APIGroup: policy
Aug  5 14:27:29.185: INFO: PreferredVersion.GroupVersion: policy/v1
Aug  5 14:27:29.185: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
Aug  5 14:27:29.185: INFO: policy/v1 matches policy/v1
Aug  5 14:27:29.185: INFO: Checking APIGroup: rbac.authorization.k8s.io
Aug  5 14:27:29.185: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Aug  5 14:27:29.185: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Aug  5 14:27:29.185: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Aug  5 14:27:29.185: INFO: Checking APIGroup: storage.k8s.io
Aug  5 14:27:29.186: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Aug  5 14:27:29.186: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Aug  5 14:27:29.186: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Aug  5 14:27:29.186: INFO: Checking APIGroup: admissionregistration.k8s.io
Aug  5 14:27:29.187: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Aug  5 14:27:29.187: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Aug  5 14:27:29.187: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Aug  5 14:27:29.187: INFO: Checking APIGroup: apiextensions.k8s.io
Aug  5 14:27:29.188: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Aug  5 14:27:29.188: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Aug  5 14:27:29.188: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Aug  5 14:27:29.188: INFO: Checking APIGroup: scheduling.k8s.io
Aug  5 14:27:29.188: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Aug  5 14:27:29.188: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Aug  5 14:27:29.188: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Aug  5 14:27:29.188: INFO: Checking APIGroup: coordination.k8s.io
Aug  5 14:27:29.189: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Aug  5 14:27:29.189: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Aug  5 14:27:29.189: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Aug  5 14:27:29.189: INFO: Checking APIGroup: node.k8s.io
Aug  5 14:27:29.190: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Aug  5 14:27:29.190: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
Aug  5 14:27:29.190: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Aug  5 14:27:29.190: INFO: Checking APIGroup: discovery.k8s.io
Aug  5 14:27:29.190: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Aug  5 14:27:29.190: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
Aug  5 14:27:29.190: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Aug  5 14:27:29.190: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Aug  5 14:27:29.191: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Aug  5 14:27:29.191: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Aug  5 14:27:29.191: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Aug  5 14:27:29.191: INFO: Checking APIGroup: internal.apiserver.k8s.io
Aug  5 14:27:29.192: INFO: PreferredVersion.GroupVersion: internal.apiserver.k8s.io/v1alpha1
Aug  5 14:27:29.192: INFO: Versions found [{internal.apiserver.k8s.io/v1alpha1 v1alpha1}]
Aug  5 14:27:29.192: INFO: internal.apiserver.k8s.io/v1alpha1 matches internal.apiserver.k8s.io/v1alpha1
Aug  5 14:27:29.192: INFO: Checking APIGroup: crd.projectcalico.org
Aug  5 14:27:29.193: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Aug  5 14:27:29.193: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Aug  5 14:27:29.193: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:188
Aug  5 14:27:29.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-4128" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":356,"completed":55,"skipped":1060,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:29.199: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug  5 14:27:29.215: INFO: Waiting up to 5m0s for pod "pod-1f6e51da-37ea-452e-af94-e82a324048e2" in namespace "emptydir-3667" to be "Succeeded or Failed"
Aug  5 14:27:29.217: INFO: Pod "pod-1f6e51da-37ea-452e-af94-e82a324048e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.139889ms
Aug  5 14:27:31.223: INFO: Pod "pod-1f6e51da-37ea-452e-af94-e82a324048e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007924029s
Aug  5 14:27:33.227: INFO: Pod "pod-1f6e51da-37ea-452e-af94-e82a324048e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011991175s
STEP: Saw pod success
Aug  5 14:27:33.227: INFO: Pod "pod-1f6e51da-37ea-452e-af94-e82a324048e2" satisfied condition "Succeeded or Failed"
Aug  5 14:27:33.229: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-1f6e51da-37ea-452e-af94-e82a324048e2 container test-container: <nil>
STEP: delete the pod
Aug  5 14:27:33.241: INFO: Waiting for pod pod-1f6e51da-37ea-452e-af94-e82a324048e2 to disappear
Aug  5 14:27:33.242: INFO: Pod pod-1f6e51da-37ea-452e-af94-e82a324048e2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 14:27:33.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3667" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":56,"skipped":1071,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:33.247: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:27:33.766: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:27:36.794: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:27:36.799: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3067-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:27:39.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7517" for this suite.
STEP: Destroying namespace "webhook-7517-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

â€¢ [SLOW TEST:6.642 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":356,"completed":57,"skipped":1106,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:39.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:27:39.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5372" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":356,"completed":58,"skipped":1128,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:39.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not conflict [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:27:39.972: INFO: The status of Pod pod-secrets-c6ae4e06-de4d-41e7-8283-d0a00631ebc3 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:27:41.977: INFO: The status of Pod pod-secrets-c6ae4e06-de4d-41e7-8283-d0a00631ebc3 is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
Aug  5 14:27:41.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":356,"completed":59,"skipped":1130,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:42.002: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Aug  5 14:27:44.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9980" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":356,"completed":60,"skipped":1162,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
   should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:44.913: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
Aug  5 14:27:44.931: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
Aug  5 14:27:44.941: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Aug  5 14:27:44.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2303" for this suite.
â€¢{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":356,"completed":61,"skipped":1192,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:44.956: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:27:44.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-714 create -f -'
Aug  5 14:27:45.579: INFO: stderr: ""
Aug  5 14:27:45.579: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Aug  5 14:27:45.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-714 create -f -'
Aug  5 14:27:45.709: INFO: stderr: ""
Aug  5 14:27:45.709: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Aug  5 14:27:46.713: INFO: Selector matched 1 pods for map[app:agnhost]
Aug  5 14:27:46.713: INFO: Found 0 / 1
Aug  5 14:27:47.713: INFO: Selector matched 1 pods for map[app:agnhost]
Aug  5 14:27:47.713: INFO: Found 1 / 1
Aug  5 14:27:47.713: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  5 14:27:47.715: INFO: Selector matched 1 pods for map[app:agnhost]
Aug  5 14:27:47.715: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  5 14:27:47.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-714 describe pod agnhost-primary-jgczs'
Aug  5 14:27:47.765: INFO: stderr: ""
Aug  5 14:27:47.765: INFO: stdout: "Name:         agnhost-primary-jgczs\nNamespace:    kubectl-714\nPriority:     0\nNode:         vke-automated-test-82a4b3cb9b0e/10.1.96.4\nStart Time:   Fri, 05 Aug 2022 14:27:45 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  cni.projectcalico.org/containerID: b17cb82b9d520ad38addaa182effd32a6964bd8379fa10d9ee5e0ab78029ea61\n              cni.projectcalico.org/podIP: 10.244.18.182/32\n              cni.projectcalico.org/podIPs: 10.244.18.182/32\nStatus:       Running\nIP:           10.244.18.182\nIPs:\n  IP:           10.244.18.182\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://9d45b725e7a02fd72229b615ce308426382ab7f5618b5b654e230456b2408385\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Image ID:       k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 05 Aug 2022 14:27:46 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6cwwn (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-6cwwn:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-714/agnhost-primary-jgczs to vke-automated-test-82a4b3cb9b0e\n  Normal  Pulled     1s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.39\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Aug  5 14:27:47.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-714 describe rc agnhost-primary'
Aug  5 14:27:47.814: INFO: stderr: ""
Aug  5 14:27:47.814: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-714\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-jgczs\n"
Aug  5 14:27:47.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-714 describe service agnhost-primary'
Aug  5 14:27:47.862: INFO: stderr: ""
Aug  5 14:27:47.862: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-714\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.37.194\nIPs:               10.96.37.194\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.18.182:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug  5 14:27:47.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-714 describe node vke-automated-test-82a4b3cb9b0e'
Aug  5 14:27:47.925: INFO: stderr: ""
Aug  5 14:27:47.925: INFO: stdout: "Name:               vke-automated-test-82a4b3cb9b0e\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=vc2-2c-4gb\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=ewr\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=vke-automated-test-82a4b3cb9b0e\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=vc2-2c-4gb\n                    region=EWR\n                    topology.kubernetes.io/region=ewr\n                    vke.vultr.com/node-id=87f40198-7755-4d66-95ce-c035fb4b52b1\n                    vke.vultr.com/node-pool=vke-automated-test\n                    vke.vultr.com/node-pool-id=9d26cb4d-67f3-472b-a4ed-d06de38ccd24\n                    vke.vultr.com/version=v1.24.3-1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"block.csi.vultr.com\":\"87f40198-7755-4d66-95ce-c035fb4b52b1\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.1.96.4/8\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.244.18.128\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 05 Aug 2022 14:11:41 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  vke-automated-test-82a4b3cb9b0e\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 05 Aug 2022 14:27:42 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 05 Aug 2022 14:12:03 +0000   Fri, 05 Aug 2022 14:12:03 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Fri, 05 Aug 2022 14:24:17 +0000   Fri, 05 Aug 2022 14:11:41 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 05 Aug 2022 14:24:17 +0000   Fri, 05 Aug 2022 14:11:41 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 05 Aug 2022 14:24:17 +0000   Fri, 05 Aug 2022 14:11:41 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 05 Aug 2022 14:24:17 +0000   Fri, 05 Aug 2022 14:12:12 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  Hostname:    vke-automated-test-82a4b3cb9b0e\n  InternalIP:  10.1.96.4\n  ExternalIP:  140.82.10.236\nCapacity:\n  cpu:                2\n  ephemeral-storage:  78544804Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             4041468Ki\n  pods:               110\nAllocatable:\n  cpu:                1800m\n  ephemeral-storage:  72386891247\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3734268Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 dc4a9d41ee2e4255a3d6c77bfc9395e9\n  System UUID:                d1fa4ba5-1605-4f63-9cfb-a37d4c59a2ca\n  Boot ID:                    527f32ba-c1f7-460f-ad2c-1f38c3c9485a\n  Kernel Version:             4.19.0-21-amd64\n  OS Image:                   Debian GNU/Linux 10 (buster)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.4\n  Kubelet Version:            v1.24.3\n  Kube-Proxy Version:         v1.24.3\nProviderID:                   vultr://87f40198-7755-4d66-95ce-c035fb4b52b1\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-2jtxk                                          250m (13%)    0 (0%)      0 (0%)           0 (0%)         15m\n  kube-system                 csi-vultr-node-kn67c                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n  kube-system                 konnectivity-agent-z6dpf                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n  kubectl-714                 agnhost-primary-jgczs                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n  sonobuoy                    sonobuoy-e2e-job-5437b3f59c524af6                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-vnb9h    0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n  webhook-1747                webhook-to-be-mutated                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         109s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (13%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age                From                   Message\n  ----     ------                   ----               ----                   -------\n  Normal   Starting                 15m                kube-proxy             \n  Warning  InvalidDiskCapacity      16m                kubelet                invalid capacity 0 on image filesystem\n  Normal   Starting                 16m                kubelet                Starting kubelet.\n  Normal   NodeAllocatableEnforced  16m                kubelet                Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     16m (x7 over 16m)  kubelet                Node vke-automated-test-82a4b3cb9b0e status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    16m (x7 over 16m)  kubelet                Node vke-automated-test-82a4b3cb9b0e status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  16m (x8 over 16m)  kubelet                Node vke-automated-test-82a4b3cb9b0e status is now: NodeHasSufficientMemory\n  Normal   Synced                   16m                cloud-node-controller  Node synced successfully\n  Normal   RegisteredNode           15m                node-controller        Node vke-automated-test-82a4b3cb9b0e event: Registered Node vke-automated-test-82a4b3cb9b0e in Controller\n"
Aug  5 14:27:47.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-714 describe namespace kubectl-714'
Aug  5 14:27:47.976: INFO: stderr: ""
Aug  5 14:27:47.977: INFO: stdout: "Name:         kubectl-714\nLabels:       e2e-framework=kubectl\n              e2e-run=f63a3d34-4434-4abc-b295-94ed0110f62c\n              kubernetes.io/metadata.name=kubectl-714\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:27:47.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-714" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":356,"completed":62,"skipped":1198,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:47.983: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7138.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7138.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7138.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7138.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7138.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7138.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7138.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7138.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  5 14:27:54.019: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local from pod dns-7138/dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b: the server could not find the requested resource (get pods dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b)
Aug  5 14:27:54.021: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local from pod dns-7138/dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b: the server could not find the requested resource (get pods dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b)
Aug  5 14:27:54.024: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7138.svc.cluster.local from pod dns-7138/dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b: the server could not find the requested resource (get pods dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b)
Aug  5 14:27:54.027: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7138.svc.cluster.local from pod dns-7138/dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b: the server could not find the requested resource (get pods dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b)
Aug  5 14:27:54.029: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local from pod dns-7138/dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b: the server could not find the requested resource (get pods dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b)
Aug  5 14:27:54.031: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local from pod dns-7138/dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b: the server could not find the requested resource (get pods dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b)
Aug  5 14:27:54.034: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7138.svc.cluster.local from pod dns-7138/dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b: the server could not find the requested resource (get pods dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b)
Aug  5 14:27:54.036: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7138.svc.cluster.local from pod dns-7138/dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b: the server could not find the requested resource (get pods dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b)
Aug  5 14:27:54.036: INFO: Lookups using dns-7138/dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7138.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7138.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7138.svc.cluster.local jessie_udp@dns-test-service-2.dns-7138.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7138.svc.cluster.local]

Aug  5 14:27:59.058: INFO: DNS probes using dns-7138/dns-test-f1bcb21e-008e-4274-b49e-90145f6afd7b succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Aug  5 14:27:59.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7138" for this suite.

â€¢ [SLOW TEST:11.100 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":356,"completed":63,"skipped":1200,"failed":0}
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:27:59.094: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: reading a file in the container
Aug  5 14:28:01.146: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6666 pod-service-account-df64eb34-0f1f-4f6a-800d-1c306deef25f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug  5 14:28:01.254: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6666 pod-service-account-df64eb34-0f1f-4f6a-800d-1c306deef25f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug  5 14:28:01.365: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6666 pod-service-account-df64eb34-0f1f-4f6a-800d-1c306deef25f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Aug  5 14:28:01.592: INFO: Got root ca configmap in namespace "svcaccounts-6666"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Aug  5 14:28:01.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6666" for this suite.
â€¢{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":356,"completed":64,"skipped":1208,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:28:01.600: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Aug  5 14:28:01.624: INFO: The status of Pod labelsupdatef948f715-b509-4e7a-b83a-6f425ae94dd1 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:28:03.628: INFO: The status of Pod labelsupdatef948f715-b509-4e7a-b83a-6f425ae94dd1 is Running (Ready = true)
Aug  5 14:28:04.143: INFO: Successfully updated pod "labelsupdatef948f715-b509-4e7a-b83a-6f425ae94dd1"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 14:28:08.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9311" for this suite.

â€¢ [SLOW TEST:6.575 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":65,"skipped":1212,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:28:08.176: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Aug  5 14:28:08.735: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
W0805 14:28:08.735930      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Aug  5 14:28:08.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3941" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":356,"completed":66,"skipped":1248,"failed":0}
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:28:08.741: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug  5 14:28:08.753: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  5 14:28:08.757: INFO: Waiting for terminating namespaces to be deleted...
Aug  5 14:28:08.759: INFO: 
Logging pods the apiserver thinks is on node vke-automated-test-82a4b3cb9b0e before test
Aug  5 14:28:08.764: INFO: labelsupdatef948f715-b509-4e7a-b83a-6f425ae94dd1 from downward-api-9311 started at 2022-08-05 14:28:01 +0000 UTC (1 container statuses recorded)
Aug  5 14:28:08.764: INFO: 	Container client-container ready: true, restart count 0
Aug  5 14:28:08.764: INFO: calico-node-2jtxk from kube-system started at 2022-08-05 14:11:50 +0000 UTC (1 container statuses recorded)
Aug  5 14:28:08.764: INFO: 	Container calico-node ready: true, restart count 0
Aug  5 14:28:08.765: INFO: csi-vultr-node-kn67c from kube-system started at 2022-08-05 14:12:12 +0000 UTC (2 container statuses recorded)
Aug  5 14:28:08.765: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 14:28:08.765: INFO: 	Container driver-registrar ready: true, restart count 0
Aug  5 14:28:08.765: INFO: konnectivity-agent-z6dpf from kube-system started at 2022-08-05 14:12:12 +0000 UTC (1 container statuses recorded)
Aug  5 14:28:08.765: INFO: 	Container konnectivity-agent ready: true, restart count 0
Aug  5 14:28:08.765: INFO: sonobuoy from sonobuoy started at 2022-08-05 14:12:25 +0000 UTC (1 container statuses recorded)
Aug  5 14:28:08.765: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  5 14:28:08.765: INFO: sonobuoy-e2e-job-5437b3f59c524af6 from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 14:28:08.765: INFO: 	Container e2e ready: true, restart count 0
Aug  5 14:28:08.765: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 14:28:08.765: INFO: sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-vnb9h from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 14:28:08.765: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 14:28:08.765: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  5 14:28:08.765: INFO: 
Logging pods the apiserver thinks is on node vke-automated-test-b1f24d775249 before test
Aug  5 14:28:08.770: INFO: calico-kube-controllers-56cdb7c587-zstqt from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 14:28:08.770: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug  5 14:28:08.770: INFO: calico-node-bc7zg from kube-system started at 2022-08-05 14:11:50 +0000 UTC (1 container statuses recorded)
Aug  5 14:28:08.770: INFO: 	Container calico-node ready: true, restart count 0
Aug  5 14:28:08.770: INFO: cluster-autoscaler-595d485b76-4kzzf from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 14:28:08.770: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Aug  5 14:28:08.770: INFO: coredns-75c8969664-pdxjk from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 14:28:08.770: INFO: 	Container coredns ready: true, restart count 0
Aug  5 14:28:08.770: INFO: coredns-75c8969664-xvmdn from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 14:28:08.770: INFO: 	Container coredns ready: true, restart count 0
Aug  5 14:28:08.770: INFO: csi-vultr-controller-0 from kube-system started at 2022-08-05 14:12:02 +0000 UTC (3 container statuses recorded)
Aug  5 14:28:08.770: INFO: 	Container csi-attacher ready: true, restart count 0
Aug  5 14:28:08.770: INFO: 	Container csi-provisioner ready: true, restart count 0
Aug  5 14:28:08.770: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 14:28:08.770: INFO: csi-vultr-node-5xrgd from kube-system started at 2022-08-05 14:12:02 +0000 UTC (2 container statuses recorded)
Aug  5 14:28:08.770: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 14:28:08.770: INFO: 	Container driver-registrar ready: true, restart count 0
Aug  5 14:28:08.770: INFO: konnectivity-agent-c72gb from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 14:28:08.770: INFO: 	Container konnectivity-agent ready: true, restart count 0
Aug  5 14:28:08.770: INFO: sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-zqktm from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 14:28:08.770: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 14:28:08.770: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1708792b1e1d91bb], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Aug  5 14:28:09.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3790" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
â€¢{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":356,"completed":67,"skipped":1254,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:28:09.790: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting the proxy server
Aug  5 14:28:09.803: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-1182 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:28:09.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1182" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":356,"completed":68,"skipped":1276,"failed":0}

------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:28:09.865: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3371
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:28:09.884: INFO: Found 0 stateful pods, waiting for 1
Aug  5 14:28:19.891: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
Aug  5 14:28:19.904: INFO: Found 1 stateful pods, waiting for 2
Aug  5 14:28:29.909: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:28:29.909: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug  5 14:28:29.919: INFO: Deleting all statefulset in ns statefulset-3371
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Aug  5 14:28:29.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3371" for this suite.

â€¢ [SLOW TEST:20.066 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":356,"completed":69,"skipped":1276,"failed":0}
SSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:28:29.931: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override all
Aug  5 14:28:29.964: INFO: Waiting up to 5m0s for pod "client-containers-49b2ce1a-33a6-447a-aae3-eec104ca1e18" in namespace "containers-8397" to be "Succeeded or Failed"
Aug  5 14:28:29.965: INFO: Pod "client-containers-49b2ce1a-33a6-447a-aae3-eec104ca1e18": Phase="Pending", Reason="", readiness=false. Elapsed: 1.513418ms
Aug  5 14:28:31.973: INFO: Pod "client-containers-49b2ce1a-33a6-447a-aae3-eec104ca1e18": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009547237s
Aug  5 14:28:33.977: INFO: Pod "client-containers-49b2ce1a-33a6-447a-aae3-eec104ca1e18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013132429s
STEP: Saw pod success
Aug  5 14:28:33.977: INFO: Pod "client-containers-49b2ce1a-33a6-447a-aae3-eec104ca1e18" satisfied condition "Succeeded or Failed"
Aug  5 14:28:33.978: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod client-containers-49b2ce1a-33a6-447a-aae3-eec104ca1e18 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 14:28:33.992: INFO: Waiting for pod client-containers-49b2ce1a-33a6-447a-aae3-eec104ca1e18 to disappear
Aug  5 14:28:33.994: INFO: Pod client-containers-49b2ce1a-33a6-447a-aae3-eec104ca1e18 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Aug  5 14:28:33.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8397" for this suite.
â€¢{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":356,"completed":70,"skipped":1283,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:28:33.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-75c52fa0-0829-497f-8636-e77ac2827fff
STEP: Creating a pod to test consume configMaps
Aug  5 14:28:34.017: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b83f0c06-d01e-4937-b187-4d4d0f573355" in namespace "projected-1658" to be "Succeeded or Failed"
Aug  5 14:28:34.019: INFO: Pod "pod-projected-configmaps-b83f0c06-d01e-4937-b187-4d4d0f573355": Phase="Pending", Reason="", readiness=false. Elapsed: 1.628592ms
Aug  5 14:28:36.024: INFO: Pod "pod-projected-configmaps-b83f0c06-d01e-4937-b187-4d4d0f573355": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006376461s
Aug  5 14:28:38.031: INFO: Pod "pod-projected-configmaps-b83f0c06-d01e-4937-b187-4d4d0f573355": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013264789s
STEP: Saw pod success
Aug  5 14:28:38.031: INFO: Pod "pod-projected-configmaps-b83f0c06-d01e-4937-b187-4d4d0f573355" satisfied condition "Succeeded or Failed"
Aug  5 14:28:38.032: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-configmaps-b83f0c06-d01e-4937-b187-4d4d0f573355 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  5 14:28:38.042: INFO: Waiting for pod pod-projected-configmaps-b83f0c06-d01e-4937-b187-4d4d0f573355 to disappear
Aug  5 14:28:38.043: INFO: Pod pod-projected-configmaps-b83f0c06-d01e-4937-b187-4d4d0f573355 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Aug  5 14:28:38.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1658" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":71,"skipped":1301,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:28:38.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8880
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-8880
Aug  5 14:28:38.067: INFO: Found 0 stateful pods, waiting for 1
Aug  5 14:28:48.073: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
Aug  5 14:28:48.081: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
Aug  5 14:28:48.085: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
Aug  5 14:28:48.086: INFO: Observed &StatefulSet event: ADDED
Aug  5 14:28:48.086: INFO: Found Statefulset ss in namespace statefulset-8880 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug  5 14:28:48.087: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
Aug  5 14:28:48.087: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug  5 14:28:48.089: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
Aug  5 14:28:48.091: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug  5 14:28:48.091: INFO: Deleting all statefulset in ns statefulset-8880
Aug  5 14:28:48.092: INFO: Scaling statefulset ss to 0
Aug  5 14:28:58.102: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:28:58.104: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Aug  5 14:28:58.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8880" for this suite.

â€¢ [SLOW TEST:20.068 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":356,"completed":72,"skipped":1303,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:28:58.118: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:28:58.127: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Aug  5 14:29:00.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-5646 --namespace=crd-publish-openapi-5646 create -f -'
Aug  5 14:29:00.657: INFO: stderr: ""
Aug  5 14:29:00.657: INFO: stdout: "e2e-test-crd-publish-openapi-1641-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug  5 14:29:00.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-5646 --namespace=crd-publish-openapi-5646 delete e2e-test-crd-publish-openapi-1641-crds test-cr'
Aug  5 14:29:00.703: INFO: stderr: ""
Aug  5 14:29:00.703: INFO: stdout: "e2e-test-crd-publish-openapi-1641-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Aug  5 14:29:00.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-5646 --namespace=crd-publish-openapi-5646 apply -f -'
Aug  5 14:29:00.827: INFO: stderr: ""
Aug  5 14:29:00.827: INFO: stdout: "e2e-test-crd-publish-openapi-1641-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug  5 14:29:00.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-5646 --namespace=crd-publish-openapi-5646 delete e2e-test-crd-publish-openapi-1641-crds test-cr'
Aug  5 14:29:00.871: INFO: stderr: ""
Aug  5 14:29:00.871: INFO: stdout: "e2e-test-crd-publish-openapi-1641-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Aug  5 14:29:00.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-5646 explain e2e-test-crd-publish-openapi-1641-crds'
Aug  5 14:29:00.995: INFO: stderr: ""
Aug  5 14:29:00.995: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1641-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:29:03.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5646" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":356,"completed":73,"skipped":1334,"failed":0}
SS
------------------------------
[sig-apps] Job 
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:29:03.022: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Indexed job
STEP: Ensuring job reaches completions
STEP: Ensuring pods with index for job exist
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Aug  5 14:29:11.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2766" for this suite.

â€¢ [SLOW TEST:8.039 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","total":356,"completed":74,"skipped":1336,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:29:11.062: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating secret secrets-7927/secret-test-348ba36b-23e6-4dc3-8067-f8921dbc1ee3
STEP: Creating a pod to test consume secrets
Aug  5 14:29:11.080: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ec1e343-b2f3-4bba-8e22-126a4c816b92" in namespace "secrets-7927" to be "Succeeded or Failed"
Aug  5 14:29:11.081: INFO: Pod "pod-configmaps-2ec1e343-b2f3-4bba-8e22-126a4c816b92": Phase="Pending", Reason="", readiness=false. Elapsed: 1.660551ms
Aug  5 14:29:13.086: INFO: Pod "pod-configmaps-2ec1e343-b2f3-4bba-8e22-126a4c816b92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006568951s
Aug  5 14:29:15.093: INFO: Pod "pod-configmaps-2ec1e343-b2f3-4bba-8e22-126a4c816b92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012852624s
STEP: Saw pod success
Aug  5 14:29:15.093: INFO: Pod "pod-configmaps-2ec1e343-b2f3-4bba-8e22-126a4c816b92" satisfied condition "Succeeded or Failed"
Aug  5 14:29:15.094: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-configmaps-2ec1e343-b2f3-4bba-8e22-126a4c816b92 container env-test: <nil>
STEP: delete the pod
Aug  5 14:29:15.104: INFO: Waiting for pod pod-configmaps-2ec1e343-b2f3-4bba-8e22-126a4c816b92 to disappear
Aug  5 14:29:15.106: INFO: Pod pod-configmaps-2ec1e343-b2f3-4bba-8e22-126a4c816b92 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:29:15.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7927" for this suite.
â€¢{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":75,"skipped":1345,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:29:15.115: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Aug  5 14:29:15.136: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:29:17.142: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Aug  5 14:29:17.150: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:29:19.153: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug  5 14:29:19.175: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  5 14:29:19.177: INFO: Pod pod-with-poststart-http-hook still exists
Aug  5 14:29:21.178: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  5 14:29:21.183: INFO: Pod pod-with-poststart-http-hook still exists
Aug  5 14:29:23.178: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  5 14:29:23.185: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Aug  5 14:29:23.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8169" for this suite.

â€¢ [SLOW TEST:8.075 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":356,"completed":76,"skipped":1363,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:29:23.190: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  5 14:29:25.227: INFO: DNS probes using dns-7873/dns-test-53775788-9b10-40e6-9e10-fef220fdb898 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Aug  5 14:29:25.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7873" for this suite.
â€¢{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":356,"completed":77,"skipped":1367,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:29:25.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 14:29:25.282: INFO: Waiting up to 5m0s for pod "downwardapi-volume-743eaac2-88db-434e-875e-f6a13376230c" in namespace "projected-3981" to be "Succeeded or Failed"
Aug  5 14:29:25.284: INFO: Pod "downwardapi-volume-743eaac2-88db-434e-875e-f6a13376230c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.628106ms
Aug  5 14:29:27.290: INFO: Pod "downwardapi-volume-743eaac2-88db-434e-875e-f6a13376230c": Phase="Running", Reason="", readiness=false. Elapsed: 2.008571476s
Aug  5 14:29:29.295: INFO: Pod "downwardapi-volume-743eaac2-88db-434e-875e-f6a13376230c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013099087s
STEP: Saw pod success
Aug  5 14:29:29.295: INFO: Pod "downwardapi-volume-743eaac2-88db-434e-875e-f6a13376230c" satisfied condition "Succeeded or Failed"
Aug  5 14:29:29.297: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-743eaac2-88db-434e-875e-f6a13376230c container client-container: <nil>
STEP: delete the pod
Aug  5 14:29:29.307: INFO: Waiting for pod downwardapi-volume-743eaac2-88db-434e-875e-f6a13376230c to disappear
Aug  5 14:29:29.308: INFO: Pod downwardapi-volume-743eaac2-88db-434e-875e-f6a13376230c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 14:29:29.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3981" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":78,"skipped":1372,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:29:29.312: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:29:29.326: INFO: Creating ReplicaSet my-hostname-basic-cfc394d9-15bd-45e4-815d-08cb4bf238c2
Aug  5 14:29:29.331: INFO: Pod name my-hostname-basic-cfc394d9-15bd-45e4-815d-08cb4bf238c2: Found 0 pods out of 1
Aug  5 14:29:34.334: INFO: Pod name my-hostname-basic-cfc394d9-15bd-45e4-815d-08cb4bf238c2: Found 1 pods out of 1
Aug  5 14:29:34.334: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-cfc394d9-15bd-45e4-815d-08cb4bf238c2" is running
Aug  5 14:29:34.335: INFO: Pod "my-hostname-basic-cfc394d9-15bd-45e4-815d-08cb4bf238c2-8xc8b" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-05 14:29:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-05 14:29:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-05 14:29:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-05 14:29:29 +0000 UTC Reason: Message:}])
Aug  5 14:29:34.335: INFO: Trying to dial the pod
Aug  5 14:29:39.348: INFO: Controller my-hostname-basic-cfc394d9-15bd-45e4-815d-08cb4bf238c2: Got expected result from replica 1 [my-hostname-basic-cfc394d9-15bd-45e4-815d-08cb4bf238c2-8xc8b]: "my-hostname-basic-cfc394d9-15bd-45e4-815d-08cb4bf238c2-8xc8b", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Aug  5 14:29:39.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-856" for this suite.

â€¢ [SLOW TEST:10.040 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":79,"skipped":1387,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:29:39.352: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  5 14:29:39.380: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:29:39.380: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:29:40.387: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:29:40.387: INFO: Node vke-automated-test-b1f24d775249 is running 0 daemon pod, expected 1
Aug  5 14:29:41.388: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug  5 14:29:41.388: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug  5 14:29:41.400: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:29:41.400: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:29:42.415: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:29:42.415: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:29:43.404: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:29:43.404: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:29:44.407: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug  5 14:29:44.407: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8440, will wait for the garbage collector to delete the pods
Aug  5 14:29:44.465: INFO: Deleting DaemonSet.extensions daemon-set took: 2.998787ms
Aug  5 14:29:44.566: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.080309ms
Aug  5 14:29:47.273: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:29:47.273: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug  5 14:29:47.275: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7189"},"items":null}

Aug  5 14:29:47.276: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7189"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Aug  5 14:29:47.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8440" for this suite.

â€¢ [SLOW TEST:7.934 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":356,"completed":80,"skipped":1395,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:29:47.286: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:29:47.628: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:29:50.640: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:29:50.644: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5513-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:29:53.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6264" for this suite.
STEP: Destroying namespace "webhook-6264-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

â€¢ [SLOW TEST:6.486 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":356,"completed":81,"skipped":1403,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:29:53.772: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-7879
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  5 14:29:53.785: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug  5 14:29:53.828: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:29:55.837: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:29:57.834: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:29:59.836: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:30:01.840: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:30:03.840: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:30:05.837: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug  5 14:30:05.841: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Aug  5 14:30:07.856: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Aug  5 14:30:07.856: INFO: Breadth first check of 10.244.18.143 on host 10.1.96.4...
Aug  5 14:30:07.857: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.18.144:9080/dial?request=hostname&protocol=http&host=10.244.18.143&port=8083&tries=1'] Namespace:pod-network-test-7879 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:30:07.857: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:30:07.858: INFO: ExecWithOptions: Clientset creation
Aug  5 14:30:07.858: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-7879/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.18.144%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.18.143%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug  5 14:30:07.925: INFO: Waiting for responses: map[]
Aug  5 14:30:07.925: INFO: reached 10.244.18.143 after 0/1 tries
Aug  5 14:30:07.925: INFO: Breadth first check of 10.244.107.151 on host 10.1.96.5...
Aug  5 14:30:07.928: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.18.144:9080/dial?request=hostname&protocol=http&host=10.244.107.151&port=8083&tries=1'] Namespace:pod-network-test-7879 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:30:07.928: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:30:07.928: INFO: ExecWithOptions: Clientset creation
Aug  5 14:30:07.928: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-7879/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.18.144%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.107.151%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug  5 14:30:07.988: INFO: Waiting for responses: map[]
Aug  5 14:30:07.988: INFO: reached 10.244.107.151 after 0/1 tries
Aug  5 14:30:07.988: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Aug  5 14:30:07.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7879" for this suite.

â€¢ [SLOW TEST:14.223 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":356,"completed":82,"skipped":1438,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:30:07.998: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
Aug  5 14:30:08.010: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:30:23.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2504" for this suite.

â€¢ [SLOW TEST:15.381 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":356,"completed":83,"skipped":1451,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:30:23.379: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:30:23.986: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:30:27.002: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:30:27.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4169" for this suite.
STEP: Destroying namespace "webhook-4169-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":356,"completed":84,"skipped":1455,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:30:27.070: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:30:27.098: INFO: The status of Pod busybox-host-aliases74975081-a210-4128-acd8-edade7e6797f is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:30:29.102: INFO: The status of Pod busybox-host-aliases74975081-a210-4128-acd8-edade7e6797f is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Aug  5 14:30:29.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6676" for this suite.
â€¢{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":85,"skipped":1487,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:30:29.120: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug  5 14:30:29.143: INFO: Waiting up to 5m0s for pod "pod-af673686-f821-4158-b2b1-18b65df4685e" in namespace "emptydir-2657" to be "Succeeded or Failed"
Aug  5 14:30:29.145: INFO: Pod "pod-af673686-f821-4158-b2b1-18b65df4685e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.828441ms
Aug  5 14:30:31.160: INFO: Pod "pod-af673686-f821-4158-b2b1-18b65df4685e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017501652s
Aug  5 14:30:33.164: INFO: Pod "pod-af673686-f821-4158-b2b1-18b65df4685e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020768024s
STEP: Saw pod success
Aug  5 14:30:33.164: INFO: Pod "pod-af673686-f821-4158-b2b1-18b65df4685e" satisfied condition "Succeeded or Failed"
Aug  5 14:30:33.166: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-af673686-f821-4158-b2b1-18b65df4685e container test-container: <nil>
STEP: delete the pod
Aug  5 14:30:33.176: INFO: Waiting for pod pod-af673686-f821-4158-b2b1-18b65df4685e to disappear
Aug  5 14:30:33.177: INFO: Pod pod-af673686-f821-4158-b2b1-18b65df4685e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 14:30:33.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2657" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":86,"skipped":1522,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:30:33.183: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Aug  5 14:30:33.204: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:30:35.209: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Aug  5 14:30:35.215: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:30:37.221: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug  5 14:30:37.231: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  5 14:30:37.233: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  5 14:30:39.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  5 14:30:39.238: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  5 14:30:41.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  5 14:30:41.242: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Aug  5 14:30:41.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4158" for this suite.

â€¢ [SLOW TEST:8.064 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":356,"completed":87,"skipped":1533,"failed":0}
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:30:41.248: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-a3d512e1-6259-4caf-a00a-39b2df9d2e23
STEP: Creating a pod to test consume configMaps
Aug  5 14:30:41.266: INFO: Waiting up to 5m0s for pod "pod-configmaps-86c91eeb-2930-4e4c-87ee-3e9e577429a8" in namespace "configmap-9688" to be "Succeeded or Failed"
Aug  5 14:30:41.268: INFO: Pod "pod-configmaps-86c91eeb-2930-4e4c-87ee-3e9e577429a8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.58983ms
Aug  5 14:30:43.272: INFO: Pod "pod-configmaps-86c91eeb-2930-4e4c-87ee-3e9e577429a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006272292s
Aug  5 14:30:45.279: INFO: Pod "pod-configmaps-86c91eeb-2930-4e4c-87ee-3e9e577429a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012622777s
STEP: Saw pod success
Aug  5 14:30:45.279: INFO: Pod "pod-configmaps-86c91eeb-2930-4e4c-87ee-3e9e577429a8" satisfied condition "Succeeded or Failed"
Aug  5 14:30:45.281: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-configmaps-86c91eeb-2930-4e4c-87ee-3e9e577429a8 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 14:30:45.292: INFO: Waiting for pod pod-configmaps-86c91eeb-2930-4e4c-87ee-3e9e577429a8 to disappear
Aug  5 14:30:45.294: INFO: Pod pod-configmaps-86c91eeb-2930-4e4c-87ee-3e9e577429a8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 14:30:45.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9688" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":88,"skipped":1533,"failed":0}
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:30:45.300: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Aug  5 14:30:45.325: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:30:47.331: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Aug  5 14:30:47.338: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:30:49.342: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Aug  5 14:30:49.346: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  5 14:30:49.348: INFO: Pod pod-with-prestop-http-hook still exists
Aug  5 14:30:51.349: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  5 14:30:51.354: INFO: Pod pod-with-prestop-http-hook still exists
Aug  5 14:30:53.348: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  5 14:30:53.354: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Aug  5 14:30:53.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8874" for this suite.

â€¢ [SLOW TEST:8.064 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":356,"completed":89,"skipped":1539,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:30:53.366: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-6622
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  5 14:30:53.376: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug  5 14:30:53.389: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:30:55.394: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:30:57.396: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:30:59.394: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:31:01.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:31:03.397: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:31:05.394: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:31:07.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:31:09.393: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:31:11.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:31:13.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 14:31:15.393: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug  5 14:31:15.397: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Aug  5 14:31:17.411: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Aug  5 14:31:17.411: INFO: Breadth first check of 10.244.18.152 on host 10.1.96.4...
Aug  5 14:31:17.412: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.18.153:9080/dial?request=hostname&protocol=udp&host=10.244.18.152&port=8081&tries=1'] Namespace:pod-network-test-6622 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:31:17.412: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:31:17.413: INFO: ExecWithOptions: Clientset creation
Aug  5 14:31:17.413: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6622/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.18.153%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.18.152%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug  5 14:31:17.475: INFO: Waiting for responses: map[]
Aug  5 14:31:17.475: INFO: reached 10.244.18.152 after 0/1 tries
Aug  5 14:31:17.475: INFO: Breadth first check of 10.244.107.152 on host 10.1.96.5...
Aug  5 14:31:17.477: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.18.153:9080/dial?request=hostname&protocol=udp&host=10.244.107.152&port=8081&tries=1'] Namespace:pod-network-test-6622 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:31:17.478: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:31:17.478: INFO: ExecWithOptions: Clientset creation
Aug  5 14:31:17.478: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6622/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.18.153%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.107.152%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug  5 14:31:17.552: INFO: Waiting for responses: map[]
Aug  5 14:31:17.552: INFO: reached 10.244.107.152 after 0/1 tries
Aug  5 14:31:17.552: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Aug  5 14:31:17.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6622" for this suite.

â€¢ [SLOW TEST:24.196 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":356,"completed":90,"skipped":1547,"failed":0}
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:17.566: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Aug  5 14:31:21.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3431" for this suite.
â€¢{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":356,"completed":91,"skipped":1554,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease 
  lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:21.603: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:188
Aug  5 14:31:21.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-3926" for this suite.
â€¢{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":356,"completed":92,"skipped":1573,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:21.643: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
Aug  5 14:31:21.659: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug  5 14:31:21.659: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug  5 14:31:21.662: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug  5 14:31:21.662: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug  5 14:31:21.670: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug  5 14:31:21.671: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug  5 14:31:21.691: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug  5 14:31:21.691: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug  5 14:31:22.421: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Aug  5 14:31:22.421: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Aug  5 14:31:22.902: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
Aug  5 14:31:22.924: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 0
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:22.954: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:22.955: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:22.955: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:22.955: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:22.956: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:24.437: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:24.437: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:24.445: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
STEP: listing Deployments
Aug  5 14:31:24.448: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
Aug  5 14:31:24.456: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
Aug  5 14:31:24.460: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug  5 14:31:24.467: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug  5 14:31:24.473: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug  5 14:31:24.484: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug  5 14:31:24.490: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug  5 14:31:25.883: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug  5 14:31:25.897: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug  5 14:31:25.899: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug  5 14:31:26.920: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
Aug  5 14:31:26.943: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:26.943: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:26.943: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:26.943: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:26.943: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 1
Aug  5 14:31:26.943: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:26.944: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:26.944: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 2
Aug  5 14:31:26.944: INFO: observed Deployment test-deployment in namespace deployment-911 with ReadyReplicas 3
STEP: deleting the Deployment
Aug  5 14:31:26.948: INFO: observed event type MODIFIED
Aug  5 14:31:26.949: INFO: observed event type MODIFIED
Aug  5 14:31:26.949: INFO: observed event type MODIFIED
Aug  5 14:31:26.949: INFO: observed event type MODIFIED
Aug  5 14:31:26.949: INFO: observed event type MODIFIED
Aug  5 14:31:26.949: INFO: observed event type MODIFIED
Aug  5 14:31:26.949: INFO: observed event type MODIFIED
Aug  5 14:31:26.949: INFO: observed event type MODIFIED
Aug  5 14:31:26.949: INFO: observed event type MODIFIED
Aug  5 14:31:26.950: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug  5 14:31:26.960: INFO: Log out all the ReplicaSets if there is no deployment created
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Aug  5 14:31:26.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-911" for this suite.

â€¢ [SLOW TEST:5.342 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":356,"completed":93,"skipped":1586,"failed":0}
SSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:26.985: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:31:27.002: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-44308afa-cfea-457e-97f4-8dda50136d76" in namespace "security-context-test-3051" to be "Succeeded or Failed"
Aug  5 14:31:27.006: INFO: Pod "alpine-nnp-false-44308afa-cfea-457e-97f4-8dda50136d76": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016437ms
Aug  5 14:31:29.009: INFO: Pod "alpine-nnp-false-44308afa-cfea-457e-97f4-8dda50136d76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007207085s
Aug  5 14:31:31.015: INFO: Pod "alpine-nnp-false-44308afa-cfea-457e-97f4-8dda50136d76": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013112866s
Aug  5 14:31:33.022: INFO: Pod "alpine-nnp-false-44308afa-cfea-457e-97f4-8dda50136d76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020224755s
Aug  5 14:31:33.022: INFO: Pod "alpine-nnp-false-44308afa-cfea-457e-97f4-8dda50136d76" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Aug  5 14:31:33.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3051" for this suite.

â€¢ [SLOW TEST:6.054 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:298
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":94,"skipped":1592,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:33.040: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:31:33.062: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug  5 14:31:33.066: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:31:33.066: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched.
Aug  5 14:31:33.081: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:31:33.081: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:31:34.086: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:31:34.086: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:31:35.085: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:31:35.085: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug  5 14:31:35.097: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:31:35.097: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Aug  5 14:31:36.101: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:31:36.101: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug  5 14:31:36.109: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:31:36.109: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:31:37.114: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:31:37.115: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:31:38.113: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:31:38.113: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:31:39.113: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:31:39.113: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4607, will wait for the garbage collector to delete the pods
Aug  5 14:31:39.172: INFO: Deleting DaemonSet.extensions daemon-set took: 3.228486ms
Aug  5 14:31:39.272: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.402874ms
Aug  5 14:31:41.577: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:31:41.577: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug  5 14:31:41.579: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8427"},"items":null}

Aug  5 14:31:41.581: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8427"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Aug  5 14:31:41.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4607" for this suite.

â€¢ [SLOW TEST:8.562 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":356,"completed":95,"skipped":1608,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:41.603: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating pod
Aug  5 14:31:41.623: INFO: The status of Pod pod-hostip-36cd23b5-44c4-4106-8870-2723331db007 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:31:43.630: INFO: The status of Pod pod-hostip-36cd23b5-44c4-4106-8870-2723331db007 is Running (Ready = true)
Aug  5 14:31:43.633: INFO: Pod pod-hostip-36cd23b5-44c4-4106-8870-2723331db007 has hostIP: 10.1.96.4
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Aug  5 14:31:43.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2759" for this suite.
â€¢{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":356,"completed":96,"skipped":1683,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:43.639: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-124f78be-d70b-44da-b12e-cdd4f709f2ef
STEP: Creating a pod to test consume configMaps
Aug  5 14:31:43.659: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2fda1377-67af-4c05-a633-4a820e36a929" in namespace "projected-4090" to be "Succeeded or Failed"
Aug  5 14:31:43.660: INFO: Pod "pod-projected-configmaps-2fda1377-67af-4c05-a633-4a820e36a929": Phase="Pending", Reason="", readiness=false. Elapsed: 1.611846ms
Aug  5 14:31:45.670: INFO: Pod "pod-projected-configmaps-2fda1377-67af-4c05-a633-4a820e36a929": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011315274s
Aug  5 14:31:47.674: INFO: Pod "pod-projected-configmaps-2fda1377-67af-4c05-a633-4a820e36a929": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015373774s
STEP: Saw pod success
Aug  5 14:31:47.674: INFO: Pod "pod-projected-configmaps-2fda1377-67af-4c05-a633-4a820e36a929" satisfied condition "Succeeded or Failed"
Aug  5 14:31:47.676: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-configmaps-2fda1377-67af-4c05-a633-4a820e36a929 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 14:31:47.685: INFO: Waiting for pod pod-projected-configmaps-2fda1377-67af-4c05-a633-4a820e36a929 to disappear
Aug  5 14:31:47.687: INFO: Pod pod-projected-configmaps-2fda1377-67af-4c05-a633-4a820e36a929 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Aug  5 14:31:47.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4090" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":97,"skipped":1701,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:47.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-1c5c6d3a-4027-45be-affc-cd9b1c4469fa
STEP: Creating a pod to test consume secrets
Aug  5 14:31:47.709: INFO: Waiting up to 5m0s for pod "pod-secrets-ab2ff009-c071-4b9e-9303-871c168d7fc2" in namespace "secrets-5859" to be "Succeeded or Failed"
Aug  5 14:31:47.710: INFO: Pod "pod-secrets-ab2ff009-c071-4b9e-9303-871c168d7fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.430874ms
Aug  5 14:31:49.716: INFO: Pod "pod-secrets-ab2ff009-c071-4b9e-9303-871c168d7fc2": Phase="Running", Reason="", readiness=false. Elapsed: 2.006500468s
Aug  5 14:31:51.722: INFO: Pod "pod-secrets-ab2ff009-c071-4b9e-9303-871c168d7fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012557702s
STEP: Saw pod success
Aug  5 14:31:51.722: INFO: Pod "pod-secrets-ab2ff009-c071-4b9e-9303-871c168d7fc2" satisfied condition "Succeeded or Failed"
Aug  5 14:31:51.723: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-secrets-ab2ff009-c071-4b9e-9303-871c168d7fc2 container secret-volume-test: <nil>
STEP: delete the pod
Aug  5 14:31:51.733: INFO: Waiting for pod pod-secrets-ab2ff009-c071-4b9e-9303-871c168d7fc2 to disappear
Aug  5 14:31:51.735: INFO: Pod pod-secrets-ab2ff009-c071-4b9e-9303-871c168d7fc2 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:31:51.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5859" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":98,"skipped":1747,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:51.740: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:31:52.074: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:31:55.098: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:31:55.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7912" for this suite.
STEP: Destroying namespace "webhook-7912-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":356,"completed":99,"skipped":1781,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:55.210: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Aug  5 14:31:58.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-457" for this suite.
â€¢{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":356,"completed":100,"skipped":1798,"failed":0}
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:58.035: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:31:58.053: INFO: created pod pod-service-account-defaultsa
Aug  5 14:31:58.053: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug  5 14:31:58.055: INFO: created pod pod-service-account-mountsa
Aug  5 14:31:58.055: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug  5 14:31:58.063: INFO: created pod pod-service-account-nomountsa
Aug  5 14:31:58.063: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug  5 14:31:58.066: INFO: created pod pod-service-account-defaultsa-mountspec
Aug  5 14:31:58.066: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug  5 14:31:58.070: INFO: created pod pod-service-account-mountsa-mountspec
Aug  5 14:31:58.070: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug  5 14:31:58.072: INFO: created pod pod-service-account-nomountsa-mountspec
Aug  5 14:31:58.072: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug  5 14:31:58.075: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug  5 14:31:58.075: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug  5 14:31:58.079: INFO: created pod pod-service-account-mountsa-nomountspec
Aug  5 14:31:58.079: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug  5 14:31:58.084: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug  5 14:31:58.084: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Aug  5 14:31:58.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6160" for this suite.
â€¢{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":356,"completed":101,"skipped":1807,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:58.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:31:58.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8410 version'
Aug  5 14:31:58.223: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Aug  5 14:31:58.223: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.3\", GitCommit:\"aef86a93758dc3cb2c658dd9657ab4ad4afc21cb\", GitTreeState:\"clean\", BuildDate:\"2022-07-13T14:30:46Z\", GoVersion:\"go1.18.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.4\nServer Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.3\", GitCommit:\"aef86a93758dc3cb2c658dd9657ab4ad4afc21cb\", GitTreeState:\"clean\", BuildDate:\"2022-07-13T14:23:26Z\", GoVersion:\"go1.18.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:31:58.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8410" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":356,"completed":102,"skipped":1808,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:31:58.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6744
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6744
STEP: Waiting until pod test-pod will start running in namespace statefulset-6744
STEP: Creating statefulset with conflicting port in namespace statefulset-6744
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6744
Aug  5 14:32:00.270: INFO: Observed stateful pod in namespace: statefulset-6744, name: ss-0, uid: 68fbf247-72a3-4e83-bcaa-0d2e94d16f4e, status phase: Pending. Waiting for statefulset controller to delete.
Aug  5 14:32:00.276: INFO: Observed stateful pod in namespace: statefulset-6744, name: ss-0, uid: 68fbf247-72a3-4e83-bcaa-0d2e94d16f4e, status phase: Failed. Waiting for statefulset controller to delete.
Aug  5 14:32:00.292: INFO: Observed stateful pod in namespace: statefulset-6744, name: ss-0, uid: 68fbf247-72a3-4e83-bcaa-0d2e94d16f4e, status phase: Failed. Waiting for statefulset controller to delete.
Aug  5 14:32:00.294: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6744
STEP: Removing pod with conflicting port in namespace statefulset-6744
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6744 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug  5 14:32:02.305: INFO: Deleting all statefulset in ns statefulset-6744
Aug  5 14:32:02.307: INFO: Scaling statefulset ss to 0
Aug  5 14:32:12.325: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:32:12.327: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Aug  5 14:32:12.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6744" for this suite.

â€¢ [SLOW TEST:14.107 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":356,"completed":103,"skipped":1822,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:32:12.342: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:32:12.352: INFO: Creating deployment "webserver-deployment"
Aug  5 14:32:12.355: INFO: Waiting for observed generation 1
Aug  5 14:32:14.359: INFO: Waiting for all required pods to come up
Aug  5 14:32:14.362: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug  5 14:32:16.370: INFO: Waiting for deployment "webserver-deployment" to complete
Aug  5 14:32:16.374: INFO: Updating deployment "webserver-deployment" with a non-existent image
Aug  5 14:32:16.378: INFO: Updating deployment webserver-deployment
Aug  5 14:32:16.378: INFO: Waiting for observed generation 2
Aug  5 14:32:18.386: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug  5 14:32:18.388: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug  5 14:32:18.390: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug  5 14:32:18.394: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug  5 14:32:18.394: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug  5 14:32:18.395: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug  5 14:32:18.398: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Aug  5 14:32:18.398: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Aug  5 14:32:18.402: INFO: Updating deployment webserver-deployment
Aug  5 14:32:18.402: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Aug  5 14:32:18.405: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug  5 14:32:18.406: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug  5 14:32:20.418: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-3995  6068d84f-e02a-4a35-b9a7-7a29a1d18ca9 9329 3 2022-08-05 14:32:12 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-08-05 14:32:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:32:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004031778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-05 14:32:18 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-57ccb67bb8" is progressing.,LastUpdateTime:2022-08-05 14:32:18 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Aug  5 14:32:20.420: INFO: New ReplicaSet "webserver-deployment-57ccb67bb8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-57ccb67bb8  deployment-3995  7aa5c9e0-8026-4594-a844-58b8e3b3848e 9328 3 2022-08-05 14:32:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 6068d84f-e02a-4a35-b9a7-7a29a1d18ca9 0xc004031cb7 0xc004031cb8}] []  [{kube-controller-manager Update apps/v1 2022-08-05 14:32:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6068d84f-e02a-4a35-b9a7-7a29a1d18ca9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:32:16 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 57ccb67bb8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004031d58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug  5 14:32:20.420: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Aug  5 14:32:20.420: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-55df494869  deployment-3995  99fbdfcf-33c9-4782-8d76-e926f5105952 9323 3 2022-08-05 14:32:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 6068d84f-e02a-4a35-b9a7-7a29a1d18ca9 0xc004031bc7 0xc004031bc8}] []  [{kube-controller-manager Update apps/v1 2022-08-05 14:32:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6068d84f-e02a-4a35-b9a7-7a29a1d18ca9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:32:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004031c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Aug  5 14:32:20.424: INFO: Pod "webserver-deployment-55df494869-5j4gj" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-5j4gj webserver-deployment-55df494869- deployment-3995  9f4fc273-0d41-4c50-9174-1d5cdb2d8887 9098 0 2022-08-05 14:32:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:24e5f48dca31242807b92d6dedfb01fb2ea6c38d792951e9693f946cc2994716 cni.projectcalico.org/podIP:10.244.107.162/32 cni.projectcalico.org/podIPs:10.244.107.162/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a20e0 0xc0040a20e1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.107.162\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-82hr5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-82hr5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.5,PodIP:10.244.107.162,StartTime:2022-08-05 14:32:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:32:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://323beb37c8f867bf53c5db0f00fceae7e21747c5808ad3000e23f0b60731e8b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.107.162,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.425: INFO: Pod "webserver-deployment-55df494869-5pb8n" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-5pb8n webserver-deployment-55df494869- deployment-3995  96362764-5429-42ec-821c-04570a64d95f 9088 0 2022-08-05 14:32:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:135f30d512e351b01e5fdcd06459dd5f8cb6a9832c38dbe0641516f8d747e897 cni.projectcalico.org/podIP:10.244.107.161/32 cni.projectcalico.org/podIPs:10.244.107.161/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a22e0 0xc0040a22e1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.107.161\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hd5pn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hd5pn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.5,PodIP:10.244.107.161,StartTime:2022-08-05 14:32:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:32:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6c0fa25090bdc68c861cb7a9e1a3a024f24bd970060e9189ab88555034394e2a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.107.161,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.425: INFO: Pod "webserver-deployment-55df494869-5shjr" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-5shjr webserver-deployment-55df494869- deployment-3995  cb90a388-3f6d-4fed-bded-28bca239b071 9297 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a2540 0xc0040a2541}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-47vqr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-47vqr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.425: INFO: Pod "webserver-deployment-55df494869-cdhfd" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-cdhfd webserver-deployment-55df494869- deployment-3995  01eeb82f-591e-478a-84cc-3374b9249b46 9362 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:15c943a35b595831e2caba2b84fd7cc66402e5b006464fcbe2ef48968ec1d916 cni.projectcalico.org/podIP:10.244.18.179/32 cni.projectcalico.org/podIPs:10.244.18.179/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a26b0 0xc0040a26b1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6kh9s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6kh9s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.425: INFO: Pod "webserver-deployment-55df494869-f8f9c" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-f8f9c webserver-deployment-55df494869- deployment-3995  68ba2668-ee7b-4e11-bb5f-b8e67d8ba782 9286 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a2830 0xc0040a2831}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7gkxl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7gkxl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.425: INFO: Pod "webserver-deployment-55df494869-fkz7h" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-fkz7h webserver-deployment-55df494869- deployment-3995  5017d6a9-7ad0-4133-be40-c5e372c97319 9121 0 2022-08-05 14:32:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:0776c445971b59c182dc16db61fff3b4fceba055d8f722a8dcdfc15e1c3f1331 cni.projectcalico.org/podIP:10.244.107.164/32 cni.projectcalico.org/podIPs:10.244.107.164/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a2980 0xc0040a2981}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.107.164\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jp8f8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jp8f8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.5,PodIP:10.244.107.164,StartTime:2022-08-05 14:32:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:32:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8b0c7853ed96b91814103c270768417a4cd76a3b15e6e9af09ec6b4069a18e96,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.107.164,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.425: INFO: Pod "webserver-deployment-55df494869-fqfcp" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-fqfcp webserver-deployment-55df494869- deployment-3995  bb16d493-fa94-48ff-8eed-d74d78d4d6e1 9377 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:fa096b812cc83b398826b6149b929a4026330bc18def4be6731ff6a3d55e7724 cni.projectcalico.org/podIP:10.244.18.180/32 cni.projectcalico.org/podIPs:10.244.18.180/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a2ba0 0xc0040a2ba1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-krtrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-krtrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.425: INFO: Pod "webserver-deployment-55df494869-ftv6x" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-ftv6x webserver-deployment-55df494869- deployment-3995  ba5f2e0e-2057-4d08-816f-9260e6424b7a 9389 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:786d74be795e770d40c100702e36923e3715ab4ea0c80ba78cbdd435eede72fb cni.projectcalico.org/podIP:10.244.18.181/32 cni.projectcalico.org/podIPs:10.244.18.181/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a2d40 0xc0040a2d41}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8ddnx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8ddnx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.426: INFO: Pod "webserver-deployment-55df494869-g8vnk" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-g8vnk webserver-deployment-55df494869- deployment-3995  96b15f7b-ac32-42e2-a4de-9e9dc1827e97 9305 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a2ec0 0xc0040a2ec1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g2fwh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g2fwh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.426: INFO: Pod "webserver-deployment-55df494869-glprn" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-glprn webserver-deployment-55df494869- deployment-3995  c428b94f-8fcf-412b-853f-f9bc26851370 9112 0 2022-08-05 14:32:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:9e8e8b1838632e13c1a6b10f89888576a8d735a109854202635c38a77794872a cni.projectcalico.org/podIP:10.244.18.171/32 cni.projectcalico.org/podIPs:10.244.18.171/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a3030 0xc0040a3031}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.18.171\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qv9xk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qv9xk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:10.244.18.171,StartTime:2022-08-05 14:32:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:32:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://59f991eca503fedfb6907c81bc1119f5e9fdf41a6620457925f2a466344db486,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.18.171,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.426: INFO: Pod "webserver-deployment-55df494869-gmssb" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-gmssb webserver-deployment-55df494869- deployment-3995  bbed779c-874b-43cb-a155-5ad50723ab35 9343 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:797b1304bd257a34234a4690769e4b85a59e3d69bcbdcdb87a727a70f0413be8 cni.projectcalico.org/podIP:10.244.18.172/32 cni.projectcalico.org/podIPs:10.244.18.172/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a3250 0xc0040a3251}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q2l7b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q2l7b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.426: INFO: Pod "webserver-deployment-55df494869-gvgxk" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-gvgxk webserver-deployment-55df494869- deployment-3995  4091c0c4-b919-47f1-8498-9ef1f9bf8315 9109 0 2022-08-05 14:32:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:f58b4c34c9888b7bac4020435894a9b760e2f4096cf63ef97bc5cedfd1fb9fd4 cni.projectcalico.org/podIP:10.244.107.160/32 cni.projectcalico.org/podIPs:10.244.107.160/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a33d0 0xc0040a33d1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.107.160\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qgjvg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qgjvg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.5,PodIP:10.244.107.160,StartTime:2022-08-05 14:32:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:32:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8b50238a45386ffd32e2e9637a0740e3280cb53ee258d8099c59c545f48fa70e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.107.160,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.426: INFO: Pod "webserver-deployment-55df494869-jcjgh" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-jcjgh webserver-deployment-55df494869- deployment-3995  e990f24b-5ea0-4969-8a33-fde15e6b3dfc 9326 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a35d0 0xc0040a35d1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gqkww,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gqkww,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.5,PodIP:,StartTime:2022-08-05 14:32:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.426: INFO: Pod "webserver-deployment-55df494869-kvjsr" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-kvjsr webserver-deployment-55df494869- deployment-3995  92ec3e35-932d-4456-93b5-ab7f156553ed 9118 0 2022-08-05 14:32:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:4ac148b028ac3bf8f4c77d46cbd84edc79bea9fdd16110bf1fd0bacc93c4281e cni.projectcalico.org/podIP:10.244.18.174/32 cni.projectcalico.org/podIPs:10.244.18.174/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a37a0 0xc0040a37a1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.18.174\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-25gxr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-25gxr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:10.244.18.174,StartTime:2022-08-05 14:32:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:32:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://98c58b70f3243c8c2e7ea7c1aeded009013e7bfe3eee044f77ec52c8c419677b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.18.174,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.426: INFO: Pod "webserver-deployment-55df494869-l8lk7" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-l8lk7 webserver-deployment-55df494869- deployment-3995  2383616d-8f22-46ee-a9ed-199b9ea91920 9294 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a39a0 0xc0040a39a1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dmrqf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dmrqf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.426: INFO: Pod "webserver-deployment-55df494869-lg8z8" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-lg8z8 webserver-deployment-55df494869- deployment-3995  e2e2590e-d0aa-4df2-b3a4-0f8f81dd55e7 9347 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:d9ec1b3635602aa216e21cea7c19797698afd17eb520ddf02f740ff8c899368f cni.projectcalico.org/podIP:10.244.107.167/32 cni.projectcalico.org/podIPs:10.244.107.167/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a3af0 0xc0040a3af1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z77z4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z77z4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.426: INFO: Pod "webserver-deployment-55df494869-mbkc2" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-mbkc2 webserver-deployment-55df494869- deployment-3995  7e6b8f04-9b6e-4cad-a143-b7525b2a9690 9375 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:32ef80c5334e29915431a8e1cbb3405608327dba430a809bd0a67375808a3dab cni.projectcalico.org/podIP:10.244.18.173/32 cni.projectcalico.org/podIPs:10.244.18.173/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a3c90 0xc0040a3c91}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-whdnt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-whdnt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.427: INFO: Pod "webserver-deployment-55df494869-t5bzg" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-t5bzg webserver-deployment-55df494869- deployment-3995  eed298f3-8e5c-4dec-96a7-cd4dbe6019fb 9115 0 2022-08-05 14:32:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:3083c0e7b91a795769e3b63b1fc8d744809936a98ed2e5acf22e4619121f69b8 cni.projectcalico.org/podIP:10.244.107.163/32 cni.projectcalico.org/podIPs:10.244.107.163/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc0040a3e10 0xc0040a3e11}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.107.163\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5jj45,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5jj45,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.5,PodIP:10.244.107.163,StartTime:2022-08-05 14:32:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:32:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://490c63cd45d46ff173684e0656d63c789f63c3d94281bfd7a8bf976ffbef999b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.107.163,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.427: INFO: Pod "webserver-deployment-55df494869-tbgz2" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-tbgz2 webserver-deployment-55df494869- deployment-3995  96da824c-c545-4f5d-a053-9f5252caef6b 9102 0 2022-08-05 14:32:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:c4b07692c13e4a9d541ed2cda8c02f58d909aeaa3ee67a69648d6e947786a728 cni.projectcalico.org/podIP:10.244.18.169/32 cni.projectcalico.org/podIPs:10.244.18.169/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc00421c030 0xc00421c031}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.18.169\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9sql2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9sql2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:10.244.18.169,StartTime:2022-08-05 14:32:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:32:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://88c07661fb12c01f8a39f32d3a340543c29c00d76b636b1b0d53dcf483da393d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.18.169,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.427: INFO: Pod "webserver-deployment-55df494869-wbf9k" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-wbf9k webserver-deployment-55df494869- deployment-3995  308999d5-a5bc-45b3-ae80-917d18a48b4f 9302 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 99fbdfcf-33c9-4782-8d76-e926f5105952 0xc00421c230 0xc00421c231}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99fbdfcf-33c9-4782-8d76-e926f5105952\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xz248,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xz248,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.427: INFO: Pod "webserver-deployment-57ccb67bb8-4jvcg" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-4jvcg webserver-deployment-57ccb67bb8- deployment-3995  328aaa8a-4dd2-43f9-bc49-08f33e9c9be7 9309 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421c380 0xc00421c381}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kssst,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kssst,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.427: INFO: Pod "webserver-deployment-57ccb67bb8-5p94p" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-5p94p webserver-deployment-57ccb67bb8- deployment-3995  c7a7b5e1-bcb3-4f8d-84a3-e495fd8bc89f 9363 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:b3a983878351665676e80b89676cd957fa838fdce9881c762293543dd9adb9e5 cni.projectcalico.org/podIP:10.244.107.168/32 cni.projectcalico.org/podIPs:10.244.107.168/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421c4e0 0xc00421c4e1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fkfzh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fkfzh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.427: INFO: Pod "webserver-deployment-57ccb67bb8-7x4xb" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-7x4xb webserver-deployment-57ccb67bb8- deployment-3995  67b79170-910c-4c0e-a35e-6fa84f2897c8 9306 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421c670 0xc00421c671}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ctsrm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ctsrm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.427: INFO: Pod "webserver-deployment-57ccb67bb8-9l82m" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-9l82m webserver-deployment-57ccb67bb8- deployment-3995  6a9bb30c-c51d-4220-84cc-5534eb51a091 9384 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:37858953659b95924bac4cf5f369097b4d867385946270e840b0b3c5638cb1d5 cni.projectcalico.org/podIP:10.244.107.170/32 cni.projectcalico.org/podIPs:10.244.107.170/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421c7d0 0xc00421c7d1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rvdsx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rvdsx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.427: INFO: Pod "webserver-deployment-57ccb67bb8-ddkg6" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-ddkg6 webserver-deployment-57ccb67bb8- deployment-3995  5af9dcbb-b064-456b-a77b-7ca5dc06f913 9307 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421c960 0xc00421c961}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-87d5m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-87d5m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.427: INFO: Pod "webserver-deployment-57ccb67bb8-nc7lr" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-nc7lr webserver-deployment-57ccb67bb8- deployment-3995  92d90742-fc6a-40b1-b3e9-29c294b77579 9303 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421cac0 0xc00421cac1}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-59tdq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-59tdq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.428: INFO: Pod "webserver-deployment-57ccb67bb8-q9jqm" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-q9jqm webserver-deployment-57ccb67bb8- deployment-3995  a89f664b-a291-47f0-a0ae-43510ba2342e 9240 0 2022-08-05 14:32:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:dfd4348b36fa85358308497d6ba9af5ce38fa7697f1c09171b37f34ac5f199ce cni.projectcalico.org/podIP:10.244.107.166/32 cni.projectcalico.org/podIPs:10.244.107.166/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421cc20 0xc00421cc21}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.107.166\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fdhg2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fdhg2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.5,PodIP:10.244.107.166,StartTime:2022-08-05 14:32:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.107.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.428: INFO: Pod "webserver-deployment-57ccb67bb8-szj5k" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-szj5k webserver-deployment-57ccb67bb8- deployment-3995  eb0ece36-1da3-436a-8277-2b0a2622b77a 9237 0 2022-08-05 14:32:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:92646fc735145803b53b9dd68585e74d3f17202ea4383582412b8b198123dd0a cni.projectcalico.org/podIP:10.244.107.165/32 cni.projectcalico.org/podIPs:10.244.107.165/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421ce50 0xc00421ce51}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.107.165\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-74nfj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-74nfj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.5,PodIP:10.244.107.165,StartTime:2022-08-05 14:32:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.107.165,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.428: INFO: Pod "webserver-deployment-57ccb67bb8-td9p7" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-td9p7 webserver-deployment-57ccb67bb8- deployment-3995  06f1ab43-f1ee-4721-a8ed-2681e25f50cd 9395 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:7a4559b3b1fcb2066980134b5d5c9830f3b5fff3c4ae83c02b89851bddb7d539 cni.projectcalico.org/podIP:10.244.107.171/32 cni.projectcalico.org/podIPs:10.244.107.171/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421d080 0xc00421d081}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pt745,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pt745,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.428: INFO: Pod "webserver-deployment-57ccb67bb8-x5549" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-x5549 webserver-deployment-57ccb67bb8- deployment-3995  324c7d72-cc3d-4150-84f7-18b0be0a7d85 9246 0 2022-08-05 14:32:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:01826a3a2afe5490dceeea0bebe901ee8563ee076aa44ee28b86c220d68c8c8b cni.projectcalico.org/podIP:10.244.18.178/32 cni.projectcalico.org/podIPs:10.244.18.178/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421d230 0xc00421d231}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xm8f5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xm8f5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:,StartTime:2022-08-05 14:32:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.428: INFO: Pod "webserver-deployment-57ccb67bb8-xlj74" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-xlj74 webserver-deployment-57ccb67bb8- deployment-3995  48d7ac0f-aca5-4b60-87c6-79f9e1b2a4a2 9231 0 2022-08-05 14:32:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:9eba51a6659b93b5065b5e7814846a9d3e00c8b916c92967834ef3f707ac5a49 cni.projectcalico.org/podIP:10.244.18.176/32 cni.projectcalico.org/podIPs:10.244.18.176/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421d450 0xc00421d451}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kw5k2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kw5k2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:,StartTime:2022-08-05 14:32:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.428: INFO: Pod "webserver-deployment-57ccb67bb8-z74zd" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-z74zd webserver-deployment-57ccb67bb8- deployment-3995  b6eb5a38-f54d-4952-bdcd-c843aea1a2f7 9378 0 2022-08-05 14:32:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:aea6c14a1a34b19b508a070518948353335631ab4fe425eae5dcee402d6c45c7 cni.projectcalico.org/podIP:10.244.107.169/32 cni.projectcalico.org/podIPs:10.244.107.169/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421d650 0xc00421d651}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-05 14:32:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-08-05 14:32:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbb5r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbb5r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-b1f24d775249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.5,PodIP:,StartTime:2022-08-05 14:32:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 14:32:20.429: INFO: Pod "webserver-deployment-57ccb67bb8-zb9z5" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-zb9z5 webserver-deployment-57ccb67bb8- deployment-3995  57ab03f8-127a-4e3f-bf0f-c5e6cb3068bf 9200 0 2022-08-05 14:32:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:dc671cc90e5e6df6edcf5fd1a64d7c15c80097ce54891429e7fc812f5f666715 cni.projectcalico.org/podIP:10.244.18.177/32 cni.projectcalico.org/podIPs:10.244.18.177/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 7aa5c9e0-8026-4594-a844-58b8e3b3848e 0xc00421d870 0xc00421d871}] []  [{kube-controller-manager Update v1 2022-08-05 14:32:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7aa5c9e0-8026-4594-a844-58b8e3b3848e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:32:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:32:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sszn6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sszn6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:32:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:,StartTime:2022-08-05 14:32:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Aug  5 14:32:20.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3995" for this suite.

â€¢ [SLOW TEST:8.092 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":356,"completed":104,"skipped":1848,"failed":0}
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:32:20.434: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  5 14:32:20.469: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:32:20.469: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:32:21.496: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:32:21.496: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:32:22.476: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:32:22.476: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:32:23.475: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:32:23.475: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:32:24.479: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:32:24.479: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:32:25.478: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:32:25.478: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:32:26.477: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:32:26.477: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:32:27.476: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:32:27.476: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:32:28.475: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug  5 14:32:28.475: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Getting /status
Aug  5 14:32:28.479: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status
Aug  5 14:32:28.483: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated
Aug  5 14:32:28.485: INFO: Observed &DaemonSet event: ADDED
Aug  5 14:32:28.485: INFO: Observed &DaemonSet event: MODIFIED
Aug  5 14:32:28.485: INFO: Observed &DaemonSet event: MODIFIED
Aug  5 14:32:28.485: INFO: Observed &DaemonSet event: MODIFIED
Aug  5 14:32:28.485: INFO: Observed &DaemonSet event: MODIFIED
Aug  5 14:32:28.485: INFO: Found daemon set daemon-set in namespace daemonsets-5984 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug  5 14:32:28.485: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status
STEP: watching for the daemon set status to be patched
Aug  5 14:32:28.490: INFO: Observed &DaemonSet event: ADDED
Aug  5 14:32:28.490: INFO: Observed &DaemonSet event: MODIFIED
Aug  5 14:32:28.490: INFO: Observed &DaemonSet event: MODIFIED
Aug  5 14:32:28.490: INFO: Observed &DaemonSet event: MODIFIED
Aug  5 14:32:28.491: INFO: Observed &DaemonSet event: MODIFIED
Aug  5 14:32:28.491: INFO: Observed daemon set daemon-set in namespace daemonsets-5984 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug  5 14:32:28.491: INFO: Observed &DaemonSet event: MODIFIED
Aug  5 14:32:28.491: INFO: Found daemon set daemon-set in namespace daemonsets-5984 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Aug  5 14:32:28.491: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5984, will wait for the garbage collector to delete the pods
Aug  5 14:32:28.549: INFO: Deleting DaemonSet.extensions daemon-set took: 3.963037ms
Aug  5 14:32:28.650: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.812723ms
Aug  5 14:32:30.454: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:32:30.454: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug  5 14:32:30.456: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9853"},"items":null}

Aug  5 14:32:30.459: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9853"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Aug  5 14:32:30.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5984" for this suite.

â€¢ [SLOW TEST:10.035 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","total":356,"completed":105,"skipped":1849,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:32:30.469: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:32:30.483: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug  5 14:32:32.512: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Aug  5 14:32:33.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5563" for this suite.
â€¢{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":356,"completed":106,"skipped":1859,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:32:33.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5611
[It] should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-5611
Aug  5 14:32:33.539: INFO: Found 0 stateful pods, waiting for 1
Aug  5 14:32:43.551: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug  5 14:32:43.564: INFO: Deleting all statefulset in ns statefulset-5611
Aug  5 14:32:43.566: INFO: Scaling statefulset ss to 0
Aug  5 14:32:53.583: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:32:53.585: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Aug  5 14:32:53.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5611" for this suite.

â€¢ [SLOW TEST:20.074 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":356,"completed":107,"skipped":1871,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:32:53.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Pod
STEP: Reading file content from the nginx-container
Aug  5 14:32:55.622: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6234 PodName:pod-sharedvolume-5cefbc60-2074-4593-8866-4842381e7cdb ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:32:55.622: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:32:55.623: INFO: ExecWithOptions: Clientset creation
Aug  5 14:32:55.623: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-6234/pods/pod-sharedvolume-5cefbc60-2074-4593-8866-4842381e7cdb/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Aug  5 14:32:55.724: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 14:32:55.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6234" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":356,"completed":108,"skipped":1897,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:32:55.732: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Aug  5 14:32:55.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-946" for this suite.
â€¢{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":356,"completed":109,"skipped":1922,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:32:55.773: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 14:32:55.789: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4c8020a-9f30-43c7-8a4f-53aae8f37aaf" in namespace "projected-6547" to be "Succeeded or Failed"
Aug  5 14:32:55.790: INFO: Pod "downwardapi-volume-b4c8020a-9f30-43c7-8a4f-53aae8f37aaf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.351269ms
Aug  5 14:32:57.794: INFO: Pod "downwardapi-volume-b4c8020a-9f30-43c7-8a4f-53aae8f37aaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005378499s
Aug  5 14:32:59.800: INFO: Pod "downwardapi-volume-b4c8020a-9f30-43c7-8a4f-53aae8f37aaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011097443s
STEP: Saw pod success
Aug  5 14:32:59.800: INFO: Pod "downwardapi-volume-b4c8020a-9f30-43c7-8a4f-53aae8f37aaf" satisfied condition "Succeeded or Failed"
Aug  5 14:32:59.801: INFO: Trying to get logs from node vke-automated-test-b1f24d775249 pod downwardapi-volume-b4c8020a-9f30-43c7-8a4f-53aae8f37aaf container client-container: <nil>
STEP: delete the pod
Aug  5 14:32:59.818: INFO: Waiting for pod downwardapi-volume-b4c8020a-9f30-43c7-8a4f-53aae8f37aaf to disappear
Aug  5 14:32:59.822: INFO: Pod downwardapi-volume-b4c8020a-9f30-43c7-8a4f-53aae8f37aaf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 14:32:59.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6547" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":110,"skipped":1961,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:32:59.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 14:32:59.843: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4083e580-d6a7-499a-8505-586e2ccce389" in namespace "downward-api-387" to be "Succeeded or Failed"
Aug  5 14:32:59.844: INFO: Pod "downwardapi-volume-4083e580-d6a7-499a-8505-586e2ccce389": Phase="Pending", Reason="", readiness=false. Elapsed: 1.313578ms
Aug  5 14:33:01.851: INFO: Pod "downwardapi-volume-4083e580-d6a7-499a-8505-586e2ccce389": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008328955s
Aug  5 14:33:03.857: INFO: Pod "downwardapi-volume-4083e580-d6a7-499a-8505-586e2ccce389": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01444074s
STEP: Saw pod success
Aug  5 14:33:03.857: INFO: Pod "downwardapi-volume-4083e580-d6a7-499a-8505-586e2ccce389" satisfied condition "Succeeded or Failed"
Aug  5 14:33:03.859: INFO: Trying to get logs from node vke-automated-test-b1f24d775249 pod downwardapi-volume-4083e580-d6a7-499a-8505-586e2ccce389 container client-container: <nil>
STEP: delete the pod
Aug  5 14:33:03.867: INFO: Waiting for pod downwardapi-volume-4083e580-d6a7-499a-8505-586e2ccce389 to disappear
Aug  5 14:33:03.869: INFO: Pod downwardapi-volume-4083e580-d6a7-499a-8505-586e2ccce389 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 14:33:03.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-387" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":111,"skipped":1989,"failed":0}
SS
------------------------------
[sig-node] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:33:03.873: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod with failed condition
STEP: updating the pod
Aug  5 14:35:04.412: INFO: Successfully updated pod "var-expansion-c861764c-9b5c-44e8-8713-7eef5c3f22ad"
STEP: waiting for pod running
STEP: deleting the pod gracefully
Aug  5 14:35:06.420: INFO: Deleting pod "var-expansion-c861764c-9b5c-44e8-8713-7eef5c3f22ad" in namespace "var-expansion-15"
Aug  5 14:35:06.426: INFO: Wait up to 5m0s for pod "var-expansion-c861764c-9b5c-44e8-8713-7eef5c3f22ad" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Aug  5 14:35:38.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-15" for this suite.

â€¢ [SLOW TEST:154.572 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":356,"completed":112,"skipped":1991,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:35:38.447: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 14:35:38.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7cdc1e38-54cb-4798-8669-f6ce3807765f" in namespace "downward-api-8160" to be "Succeeded or Failed"
Aug  5 14:35:38.468: INFO: Pod "downwardapi-volume-7cdc1e38-54cb-4798-8669-f6ce3807765f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.321133ms
Aug  5 14:35:40.474: INFO: Pod "downwardapi-volume-7cdc1e38-54cb-4798-8669-f6ce3807765f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006464736s
Aug  5 14:35:42.479: INFO: Pod "downwardapi-volume-7cdc1e38-54cb-4798-8669-f6ce3807765f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011990412s
STEP: Saw pod success
Aug  5 14:35:42.479: INFO: Pod "downwardapi-volume-7cdc1e38-54cb-4798-8669-f6ce3807765f" satisfied condition "Succeeded or Failed"
Aug  5 14:35:42.481: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-7cdc1e38-54cb-4798-8669-f6ce3807765f container client-container: <nil>
STEP: delete the pod
Aug  5 14:35:42.507: INFO: Waiting for pod downwardapi-volume-7cdc1e38-54cb-4798-8669-f6ce3807765f to disappear
Aug  5 14:35:42.509: INFO: Pod downwardapi-volume-7cdc1e38-54cb-4798-8669-f6ce3807765f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 14:35:42.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8160" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":113,"skipped":2002,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:35:42.513: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Aug  5 14:35:55.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7849" for this suite.

â€¢ [SLOW TEST:13.062 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":356,"completed":114,"skipped":2025,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:35:55.576: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:35:55.593: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug  5 14:35:55.598: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:35:55.598: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:35:56.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 14:35:56.604: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 14:35:57.606: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug  5 14:35:57.606: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug  5 14:35:57.620: INFO: Wrong image for pod: daemon-set-9gfz8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug  5 14:35:57.620: INFO: Wrong image for pod: daemon-set-b69l5. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug  5 14:35:58.627: INFO: Wrong image for pod: daemon-set-9gfz8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug  5 14:35:59.627: INFO: Wrong image for pod: daemon-set-9gfz8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug  5 14:36:00.626: INFO: Wrong image for pod: daemon-set-9gfz8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug  5 14:36:00.626: INFO: Pod daemon-set-w55qs is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug  5 14:36:03.632: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug  5 14:36:03.632: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9113, will wait for the garbage collector to delete the pods
Aug  5 14:36:03.695: INFO: Deleting DaemonSet.extensions daemon-set took: 3.265682ms
Aug  5 14:36:03.796: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.059892ms
Aug  5 14:36:06.700: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 14:36:06.700: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug  5 14:36:06.701: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"10912"},"items":null}

Aug  5 14:36:06.703: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"10912"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Aug  5 14:36:06.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9113" for this suite.

â€¢ [SLOW TEST:11.136 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":356,"completed":115,"skipped":2048,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:36:06.719: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-3dc3bd59-efbe-4439-8274-95aec0f0c914
STEP: Creating a pod to test consume secrets
Aug  5 14:36:06.740: INFO: Waiting up to 5m0s for pod "pod-secrets-d884f821-d25b-4735-ba2b-c5e507c35b8c" in namespace "secrets-1676" to be "Succeeded or Failed"
Aug  5 14:36:06.742: INFO: Pod "pod-secrets-d884f821-d25b-4735-ba2b-c5e507c35b8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.353797ms
Aug  5 14:36:08.749: INFO: Pod "pod-secrets-d884f821-d25b-4735-ba2b-c5e507c35b8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009052803s
Aug  5 14:36:10.754: INFO: Pod "pod-secrets-d884f821-d25b-4735-ba2b-c5e507c35b8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014571686s
STEP: Saw pod success
Aug  5 14:36:10.754: INFO: Pod "pod-secrets-d884f821-d25b-4735-ba2b-c5e507c35b8c" satisfied condition "Succeeded or Failed"
Aug  5 14:36:10.756: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-secrets-d884f821-d25b-4735-ba2b-c5e507c35b8c container secret-env-test: <nil>
STEP: delete the pod
Aug  5 14:36:10.766: INFO: Waiting for pod pod-secrets-d884f821-d25b-4735-ba2b-c5e507c35b8c to disappear
Aug  5 14:36:10.767: INFO: Pod pod-secrets-d884f821-d25b-4735-ba2b-c5e507c35b8c no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:36:10.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1676" for this suite.
â€¢{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":356,"completed":116,"skipped":2057,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:36:10.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug  5 14:36:10.790: INFO: Waiting up to 5m0s for pod "pod-33a10ea0-6d0b-4e1d-9934-51916ad7a0bf" in namespace "emptydir-6781" to be "Succeeded or Failed"
Aug  5 14:36:10.792: INFO: Pod "pod-33a10ea0-6d0b-4e1d-9934-51916ad7a0bf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.851491ms
Aug  5 14:36:12.800: INFO: Pod "pod-33a10ea0-6d0b-4e1d-9934-51916ad7a0bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009641845s
Aug  5 14:36:14.807: INFO: Pod "pod-33a10ea0-6d0b-4e1d-9934-51916ad7a0bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016500337s
STEP: Saw pod success
Aug  5 14:36:14.807: INFO: Pod "pod-33a10ea0-6d0b-4e1d-9934-51916ad7a0bf" satisfied condition "Succeeded or Failed"
Aug  5 14:36:14.808: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-33a10ea0-6d0b-4e1d-9934-51916ad7a0bf container test-container: <nil>
STEP: delete the pod
Aug  5 14:36:14.817: INFO: Waiting for pod pod-33a10ea0-6d0b-4e1d-9934-51916ad7a0bf to disappear
Aug  5 14:36:14.819: INFO: Pod pod-33a10ea0-6d0b-4e1d-9934-51916ad7a0bf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 14:36:14.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6781" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":117,"skipped":2081,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:36:14.825: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-c3f03daf-55d1-4ada-b36d-3e6a091af7a8
STEP: Creating a pod to test consume configMaps
Aug  5 14:36:14.849: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b49d736-e914-45d4-983a-72cb689da059" in namespace "projected-8124" to be "Succeeded or Failed"
Aug  5 14:36:14.851: INFO: Pod "pod-projected-configmaps-3b49d736-e914-45d4-983a-72cb689da059": Phase="Pending", Reason="", readiness=false. Elapsed: 1.826729ms
Aug  5 14:36:16.857: INFO: Pod "pod-projected-configmaps-3b49d736-e914-45d4-983a-72cb689da059": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007684993s
Aug  5 14:36:18.861: INFO: Pod "pod-projected-configmaps-3b49d736-e914-45d4-983a-72cb689da059": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011574509s
STEP: Saw pod success
Aug  5 14:36:18.861: INFO: Pod "pod-projected-configmaps-3b49d736-e914-45d4-983a-72cb689da059" satisfied condition "Succeeded or Failed"
Aug  5 14:36:18.863: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-configmaps-3b49d736-e914-45d4-983a-72cb689da059 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 14:36:18.873: INFO: Waiting for pod pod-projected-configmaps-3b49d736-e914-45d4-983a-72cb689da059 to disappear
Aug  5 14:36:18.875: INFO: Pod pod-projected-configmaps-3b49d736-e914-45d4-983a-72cb689da059 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Aug  5 14:36:18.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8124" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":118,"skipped":2096,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:36:18.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-9883
Aug  5 14:36:18.902: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:36:20.906: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Aug  5 14:36:20.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-9883 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Aug  5 14:36:21.039: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Aug  5 14:36:21.039: INFO: stdout: "iptables"
Aug  5 14:36:21.039: INFO: proxyMode: iptables
Aug  5 14:36:21.043: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug  5 14:36:21.045: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-9883
STEP: creating replication controller affinity-clusterip-timeout in namespace services-9883
I0805 14:36:21.051645      18 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-9883, replica count: 3
I0805 14:36:24.102735      18 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 14:36:24.110: INFO: Creating new exec pod
Aug  5 14:36:27.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-9883 exec execpod-affinityxw9np -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Aug  5 14:36:27.224: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Aug  5 14:36:27.224: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 14:36:27.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-9883 exec execpod-affinityxw9np -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.102.49.98 80'
Aug  5 14:36:27.339: INFO: stderr: "+ + nc -v -t -w 2 10.102.49.98 80\necho hostName\nConnection to 10.102.49.98 80 port [tcp/http] succeeded!\n"
Aug  5 14:36:27.339: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 14:36:27.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-9883 exec execpod-affinityxw9np -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.102.49.98:80/ ; done'
Aug  5 14:36:27.514: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n"
Aug  5 14:36:27.514: INFO: stdout: "\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x\naffinity-clusterip-timeout-mnm9x"
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Received response from host: affinity-clusterip-timeout-mnm9x
Aug  5 14:36:27.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-9883 exec execpod-affinityxw9np -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.102.49.98:80/'
Aug  5 14:36:27.622: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n"
Aug  5 14:36:27.622: INFO: stdout: "affinity-clusterip-timeout-mnm9x"
Aug  5 14:36:47.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-9883 exec execpod-affinityxw9np -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.102.49.98:80/'
Aug  5 14:36:47.761: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.102.49.98:80/\n"
Aug  5 14:36:47.761: INFO: stdout: "affinity-clusterip-timeout-54684"
Aug  5 14:36:47.761: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-9883, will wait for the garbage collector to delete the pods
Aug  5 14:36:47.841: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 3.399513ms
Aug  5 14:36:47.942: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.987054ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 14:36:49.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9883" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:30.878 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":119,"skipped":2110,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:36:49.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Aug  5 14:36:49.776: INFO: Waiting up to 5m0s for pod "downward-api-9da599da-bbf2-44de-9ccc-6c48c602704d" in namespace "downward-api-6194" to be "Succeeded or Failed"
Aug  5 14:36:49.779: INFO: Pod "downward-api-9da599da-bbf2-44de-9ccc-6c48c602704d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.472198ms
Aug  5 14:36:51.787: INFO: Pod "downward-api-9da599da-bbf2-44de-9ccc-6c48c602704d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011100327s
Aug  5 14:36:53.793: INFO: Pod "downward-api-9da599da-bbf2-44de-9ccc-6c48c602704d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016586933s
STEP: Saw pod success
Aug  5 14:36:53.793: INFO: Pod "downward-api-9da599da-bbf2-44de-9ccc-6c48c602704d" satisfied condition "Succeeded or Failed"
Aug  5 14:36:53.795: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downward-api-9da599da-bbf2-44de-9ccc-6c48c602704d container dapi-container: <nil>
STEP: delete the pod
Aug  5 14:36:53.803: INFO: Waiting for pod downward-api-9da599da-bbf2-44de-9ccc-6c48c602704d to disappear
Aug  5 14:36:53.804: INFO: Pod downward-api-9da599da-bbf2-44de-9ccc-6c48c602704d no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Aug  5 14:36:53.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6194" for this suite.
â€¢{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":356,"completed":120,"skipped":2135,"failed":0}
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:36:53.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:36:53.826: INFO: created pod
Aug  5 14:36:53.826: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-8403" to be "Succeeded or Failed"
Aug  5 14:36:53.828: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.993841ms
Aug  5 14:36:55.831: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005731267s
Aug  5 14:36:57.838: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012659567s
STEP: Saw pod success
Aug  5 14:36:57.838: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Aug  5 14:37:27.838: INFO: polling logs
Aug  5 14:37:27.845: INFO: Pod logs: 
I0805 14:36:54.864617       1 log.go:195] OK: Got token
I0805 14:36:54.864651       1 log.go:195] validating with in-cluster discovery
I0805 14:36:54.865026       1 log.go:195] OK: got issuer https://kubernetes.default.svc
I0805 14:36:54.865051       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-8403:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1659710814, NotBefore:1659710214, IssuedAt:1659710214, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8403", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"b9ca77ea-e6bd-488c-b717-3bec410c267c"}}}
I0805 14:36:54.880535       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
I0805 14:36:54.885109       1 log.go:195] OK: Validated signature on JWT
I0805 14:36:54.885169       1 log.go:195] OK: Got valid claims from token!
I0805 14:36:54.885187       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-8403:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1659710814, NotBefore:1659710214, IssuedAt:1659710214, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8403", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"b9ca77ea-e6bd-488c-b717-3bec410c267c"}}}

Aug  5 14:37:27.845: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Aug  5 14:37:27.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8403" for this suite.

â€¢ [SLOW TEST:34.047 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":356,"completed":121,"skipped":2140,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:37:27.857: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1412
STEP: creating an pod
Aug  5 14:37:27.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-6184 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.39 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Aug  5 14:37:27.920: INFO: stderr: ""
Aug  5 14:37:27.920: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for log generator to start.
Aug  5 14:37:27.920: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Aug  5 14:37:27.920: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6184" to be "running and ready, or succeeded"
Aug  5 14:37:27.926: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.802269ms
Aug  5 14:37:29.931: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.011156424s
Aug  5 14:37:29.931: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Aug  5 14:37:29.931: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Aug  5 14:37:29.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-6184 logs logs-generator logs-generator'
Aug  5 14:37:29.979: INFO: stderr: ""
Aug  5 14:37:29.979: INFO: stdout: "I0805 14:37:28.663599       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/slnt 558\nI0805 14:37:28.863660       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/nqh 490\nI0805 14:37:29.064013       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/899r 395\nI0805 14:37:29.264314       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/pz8 379\nI0805 14:37:29.464626       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/mrl 359\nI0805 14:37:29.663985       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/7ch5 338\nI0805 14:37:29.864308       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tvh 536\n"
STEP: limiting log lines
Aug  5 14:37:29.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-6184 logs logs-generator logs-generator --tail=1'
Aug  5 14:37:30.028: INFO: stderr: ""
Aug  5 14:37:30.028: INFO: stdout: "I0805 14:37:29.864308       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tvh 536\n"
Aug  5 14:37:30.028: INFO: got output "I0805 14:37:29.864308       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tvh 536\n"
STEP: limiting log bytes
Aug  5 14:37:30.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-6184 logs logs-generator logs-generator --limit-bytes=1'
Aug  5 14:37:30.075: INFO: stderr: ""
Aug  5 14:37:30.075: INFO: stdout: "I"
Aug  5 14:37:30.075: INFO: got output "I"
STEP: exposing timestamps
Aug  5 14:37:30.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-6184 logs logs-generator logs-generator --tail=1 --timestamps'
Aug  5 14:37:30.123: INFO: stderr: ""
Aug  5 14:37:30.123: INFO: stdout: "2022-08-05T14:37:30.064751578Z I0805 14:37:30.064631       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/68rj 459\n"
Aug  5 14:37:30.123: INFO: got output "2022-08-05T14:37:30.064751578Z I0805 14:37:30.064631       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/68rj 459\n"
STEP: restricting to a time range
Aug  5 14:37:32.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-6184 logs logs-generator logs-generator --since=1s'
Aug  5 14:37:32.674: INFO: stderr: ""
Aug  5 14:37:32.674: INFO: stdout: "I0805 14:37:31.864371       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/pr4 405\nI0805 14:37:32.063632       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/88dg 438\nI0805 14:37:32.264007       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/nq5 416\nI0805 14:37:32.464321       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/c6h7 389\nI0805 14:37:32.664628       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/5r5 343\n"
Aug  5 14:37:32.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-6184 logs logs-generator logs-generator --since=24h'
Aug  5 14:37:32.723: INFO: stderr: ""
Aug  5 14:37:32.723: INFO: stdout: "I0805 14:37:28.663599       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/slnt 558\nI0805 14:37:28.863660       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/nqh 490\nI0805 14:37:29.064013       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/899r 395\nI0805 14:37:29.264314       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/pz8 379\nI0805 14:37:29.464626       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/mrl 359\nI0805 14:37:29.663985       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/7ch5 338\nI0805 14:37:29.864308       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tvh 536\nI0805 14:37:30.064631       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/68rj 459\nI0805 14:37:30.263928       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/sdbg 571\nI0805 14:37:30.464290       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/v5hn 329\nI0805 14:37:30.664597       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/6wwf 244\nI0805 14:37:30.863962       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/4vx 220\nI0805 14:37:31.064250       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/gwg 399\nI0805 14:37:31.264589       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/hbmr 345\nI0805 14:37:31.466310       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/zkn2 453\nI0805 14:37:31.664053       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/gk7 213\nI0805 14:37:31.864371       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/pr4 405\nI0805 14:37:32.063632       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/88dg 438\nI0805 14:37:32.264007       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/nq5 416\nI0805 14:37:32.464321       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/c6h7 389\nI0805 14:37:32.664628       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/5r5 343\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1417
Aug  5 14:37:32.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-6184 delete pod logs-generator'
Aug  5 14:37:33.426: INFO: stderr: ""
Aug  5 14:37:33.426: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:37:33.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6184" for this suite.

â€¢ [SLOW TEST:5.574 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1409
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":356,"completed":122,"skipped":2144,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:37:33.431: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1538
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
Aug  5 14:37:33.448: INFO: Found 0 stateful pods, waiting for 3
Aug  5 14:37:43.458: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:37:43.458: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:37:43.458: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:37:43.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-1538 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug  5 14:37:43.587: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug  5 14:37:43.587: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug  5 14:37:43.587: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Aug  5 14:37:53.617: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug  5 14:38:03.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-1538 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug  5 14:38:03.737: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug  5 14:38:03.737: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug  5 14:38:03.737: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Aug  5 14:38:23.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-1538 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug  5 14:38:23.876: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug  5 14:38:23.876: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug  5 14:38:23.876: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug  5 14:38:33.913: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug  5 14:38:43.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=statefulset-1538 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug  5 14:38:44.032: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug  5 14:38:44.032: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug  5 14:38:44.032: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug  5 14:38:54.050: INFO: Deleting all statefulset in ns statefulset-1538
Aug  5 14:38:54.051: INFO: Scaling statefulset ss2 to 0
Aug  5 14:39:04.065: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:39:04.067: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Aug  5 14:39:04.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1538" for this suite.

â€¢ [SLOW TEST:90.650 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":356,"completed":123,"skipped":2152,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:39:04.082: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1540
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Aug  5 14:39:04.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-4547 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2'
Aug  5 14:39:04.144: INFO: stderr: ""
Aug  5 14:39:04.145: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1544
Aug  5 14:39:04.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-4547 delete pods e2e-test-httpd-pod'
Aug  5 14:39:06.639: INFO: stderr: ""
Aug  5 14:39:06.639: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:39:06.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4547" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":356,"completed":124,"skipped":2158,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:39:06.645: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 14:39:06.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9598" for this suite.
â€¢{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":356,"completed":125,"skipped":2271,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:39:06.674: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:39:06.684: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: creating the pod
STEP: submitting the pod to kubernetes
Aug  5 14:39:06.689: INFO: The status of Pod pod-logs-websocket-0cfb6a55-f21f-45dd-bdd4-d9ff1de98da4 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:39:08.695: INFO: The status of Pod pod-logs-websocket-0cfb6a55-f21f-45dd-bdd4-d9ff1de98da4 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Aug  5 14:39:08.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7207" for this suite.
â€¢{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":356,"completed":126,"skipped":2312,"failed":0}
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:39:08.721: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:39:08.739: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug  5 14:39:13.746: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  5 14:39:13.746: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug  5 14:39:15.753: INFO: Creating deployment "test-rollover-deployment"
Aug  5 14:39:15.757: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug  5 14:39:17.762: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug  5 14:39:17.765: INFO: Ensure that both replica sets have 1 created replica
Aug  5 14:39:17.769: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug  5 14:39:17.775: INFO: Updating deployment test-rollover-deployment
Aug  5 14:39:17.775: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug  5 14:39:19.780: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug  5 14:39:19.783: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug  5 14:39:19.786: INFO: all replica sets need to contain the pod-template-hash label
Aug  5 14:39:19.786: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 39, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  5 14:39:21.795: INFO: all replica sets need to contain the pod-template-hash label
Aug  5 14:39:21.795: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 39, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  5 14:39:23.794: INFO: all replica sets need to contain the pod-template-hash label
Aug  5 14:39:23.795: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 39, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  5 14:39:25.795: INFO: all replica sets need to contain the pod-template-hash label
Aug  5 14:39:25.795: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 39, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  5 14:39:27.793: INFO: all replica sets need to contain the pod-template-hash label
Aug  5 14:39:27.793: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 39, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 39, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  5 14:39:29.792: INFO: 
Aug  5 14:39:29.792: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug  5 14:39:29.797: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-2626  0f9e1489-7a29-4906-b6b1-ac35cbe944e0 12394 2 2022-08-05 14:39:15 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-08-05 14:39:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002a00928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-05 14:39:15 +0000 UTC,LastTransitionTime:2022-08-05 14:39:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-779c67f4f8" has successfully progressed.,LastUpdateTime:2022-08-05 14:39:28 +0000 UTC,LastTransitionTime:2022-08-05 14:39:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug  5 14:39:29.799: INFO: New ReplicaSet "test-rollover-deployment-779c67f4f8" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-779c67f4f8  deployment-2626  e21f0dd9-e051-44e8-be4e-364247942df2 12384 2 2022-08-05 14:39:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 0f9e1489-7a29-4906-b6b1-ac35cbe944e0 0xc004bb0be7 0xc004bb0be8}] []  [{kube-controller-manager Update apps/v1 2022-08-05 14:39:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0f9e1489-7a29-4906-b6b1-ac35cbe944e0\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:39:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 779c67f4f8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004bb0c98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug  5 14:39:29.799: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug  5 14:39:29.799: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-2626  4f96d582-d1cf-4fe0-926b-511a6346bd16 12393 2 2022-08-05 14:39:08 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 0f9e1489-7a29-4906-b6b1-ac35cbe944e0 0xc004bb0ab7 0xc004bb0ab8}] []  [{e2e.test Update apps/v1 2022-08-05 14:39:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0f9e1489-7a29-4906-b6b1-ac35cbe944e0\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:39:28 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004bb0b78 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug  5 14:39:29.799: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-87f8f6dcf  deployment-2626  46cd0bc9-7f04-41f2-af75-b0631bad70dc 12339 2 2022-08-05 14:39:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 0f9e1489-7a29-4906-b6b1-ac35cbe944e0 0xc004bb0d00 0xc004bb0d01}] []  [{kube-controller-manager Update apps/v1 2022-08-05 14:39:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0f9e1489-7a29-4906-b6b1-ac35cbe944e0\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 14:39:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 87f8f6dcf,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004bb0da8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug  5 14:39:29.801: INFO: Pod "test-rollover-deployment-779c67f4f8-2kchc" is available:
&Pod{ObjectMeta:{test-rollover-deployment-779c67f4f8-2kchc test-rollover-deployment-779c67f4f8- deployment-2626  94f71367-c201-41a3-8d11-2051856afd9a 12354 0 2022-08-05 14:39:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[cni.projectcalico.org/containerID:6a18564289bb7909b35d456a2433d98a9d9d6aa48a4d28378826154f47e12088 cni.projectcalico.org/podIP:10.244.18.154/32 cni.projectcalico.org/podIPs:10.244.18.154/32] [{apps/v1 ReplicaSet test-rollover-deployment-779c67f4f8 e21f0dd9-e051-44e8-be4e-364247942df2 0xc002a00e37 0xc002a00e38}] []  [{kube-controller-manager Update v1 2022-08-05 14:39:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e21f0dd9-e051-44e8-be4e-364247942df2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-05 14:39:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-05 14:39:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.18.154\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5fc2x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5fc2x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:39:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:39:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:39:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 14:39:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:10.244.18.154,StartTime:2022-08-05 14:39:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 14:39:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:containerd://5fd6ba6bcc5ec0c5ad7bde5a7bf306f9becae4184efcce4de0436da2840751e7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.18.154,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Aug  5 14:39:29.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2626" for this suite.

â€¢ [SLOW TEST:21.084 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":356,"completed":127,"skipped":2317,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:39:29.806: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:39:29.819: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-d733fad7-4161-4b33-9134-86b8f7dd5264" in namespace "security-context-test-4195" to be "Succeeded or Failed"
Aug  5 14:39:29.821: INFO: Pod "busybox-readonly-false-d733fad7-4161-4b33-9134-86b8f7dd5264": Phase="Pending", Reason="", readiness=false. Elapsed: 1.769833ms
Aug  5 14:39:31.827: INFO: Pod "busybox-readonly-false-d733fad7-4161-4b33-9134-86b8f7dd5264": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008040696s
Aug  5 14:39:33.833: INFO: Pod "busybox-readonly-false-d733fad7-4161-4b33-9134-86b8f7dd5264": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014385945s
Aug  5 14:39:33.833: INFO: Pod "busybox-readonly-false-d733fad7-4161-4b33-9134-86b8f7dd5264" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Aug  5 14:39:33.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4195" for this suite.
â€¢{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":356,"completed":128,"skipped":2345,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:39:33.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Aug  5 14:39:33.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3313" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":356,"completed":129,"skipped":2369,"failed":0}
S
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces 
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:39:33.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:39:33.880: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename disruption-2
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-7654
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:188
Aug  5 14:39:39.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-5210" for this suite.
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Aug  5 14:39:39.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7654" for this suite.

â€¢ [SLOW TEST:6.076 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":356,"completed":130,"skipped":2370,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:39:39.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Aug  5 14:39:56.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7541" for this suite.

â€¢ [SLOW TEST:16.100 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":356,"completed":131,"skipped":2378,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:39:56.043: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:39:56.247: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:39:59.261: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:39:59.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:40:02.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5657" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

â€¢ [SLOW TEST:6.384 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":356,"completed":132,"skipped":2385,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:02.428: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:40:02.468: INFO: The status of Pod busybox-readonly-fs5c2410f6-6a82-4274-8f8d-8a18ea75fd2e is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:40:04.473: INFO: The status of Pod busybox-readonly-fs5c2410f6-6a82-4274-8f8d-8a18ea75fd2e is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Aug  5 14:40:04.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9365" for this suite.
â€¢{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":133,"skipped":2401,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:04.489: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:40:05.137: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:40:08.152: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:40:08.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8254" for this suite.
STEP: Destroying namespace "webhook-8254-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":356,"completed":134,"skipped":2438,"failed":0}
SS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:08.315: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Aug  5 14:40:08.369: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Aug  5 14:40:13.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7046" for this suite.

â€¢ [SLOW TEST:5.498 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":356,"completed":135,"skipped":2440,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:13.814: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:40:14.131: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:40:17.144: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Aug  5 14:40:19.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=webhook-7382 attach --namespace=webhook-7382 to-be-attached-pod -i -c=container1'
Aug  5 14:40:19.236: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:40:19.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7382" for this suite.
STEP: Destroying namespace "webhook-7382-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

â€¢ [SLOW TEST:5.445 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":356,"completed":136,"skipped":2448,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:19.260: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
Aug  5 14:40:19.316: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:40:21.323: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
Aug  5 14:40:21.330: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:40:23.336: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug  5 14:40:23.338: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8504 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:40:23.338: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:40:23.339: INFO: ExecWithOptions: Clientset creation
Aug  5 14:40:23.339: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8504/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug  5 14:40:23.404: INFO: Exec stderr: ""
Aug  5 14:40:23.405: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8504 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:40:23.405: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:40:23.405: INFO: ExecWithOptions: Clientset creation
Aug  5 14:40:23.405: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8504/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug  5 14:40:23.475: INFO: Exec stderr: ""
Aug  5 14:40:23.475: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8504 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:40:23.475: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:40:23.475: INFO: ExecWithOptions: Clientset creation
Aug  5 14:40:23.475: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8504/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug  5 14:40:23.532: INFO: Exec stderr: ""
Aug  5 14:40:23.532: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8504 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:40:23.532: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:40:23.533: INFO: ExecWithOptions: Clientset creation
Aug  5 14:40:23.533: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8504/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug  5 14:40:23.591: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug  5 14:40:23.591: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8504 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:40:23.591: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:40:23.591: INFO: ExecWithOptions: Clientset creation
Aug  5 14:40:23.591: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8504/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Aug  5 14:40:23.648: INFO: Exec stderr: ""
Aug  5 14:40:23.649: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8504 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:40:23.649: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:40:23.649: INFO: ExecWithOptions: Clientset creation
Aug  5 14:40:23.649: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8504/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Aug  5 14:40:23.709: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug  5 14:40:23.709: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8504 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:40:23.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:40:23.709: INFO: ExecWithOptions: Clientset creation
Aug  5 14:40:23.709: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8504/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug  5 14:40:23.775: INFO: Exec stderr: ""
Aug  5 14:40:23.775: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8504 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:40:23.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:40:23.775: INFO: ExecWithOptions: Clientset creation
Aug  5 14:40:23.775: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8504/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug  5 14:40:23.839: INFO: Exec stderr: ""
Aug  5 14:40:23.839: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8504 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:40:23.839: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:40:23.839: INFO: ExecWithOptions: Clientset creation
Aug  5 14:40:23.839: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8504/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug  5 14:40:23.898: INFO: Exec stderr: ""
Aug  5 14:40:23.898: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8504 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 14:40:23.898: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:40:23.899: INFO: ExecWithOptions: Clientset creation
Aug  5 14:40:23.899: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8504/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug  5 14:40:23.958: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:188
Aug  5 14:40:23.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8504" for this suite.
â€¢{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":137,"skipped":2470,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:23.973: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2708.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2708.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2708.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2708.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  5 14:40:26.024: INFO: DNS probes using dns-2708/dns-test-3f10b29c-fb42-4cb6-b587-7c3c7fd2c110 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Aug  5 14:40:26.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2708" for this suite.
â€¢{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","total":356,"completed":138,"skipped":2475,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:26.053: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Aug  5 14:40:26.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-809" for this suite.
â€¢{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":356,"completed":139,"skipped":2490,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:26.086: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4491
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-4491
STEP: creating replication controller externalsvc in namespace services-4491
I0805 14:40:26.109002      18 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4491, replica count: 2
I0805 14:40:29.159803      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Aug  5 14:40:29.174: INFO: Creating new exec pod
Aug  5 14:40:31.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-4491 exec execpod9wc46 -- /bin/sh -x -c nslookup nodeport-service.services-4491.svc.cluster.local'
Aug  5 14:40:31.310: INFO: stderr: "+ nslookup nodeport-service.services-4491.svc.cluster.local\n"
Aug  5 14:40:31.310: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-4491.svc.cluster.local\tcanonical name = externalsvc.services-4491.svc.cluster.local.\nName:\texternalsvc.services-4491.svc.cluster.local\nAddress: 10.109.154.71\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4491, will wait for the garbage collector to delete the pods
Aug  5 14:40:31.367: INFO: Deleting ReplicationController externalsvc took: 3.856047ms
Aug  5 14:40:31.471: INFO: Terminating ReplicationController externalsvc pods took: 103.98481ms
Aug  5 14:40:33.282: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 14:40:33.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4491" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:7.206 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":356,"completed":140,"skipped":2508,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:33.292: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Aug  5 14:40:35.824: INFO: Successfully updated pod "adopt-release-n9qgj"
STEP: Checking that the Job readopts the Pod
Aug  5 14:40:35.824: INFO: Waiting up to 15m0s for pod "adopt-release-n9qgj" in namespace "job-4683" to be "adopted"
Aug  5 14:40:35.826: INFO: Pod "adopt-release-n9qgj": Phase="Running", Reason="", readiness=true. Elapsed: 1.637196ms
Aug  5 14:40:37.831: INFO: Pod "adopt-release-n9qgj": Phase="Running", Reason="", readiness=true. Elapsed: 2.006846957s
Aug  5 14:40:37.831: INFO: Pod "adopt-release-n9qgj" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Aug  5 14:40:38.342: INFO: Successfully updated pod "adopt-release-n9qgj"
STEP: Checking that the Job releases the Pod
Aug  5 14:40:38.342: INFO: Waiting up to 15m0s for pod "adopt-release-n9qgj" in namespace "job-4683" to be "released"
Aug  5 14:40:38.344: INFO: Pod "adopt-release-n9qgj": Phase="Running", Reason="", readiness=true. Elapsed: 1.534753ms
Aug  5 14:40:40.350: INFO: Pod "adopt-release-n9qgj": Phase="Running", Reason="", readiness=true. Elapsed: 2.007533995s
Aug  5 14:40:40.350: INFO: Pod "adopt-release-n9qgj" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Aug  5 14:40:40.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4683" for this suite.

â€¢ [SLOW TEST:7.063 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":356,"completed":141,"skipped":2515,"failed":0}
SSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:40.357: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:188
Aug  5 14:40:40.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-752" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":356,"completed":142,"skipped":2518,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:40.378: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 14:40:40.393: INFO: Waiting up to 5m0s for pod "downwardapi-volume-62c07b92-9fa4-419e-b488-0ecef937e1a6" in namespace "projected-9836" to be "Succeeded or Failed"
Aug  5 14:40:40.395: INFO: Pod "downwardapi-volume-62c07b92-9fa4-419e-b488-0ecef937e1a6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.971658ms
Aug  5 14:40:42.401: INFO: Pod "downwardapi-volume-62c07b92-9fa4-419e-b488-0ecef937e1a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00807092s
Aug  5 14:40:44.407: INFO: Pod "downwardapi-volume-62c07b92-9fa4-419e-b488-0ecef937e1a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014224575s
STEP: Saw pod success
Aug  5 14:40:44.407: INFO: Pod "downwardapi-volume-62c07b92-9fa4-419e-b488-0ecef937e1a6" satisfied condition "Succeeded or Failed"
Aug  5 14:40:44.410: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-62c07b92-9fa4-419e-b488-0ecef937e1a6 container client-container: <nil>
STEP: delete the pod
Aug  5 14:40:44.424: INFO: Waiting for pod downwardapi-volume-62c07b92-9fa4-419e-b488-0ecef937e1a6 to disappear
Aug  5 14:40:44.425: INFO: Pod downwardapi-volume-62c07b92-9fa4-419e-b488-0ecef937e1a6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 14:40:44.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9836" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":143,"skipped":2556,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:44.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug  5 14:40:44.448: INFO: Waiting up to 5m0s for pod "pod-00772f3e-ead0-4996-8eba-d8fdc82123e6" in namespace "emptydir-7025" to be "Succeeded or Failed"
Aug  5 14:40:44.454: INFO: Pod "pod-00772f3e-ead0-4996-8eba-d8fdc82123e6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.719585ms
Aug  5 14:40:46.458: INFO: Pod "pod-00772f3e-ead0-4996-8eba-d8fdc82123e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010159822s
Aug  5 14:40:48.463: INFO: Pod "pod-00772f3e-ead0-4996-8eba-d8fdc82123e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01574702s
STEP: Saw pod success
Aug  5 14:40:48.464: INFO: Pod "pod-00772f3e-ead0-4996-8eba-d8fdc82123e6" satisfied condition "Succeeded or Failed"
Aug  5 14:40:48.465: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-00772f3e-ead0-4996-8eba-d8fdc82123e6 container test-container: <nil>
STEP: delete the pod
Aug  5 14:40:48.474: INFO: Waiting for pod pod-00772f3e-ead0-4996-8eba-d8fdc82123e6 to disappear
Aug  5 14:40:48.476: INFO: Pod pod-00772f3e-ead0-4996-8eba-d8fdc82123e6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 14:40:48.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7025" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":144,"skipped":2582,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:48.480: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  5 14:40:52.522: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Aug  5 14:40:52.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2068" for this suite.
â€¢{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":145,"skipped":2594,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:52.533: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 14:40:52.551: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c483c554-72f0-4be5-a427-6830e0ef70f1" in namespace "downward-api-4501" to be "Succeeded or Failed"
Aug  5 14:40:52.553: INFO: Pod "downwardapi-volume-c483c554-72f0-4be5-a427-6830e0ef70f1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.806573ms
Aug  5 14:40:54.559: INFO: Pod "downwardapi-volume-c483c554-72f0-4be5-a427-6830e0ef70f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008038154s
Aug  5 14:40:56.563: INFO: Pod "downwardapi-volume-c483c554-72f0-4be5-a427-6830e0ef70f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011584114s
STEP: Saw pod success
Aug  5 14:40:56.563: INFO: Pod "downwardapi-volume-c483c554-72f0-4be5-a427-6830e0ef70f1" satisfied condition "Succeeded or Failed"
Aug  5 14:40:56.565: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-c483c554-72f0-4be5-a427-6830e0ef70f1 container client-container: <nil>
STEP: delete the pod
Aug  5 14:40:56.575: INFO: Waiting for pod downwardapi-volume-c483c554-72f0-4be5-a427-6830e0ef70f1 to disappear
Aug  5 14:40:56.576: INFO: Pod downwardapi-volume-c483c554-72f0-4be5-a427-6830e0ef70f1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 14:40:56.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4501" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":146,"skipped":2602,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:40:56.581: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-88d7ac72-b7aa-4e7a-b221-c1e96f785a36
STEP: Creating a pod to test consume secrets
Aug  5 14:40:56.596: INFO: Waiting up to 5m0s for pod "pod-secrets-5ff328d7-f957-4781-b7e5-58663e24f707" in namespace "secrets-3561" to be "Succeeded or Failed"
Aug  5 14:40:56.598: INFO: Pod "pod-secrets-5ff328d7-f957-4781-b7e5-58663e24f707": Phase="Pending", Reason="", readiness=false. Elapsed: 1.391152ms
Aug  5 14:40:58.605: INFO: Pod "pod-secrets-5ff328d7-f957-4781-b7e5-58663e24f707": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008720414s
Aug  5 14:41:00.610: INFO: Pod "pod-secrets-5ff328d7-f957-4781-b7e5-58663e24f707": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013790855s
STEP: Saw pod success
Aug  5 14:41:00.610: INFO: Pod "pod-secrets-5ff328d7-f957-4781-b7e5-58663e24f707" satisfied condition "Succeeded or Failed"
Aug  5 14:41:00.612: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-secrets-5ff328d7-f957-4781-b7e5-58663e24f707 container secret-volume-test: <nil>
STEP: delete the pod
Aug  5 14:41:00.620: INFO: Waiting for pod pod-secrets-5ff328d7-f957-4781-b7e5-58663e24f707 to disappear
Aug  5 14:41:00.622: INFO: Pod pod-secrets-5ff328d7-f957-4781-b7e5-58663e24f707 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:41:00.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3561" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":147,"skipped":2627,"failed":0}
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:41:00.628: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name projected-secret-test-c3611830-6d55-43d3-a4fb-ac68b8cdb69b
STEP: Creating a pod to test consume secrets
Aug  5 14:41:00.644: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0b4bcb00-1c26-4632-9da2-7cd0b885a750" in namespace "projected-6754" to be "Succeeded or Failed"
Aug  5 14:41:00.646: INFO: Pod "pod-projected-secrets-0b4bcb00-1c26-4632-9da2-7cd0b885a750": Phase="Pending", Reason="", readiness=false. Elapsed: 1.930004ms
Aug  5 14:41:02.652: INFO: Pod "pod-projected-secrets-0b4bcb00-1c26-4632-9da2-7cd0b885a750": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008374518s
Aug  5 14:41:04.658: INFO: Pod "pod-projected-secrets-0b4bcb00-1c26-4632-9da2-7cd0b885a750": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014490439s
STEP: Saw pod success
Aug  5 14:41:04.658: INFO: Pod "pod-projected-secrets-0b4bcb00-1c26-4632-9da2-7cd0b885a750" satisfied condition "Succeeded or Failed"
Aug  5 14:41:04.660: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-secrets-0b4bcb00-1c26-4632-9da2-7cd0b885a750 container secret-volume-test: <nil>
STEP: delete the pod
Aug  5 14:41:04.670: INFO: Waiting for pod pod-projected-secrets-0b4bcb00-1c26-4632-9da2-7cd0b885a750 to disappear
Aug  5 14:41:04.672: INFO: Pod pod-projected-secrets-0b4bcb00-1c26-4632-9da2-7cd0b885a750 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Aug  5 14:41:04.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6754" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":148,"skipped":2629,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:41:04.678: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7066
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
Aug  5 14:41:04.698: INFO: Found 0 stateful pods, waiting for 3
Aug  5 14:41:14.709: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:41:14.710: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:41:14.710: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Aug  5 14:41:14.730: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug  5 14:41:24.764: INFO: Updating stateful set ss2
Aug  5 14:41:24.768: INFO: Waiting for Pod statefulset-7066/ss2-2 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
STEP: Restoring Pods to the correct revision when they are deleted
Aug  5 14:41:34.827: INFO: Found 2 stateful pods, waiting for 3
Aug  5 14:41:44.834: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:41:44.834: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  5 14:41:44.834: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug  5 14:41:44.853: INFO: Updating stateful set ss2
Aug  5 14:41:44.856: INFO: Waiting for Pod statefulset-7066/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Aug  5 14:41:54.889: INFO: Updating stateful set ss2
Aug  5 14:41:54.894: INFO: Waiting for StatefulSet statefulset-7066/ss2 to complete update
Aug  5 14:41:54.894: INFO: Waiting for Pod statefulset-7066/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug  5 14:42:04.903: INFO: Deleting all statefulset in ns statefulset-7066
Aug  5 14:42:04.904: INFO: Scaling statefulset ss2 to 0
Aug  5 14:42:14.921: INFO: Waiting for statefulset status.replicas updated to 0
Aug  5 14:42:14.923: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Aug  5 14:42:14.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7066" for this suite.

â€¢ [SLOW TEST:70.255 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":356,"completed":149,"skipped":2638,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:42:14.933: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Aug  5 14:42:54.993: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0805 14:42:54.993591      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Aug  5 14:42:54.993: INFO: Deleting pod "simpletest.rc-29nst" in namespace "gc-4543"
Aug  5 14:42:54.997: INFO: Deleting pod "simpletest.rc-2frt6" in namespace "gc-4543"
Aug  5 14:42:55.006: INFO: Deleting pod "simpletest.rc-2xwnt" in namespace "gc-4543"
Aug  5 14:42:55.036: INFO: Deleting pod "simpletest.rc-2z42m" in namespace "gc-4543"
Aug  5 14:42:55.045: INFO: Deleting pod "simpletest.rc-48f52" in namespace "gc-4543"
Aug  5 14:42:55.050: INFO: Deleting pod "simpletest.rc-5gn58" in namespace "gc-4543"
Aug  5 14:42:55.081: INFO: Deleting pod "simpletest.rc-657q4" in namespace "gc-4543"
Aug  5 14:42:55.087: INFO: Deleting pod "simpletest.rc-66qpd" in namespace "gc-4543"
Aug  5 14:42:55.096: INFO: Deleting pod "simpletest.rc-675xt" in namespace "gc-4543"
Aug  5 14:42:55.104: INFO: Deleting pod "simpletest.rc-69q79" in namespace "gc-4543"
Aug  5 14:42:55.115: INFO: Deleting pod "simpletest.rc-6dg9p" in namespace "gc-4543"
Aug  5 14:42:55.121: INFO: Deleting pod "simpletest.rc-6ltjn" in namespace "gc-4543"
Aug  5 14:42:55.125: INFO: Deleting pod "simpletest.rc-6wp9t" in namespace "gc-4543"
Aug  5 14:42:55.133: INFO: Deleting pod "simpletest.rc-7d6sr" in namespace "gc-4543"
Aug  5 14:42:55.141: INFO: Deleting pod "simpletest.rc-7g2x6" in namespace "gc-4543"
Aug  5 14:42:55.157: INFO: Deleting pod "simpletest.rc-7j4bb" in namespace "gc-4543"
Aug  5 14:42:55.188: INFO: Deleting pod "simpletest.rc-7n6mv" in namespace "gc-4543"
Aug  5 14:42:55.193: INFO: Deleting pod "simpletest.rc-82bjh" in namespace "gc-4543"
Aug  5 14:42:55.198: INFO: Deleting pod "simpletest.rc-8kl2p" in namespace "gc-4543"
Aug  5 14:42:55.203: INFO: Deleting pod "simpletest.rc-8z5d5" in namespace "gc-4543"
Aug  5 14:42:55.208: INFO: Deleting pod "simpletest.rc-94888" in namespace "gc-4543"
Aug  5 14:42:55.211: INFO: Deleting pod "simpletest.rc-94sfx" in namespace "gc-4543"
Aug  5 14:42:55.215: INFO: Deleting pod "simpletest.rc-9c5r8" in namespace "gc-4543"
Aug  5 14:42:55.218: INFO: Deleting pod "simpletest.rc-9j56q" in namespace "gc-4543"
Aug  5 14:42:55.223: INFO: Deleting pod "simpletest.rc-9mdmn" in namespace "gc-4543"
Aug  5 14:42:55.237: INFO: Deleting pod "simpletest.rc-9wv9c" in namespace "gc-4543"
Aug  5 14:42:55.285: INFO: Deleting pod "simpletest.rc-b8hzg" in namespace "gc-4543"
Aug  5 14:42:55.312: INFO: Deleting pod "simpletest.rc-b99bd" in namespace "gc-4543"
Aug  5 14:42:55.317: INFO: Deleting pod "simpletest.rc-bpcr4" in namespace "gc-4543"
Aug  5 14:42:55.321: INFO: Deleting pod "simpletest.rc-bsb6x" in namespace "gc-4543"
Aug  5 14:42:55.325: INFO: Deleting pod "simpletest.rc-c9f69" in namespace "gc-4543"
Aug  5 14:42:55.330: INFO: Deleting pod "simpletest.rc-c9xnk" in namespace "gc-4543"
Aug  5 14:42:55.339: INFO: Deleting pod "simpletest.rc-ccvmv" in namespace "gc-4543"
Aug  5 14:42:55.345: INFO: Deleting pod "simpletest.rc-ctrjw" in namespace "gc-4543"
Aug  5 14:42:55.348: INFO: Deleting pod "simpletest.rc-dcb28" in namespace "gc-4543"
Aug  5 14:42:55.398: INFO: Deleting pod "simpletest.rc-djxrb" in namespace "gc-4543"
Aug  5 14:42:55.403: INFO: Deleting pod "simpletest.rc-dklpc" in namespace "gc-4543"
Aug  5 14:42:55.407: INFO: Deleting pod "simpletest.rc-dn6sf" in namespace "gc-4543"
Aug  5 14:42:55.410: INFO: Deleting pod "simpletest.rc-ds92l" in namespace "gc-4543"
Aug  5 14:42:55.413: INFO: Deleting pod "simpletest.rc-dwv9s" in namespace "gc-4543"
Aug  5 14:42:55.418: INFO: Deleting pod "simpletest.rc-f5gdx" in namespace "gc-4543"
Aug  5 14:42:55.430: INFO: Deleting pod "simpletest.rc-f62cr" in namespace "gc-4543"
Aug  5 14:42:55.443: INFO: Deleting pod "simpletest.rc-f6lpd" in namespace "gc-4543"
Aug  5 14:42:55.449: INFO: Deleting pod "simpletest.rc-fvmdk" in namespace "gc-4543"
Aug  5 14:42:55.491: INFO: Deleting pod "simpletest.rc-fwrbt" in namespace "gc-4543"
Aug  5 14:42:55.496: INFO: Deleting pod "simpletest.rc-ggwzb" in namespace "gc-4543"
Aug  5 14:42:55.500: INFO: Deleting pod "simpletest.rc-gqmg5" in namespace "gc-4543"
Aug  5 14:42:55.505: INFO: Deleting pod "simpletest.rc-gzcx5" in namespace "gc-4543"
Aug  5 14:42:55.512: INFO: Deleting pod "simpletest.rc-h6gpx" in namespace "gc-4543"
Aug  5 14:42:55.518: INFO: Deleting pod "simpletest.rc-hb79l" in namespace "gc-4543"
Aug  5 14:42:55.522: INFO: Deleting pod "simpletest.rc-hmjpn" in namespace "gc-4543"
Aug  5 14:42:55.526: INFO: Deleting pod "simpletest.rc-hn4v6" in namespace "gc-4543"
Aug  5 14:42:55.532: INFO: Deleting pod "simpletest.rc-hvxcq" in namespace "gc-4543"
Aug  5 14:42:55.561: INFO: Deleting pod "simpletest.rc-hwgxx" in namespace "gc-4543"
Aug  5 14:42:55.567: INFO: Deleting pod "simpletest.rc-j75pv" in namespace "gc-4543"
Aug  5 14:42:55.572: INFO: Deleting pod "simpletest.rc-j774b" in namespace "gc-4543"
Aug  5 14:42:55.577: INFO: Deleting pod "simpletest.rc-jk4th" in namespace "gc-4543"
Aug  5 14:42:55.581: INFO: Deleting pod "simpletest.rc-jkzd7" in namespace "gc-4543"
Aug  5 14:42:55.584: INFO: Deleting pod "simpletest.rc-jlk84" in namespace "gc-4543"
Aug  5 14:42:55.588: INFO: Deleting pod "simpletest.rc-k2psj" in namespace "gc-4543"
Aug  5 14:42:55.592: INFO: Deleting pod "simpletest.rc-k5llr" in namespace "gc-4543"
Aug  5 14:42:55.640: INFO: Deleting pod "simpletest.rc-kg28r" in namespace "gc-4543"
Aug  5 14:42:55.679: INFO: Deleting pod "simpletest.rc-kwbxw" in namespace "gc-4543"
Aug  5 14:42:55.733: INFO: Deleting pod "simpletest.rc-m4bj4" in namespace "gc-4543"
Aug  5 14:42:55.796: INFO: Deleting pod "simpletest.rc-mclll" in namespace "gc-4543"
Aug  5 14:42:55.833: INFO: Deleting pod "simpletest.rc-mctx8" in namespace "gc-4543"
Aug  5 14:42:55.946: INFO: Deleting pod "simpletest.rc-mzsg9" in namespace "gc-4543"
Aug  5 14:42:56.006: INFO: Deleting pod "simpletest.rc-mzz8d" in namespace "gc-4543"
Aug  5 14:42:56.032: INFO: Deleting pod "simpletest.rc-ndnfl" in namespace "gc-4543"
Aug  5 14:42:56.037: INFO: Deleting pod "simpletest.rc-nkb9l" in namespace "gc-4543"
Aug  5 14:42:56.090: INFO: Deleting pod "simpletest.rc-nl6vk" in namespace "gc-4543"
Aug  5 14:42:56.129: INFO: Deleting pod "simpletest.rc-nndqs" in namespace "gc-4543"
Aug  5 14:42:56.180: INFO: Deleting pod "simpletest.rc-nngbj" in namespace "gc-4543"
Aug  5 14:42:56.233: INFO: Deleting pod "simpletest.rc-nq7dm" in namespace "gc-4543"
Aug  5 14:42:56.280: INFO: Deleting pod "simpletest.rc-nwz59" in namespace "gc-4543"
Aug  5 14:42:56.341: INFO: Deleting pod "simpletest.rc-p9llt" in namespace "gc-4543"
Aug  5 14:42:56.388: INFO: Deleting pod "simpletest.rc-pl6q8" in namespace "gc-4543"
Aug  5 14:42:56.429: INFO: Deleting pod "simpletest.rc-pqvrt" in namespace "gc-4543"
Aug  5 14:42:56.479: INFO: Deleting pod "simpletest.rc-q25kj" in namespace "gc-4543"
Aug  5 14:42:56.530: INFO: Deleting pod "simpletest.rc-qn6zn" in namespace "gc-4543"
Aug  5 14:42:56.593: INFO: Deleting pod "simpletest.rc-qppp8" in namespace "gc-4543"
Aug  5 14:42:56.638: INFO: Deleting pod "simpletest.rc-qpzdn" in namespace "gc-4543"
Aug  5 14:42:56.680: INFO: Deleting pod "simpletest.rc-qxc5c" in namespace "gc-4543"
Aug  5 14:42:56.729: INFO: Deleting pod "simpletest.rc-qzl78" in namespace "gc-4543"
Aug  5 14:42:56.799: INFO: Deleting pod "simpletest.rc-s467b" in namespace "gc-4543"
Aug  5 14:42:56.836: INFO: Deleting pod "simpletest.rc-sdfzn" in namespace "gc-4543"
Aug  5 14:42:56.895: INFO: Deleting pod "simpletest.rc-sfvbc" in namespace "gc-4543"
Aug  5 14:42:56.929: INFO: Deleting pod "simpletest.rc-sl84k" in namespace "gc-4543"
Aug  5 14:42:56.980: INFO: Deleting pod "simpletest.rc-v8bcl" in namespace "gc-4543"
Aug  5 14:42:57.029: INFO: Deleting pod "simpletest.rc-w6b6d" in namespace "gc-4543"
Aug  5 14:42:57.079: INFO: Deleting pod "simpletest.rc-w86nc" in namespace "gc-4543"
Aug  5 14:42:57.129: INFO: Deleting pod "simpletest.rc-w8rl6" in namespace "gc-4543"
Aug  5 14:42:57.179: INFO: Deleting pod "simpletest.rc-wwjn5" in namespace "gc-4543"
Aug  5 14:42:57.229: INFO: Deleting pod "simpletest.rc-xcn8b" in namespace "gc-4543"
Aug  5 14:42:57.290: INFO: Deleting pod "simpletest.rc-xh2jm" in namespace "gc-4543"
Aug  5 14:42:57.329: INFO: Deleting pod "simpletest.rc-xxgqd" in namespace "gc-4543"
Aug  5 14:42:57.390: INFO: Deleting pod "simpletest.rc-z6jtm" in namespace "gc-4543"
Aug  5 14:42:57.430: INFO: Deleting pod "simpletest.rc-zkwsb" in namespace "gc-4543"
Aug  5 14:42:57.480: INFO: Deleting pod "simpletest.rc-zm6tx" in namespace "gc-4543"
Aug  5 14:42:57.536: INFO: Deleting pod "simpletest.rc-zstdp" in namespace "gc-4543"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Aug  5 14:42:57.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4543" for this suite.

â€¢ [SLOW TEST:42.744 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":356,"completed":150,"skipped":2649,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:42:57.679: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Aug  5 14:42:57.745: INFO: The status of Pod annotationupdate8841c68b-3929-4719-85ec-5039ed6132bb is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:42:59.750: INFO: The status of Pod annotationupdate8841c68b-3929-4719-85ec-5039ed6132bb is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:43:01.751: INFO: The status of Pod annotationupdate8841c68b-3929-4719-85ec-5039ed6132bb is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:43:03.754: INFO: The status of Pod annotationupdate8841c68b-3929-4719-85ec-5039ed6132bb is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:43:05.752: INFO: The status of Pod annotationupdate8841c68b-3929-4719-85ec-5039ed6132bb is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:43:07.750: INFO: The status of Pod annotationupdate8841c68b-3929-4719-85ec-5039ed6132bb is Running (Ready = true)
Aug  5 14:43:08.281: INFO: Successfully updated pod "annotationupdate8841c68b-3929-4719-85ec-5039ed6132bb"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 14:43:10.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3997" for this suite.

â€¢ [SLOW TEST:12.627 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":151,"skipped":2650,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:43:10.306: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Aug  5 14:43:10.320: INFO: The status of Pod annotationupdatec7b6e6a9-f01d-4c33-aceb-e460d5250142 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:43:12.326: INFO: The status of Pod annotationupdatec7b6e6a9-f01d-4c33-aceb-e460d5250142 is Running (Ready = true)
Aug  5 14:43:12.842: INFO: Successfully updated pod "annotationupdatec7b6e6a9-f01d-4c33-aceb-e460d5250142"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 14:43:14.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4780" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":152,"skipped":2658,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:43:14.857: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:79
Aug  5 14:43:14.869: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the sample API server.
Aug  5 14:43:15.483: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug  5 14:43:17.509: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  5 14:43:19.515: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  5 14:43:21.527: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 43, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  5 14:43:24.441: INFO: Waited 922.471341ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
Aug  5 14:43:24.488: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:69
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:188
Aug  5 14:43:24.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9238" for this suite.

â€¢ [SLOW TEST:10.218 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":356,"completed":153,"skipped":2663,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:43:25.079: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-f1ae3603-5ec0-48e2-acfb-30873196eda7
STEP: Creating a pod to test consume configMaps
Aug  5 14:43:25.098: INFO: Waiting up to 5m0s for pod "pod-configmaps-3a35125d-7fb9-47ea-b5eb-9bb34c8c3b67" in namespace "configmap-5923" to be "Succeeded or Failed"
Aug  5 14:43:25.100: INFO: Pod "pod-configmaps-3a35125d-7fb9-47ea-b5eb-9bb34c8c3b67": Phase="Pending", Reason="", readiness=false. Elapsed: 1.543461ms
Aug  5 14:43:27.103: INFO: Pod "pod-configmaps-3a35125d-7fb9-47ea-b5eb-9bb34c8c3b67": Phase="Running", Reason="", readiness=false. Elapsed: 2.005042478s
Aug  5 14:43:29.109: INFO: Pod "pod-configmaps-3a35125d-7fb9-47ea-b5eb-9bb34c8c3b67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011100374s
STEP: Saw pod success
Aug  5 14:43:29.109: INFO: Pod "pod-configmaps-3a35125d-7fb9-47ea-b5eb-9bb34c8c3b67" satisfied condition "Succeeded or Failed"
Aug  5 14:43:29.111: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-configmaps-3a35125d-7fb9-47ea-b5eb-9bb34c8c3b67 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 14:43:29.120: INFO: Waiting for pod pod-configmaps-3a35125d-7fb9-47ea-b5eb-9bb34c8c3b67 to disappear
Aug  5 14:43:29.121: INFO: Pod pod-configmaps-3a35125d-7fb9-47ea-b5eb-9bb34c8c3b67 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 14:43:29.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5923" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":154,"skipped":2750,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:43:29.125: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Aug  5 14:43:29.140: INFO: The status of Pod labelsupdate56d50443-9321-4f58-b25c-eef983536378 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:43:31.147: INFO: The status of Pod labelsupdate56d50443-9321-4f58-b25c-eef983536378 is Running (Ready = true)
Aug  5 14:43:31.663: INFO: Successfully updated pod "labelsupdate56d50443-9321-4f58-b25c-eef983536378"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 14:43:35.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4111" for this suite.

â€¢ [SLOW TEST:6.566 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":155,"skipped":2764,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:43:35.692: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Aug  5 14:43:35.704: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Aug  5 14:43:45.418: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 14:43:48.431: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:43:57.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-818" for this suite.

â€¢ [SLOW TEST:21.749 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":356,"completed":156,"skipped":2777,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints 
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:43:57.441: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug  5 14:43:57.460: INFO: Waiting up to 1m0s for all nodes to be ready
Aug  5 14:44:57.479: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:44:57.481: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:44:57.500: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: Value: Forbidden: may not be changed in an update.
Aug  5 14:44:57.502: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: Value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:188
Aug  5 14:44:57.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-266" for this suite.
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Aug  5 14:44:57.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-311" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

â€¢ [SLOW TEST:60.097 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","total":356,"completed":157,"skipped":2792,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:44:57.540: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
STEP: create deployment with httpd image
Aug  5 14:44:57.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-7485 create -f -'
Aug  5 14:44:57.987: INFO: stderr: ""
Aug  5 14:44:57.987: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
Aug  5 14:44:57.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-7485 diff -f -'
Aug  5 14:44:58.129: INFO: rc: 1
Aug  5 14:44:58.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-7485 delete -f -'
Aug  5 14:44:58.184: INFO: stderr: ""
Aug  5 14:44:58.184: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:44:58.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7485" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":356,"completed":158,"skipped":2811,"failed":0}
SSSSSSS
------------------------------
[sig-node] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:44:58.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name secret-emptykey-test-bf60b0ce-f450-4e25-a567-cc212d6774f8
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:44:58.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6840" for this suite.
â€¢{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":356,"completed":159,"skipped":2818,"failed":0}
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:44:58.215: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Aug  5 14:45:04.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-790" for this suite.
STEP: Destroying namespace "nsdeletetest-8702" for this suite.
Aug  5 14:45:04.262: INFO: Namespace nsdeletetest-8702 was already deleted
STEP: Destroying namespace "nsdeletetest-5757" for this suite.

â€¢ [SLOW TEST:6.049 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":356,"completed":160,"skipped":2819,"failed":0}
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:45:04.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-0b7a8fec-e307-4cb6-9e46-d3f95f92f87f
STEP: Creating secret with name s-test-opt-upd-cc93dfd9-c6bc-431d-a760-fc3ea54f6a4c
STEP: Creating the pod
Aug  5 14:45:04.285: INFO: The status of Pod pod-secrets-6300a5c9-3b9d-4487-89f5-2b2f3227f354 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:45:06.291: INFO: The status of Pod pod-secrets-6300a5c9-3b9d-4487-89f5-2b2f3227f354 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:45:08.291: INFO: The status of Pod pod-secrets-6300a5c9-3b9d-4487-89f5-2b2f3227f354 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-0b7a8fec-e307-4cb6-9e46-d3f95f92f87f
STEP: Updating secret s-test-opt-upd-cc93dfd9-c6bc-431d-a760-fc3ea54f6a4c
STEP: Creating secret with name s-test-opt-create-f433fb3c-218a-420a-84aa-746db1a9ef94
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:46:24.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1420" for this suite.

â€¢ [SLOW TEST:80.358 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":161,"skipped":2825,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:46:24.623: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5771.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5771.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5771.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5771.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5771.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5771.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5771.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5771.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5771.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5771.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 0.86.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.86.0_udp@PTR;check="$$(dig +tcp +noall +answer +search 0.86.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.86.0_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5771.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5771.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5771.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5771.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5771.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5771.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5771.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5771.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5771.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5771.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 0.86.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.86.0_udp@PTR;check="$$(dig +tcp +noall +answer +search 0.86.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.86.0_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  5 14:46:26.664: INFO: Unable to read wheezy_udp@dns-test-service.dns-5771.svc.cluster.local from pod dns-5771/dns-test-68604f92-1303-4a27-a52d-b76d97189eb9: the server could not find the requested resource (get pods dns-test-68604f92-1303-4a27-a52d-b76d97189eb9)
Aug  5 14:46:26.667: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5771.svc.cluster.local from pod dns-5771/dns-test-68604f92-1303-4a27-a52d-b76d97189eb9: the server could not find the requested resource (get pods dns-test-68604f92-1303-4a27-a52d-b76d97189eb9)
Aug  5 14:46:26.669: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local from pod dns-5771/dns-test-68604f92-1303-4a27-a52d-b76d97189eb9: the server could not find the requested resource (get pods dns-test-68604f92-1303-4a27-a52d-b76d97189eb9)
Aug  5 14:46:26.671: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local from pod dns-5771/dns-test-68604f92-1303-4a27-a52d-b76d97189eb9: the server could not find the requested resource (get pods dns-test-68604f92-1303-4a27-a52d-b76d97189eb9)
Aug  5 14:46:26.681: INFO: Unable to read jessie_udp@dns-test-service.dns-5771.svc.cluster.local from pod dns-5771/dns-test-68604f92-1303-4a27-a52d-b76d97189eb9: the server could not find the requested resource (get pods dns-test-68604f92-1303-4a27-a52d-b76d97189eb9)
Aug  5 14:46:26.683: INFO: Unable to read jessie_tcp@dns-test-service.dns-5771.svc.cluster.local from pod dns-5771/dns-test-68604f92-1303-4a27-a52d-b76d97189eb9: the server could not find the requested resource (get pods dns-test-68604f92-1303-4a27-a52d-b76d97189eb9)
Aug  5 14:46:26.685: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local from pod dns-5771/dns-test-68604f92-1303-4a27-a52d-b76d97189eb9: the server could not find the requested resource (get pods dns-test-68604f92-1303-4a27-a52d-b76d97189eb9)
Aug  5 14:46:26.687: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local from pod dns-5771/dns-test-68604f92-1303-4a27-a52d-b76d97189eb9: the server could not find the requested resource (get pods dns-test-68604f92-1303-4a27-a52d-b76d97189eb9)
Aug  5 14:46:26.695: INFO: Lookups using dns-5771/dns-test-68604f92-1303-4a27-a52d-b76d97189eb9 failed for: [wheezy_udp@dns-test-service.dns-5771.svc.cluster.local wheezy_tcp@dns-test-service.dns-5771.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local jessie_udp@dns-test-service.dns-5771.svc.cluster.local jessie_tcp@dns-test-service.dns-5771.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5771.svc.cluster.local]

Aug  5 14:46:31.735: INFO: DNS probes using dns-5771/dns-test-68604f92-1303-4a27-a52d-b76d97189eb9 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Aug  5 14:46:31.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5771" for this suite.

â€¢ [SLOW TEST:7.175 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":356,"completed":162,"skipped":2858,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:46:31.799: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-a9ae62d7-bb7f-4dbd-917a-77ec0abbe1f7 in namespace container-probe-2819
Aug  5 14:46:33.821: INFO: Started pod liveness-a9ae62d7-bb7f-4dbd-917a-77ec0abbe1f7 in namespace container-probe-2819
STEP: checking the pod's current state and verifying that restartCount is present
Aug  5 14:46:33.823: INFO: Initial restart count of pod liveness-a9ae62d7-bb7f-4dbd-917a-77ec0abbe1f7 is 0
Aug  5 14:46:53.879: INFO: Restart count of pod container-probe-2819/liveness-a9ae62d7-bb7f-4dbd-917a-77ec0abbe1f7 is now 1 (20.056140758s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Aug  5 14:46:53.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2819" for this suite.

â€¢ [SLOW TEST:22.097 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":163,"skipped":2920,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:46:53.909: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-572d2d13-0303-4cd4-a51b-a66d624ed765 in namespace container-probe-5110
Aug  5 14:46:55.934: INFO: Started pod liveness-572d2d13-0303-4cd4-a51b-a66d624ed765 in namespace container-probe-5110
STEP: checking the pod's current state and verifying that restartCount is present
Aug  5 14:46:55.936: INFO: Initial restart count of pod liveness-572d2d13-0303-4cd4-a51b-a66d624ed765 is 0
Aug  5 14:47:15.985: INFO: Restart count of pod container-probe-5110/liveness-572d2d13-0303-4cd4-a51b-a66d624ed765 is now 1 (20.048864259s elapsed)
Aug  5 14:47:36.034: INFO: Restart count of pod container-probe-5110/liveness-572d2d13-0303-4cd4-a51b-a66d624ed765 is now 2 (40.098172922s elapsed)
Aug  5 14:47:56.084: INFO: Restart count of pod container-probe-5110/liveness-572d2d13-0303-4cd4-a51b-a66d624ed765 is now 3 (1m0.147481359s elapsed)
Aug  5 14:48:16.140: INFO: Restart count of pod container-probe-5110/liveness-572d2d13-0303-4cd4-a51b-a66d624ed765 is now 4 (1m20.204074399s elapsed)
Aug  5 14:49:18.331: INFO: Restart count of pod container-probe-5110/liveness-572d2d13-0303-4cd4-a51b-a66d624ed765 is now 5 (2m22.39449719s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Aug  5 14:49:18.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5110" for this suite.

â€¢ [SLOW TEST:144.436 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":356,"completed":164,"skipped":2986,"failed":0}
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:49:18.357: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6721 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6721;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6721 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6721;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6721.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6721.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6721.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6721.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6721.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6721.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6721.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6721.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6721.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6721.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6721.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6721.svc;check="$$(dig +notcp +noall +answer +search 62.62.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.62.62_udp@PTR;check="$$(dig +tcp +noall +answer +search 62.62.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.62.62_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6721 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6721;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6721 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6721;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6721.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6721.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6721.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6721.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6721.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6721.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6721.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6721.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6721.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6721.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6721.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6721.svc;check="$$(dig +notcp +noall +answer +search 62.62.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.62.62_udp@PTR;check="$$(dig +tcp +noall +answer +search 62.62.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.62.62_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  5 14:49:20.399: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.401: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.403: INFO: Unable to read wheezy_udp@dns-test-service.dns-6721 from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.406: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6721 from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.408: INFO: Unable to read wheezy_udp@dns-test-service.dns-6721.svc from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.410: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6721.svc from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.412: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6721.svc from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.415: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6721.svc from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.430: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.432: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.435: INFO: Unable to read jessie_udp@dns-test-service.dns-6721 from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.438: INFO: Unable to read jessie_tcp@dns-test-service.dns-6721 from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.441: INFO: Unable to read jessie_udp@dns-test-service.dns-6721.svc from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.444: INFO: Unable to read jessie_tcp@dns-test-service.dns-6721.svc from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.446: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6721.svc from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.449: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6721.svc from pod dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad: the server could not find the requested resource (get pods dns-test-0d84d482-8324-4410-a8a0-687bc8115aad)
Aug  5 14:49:20.459: INFO: Lookups using dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6721 wheezy_tcp@dns-test-service.dns-6721 wheezy_udp@dns-test-service.dns-6721.svc wheezy_tcp@dns-test-service.dns-6721.svc wheezy_udp@_http._tcp.dns-test-service.dns-6721.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6721.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6721 jessie_tcp@dns-test-service.dns-6721 jessie_udp@dns-test-service.dns-6721.svc jessie_tcp@dns-test-service.dns-6721.svc jessie_udp@_http._tcp.dns-test-service.dns-6721.svc jessie_tcp@_http._tcp.dns-test-service.dns-6721.svc]

Aug  5 14:49:25.521: INFO: DNS probes using dns-6721/dns-test-0d84d482-8324-4410-a8a0-687bc8115aad succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Aug  5 14:49:25.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6721" for this suite.

â€¢ [SLOW TEST:7.221 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":356,"completed":165,"skipped":2986,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:49:25.579: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pod templates
Aug  5 14:49:25.621: INFO: created test-podtemplate-1
Aug  5 14:49:25.623: INFO: created test-podtemplate-2
Aug  5 14:49:25.625: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
Aug  5 14:49:25.627: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
Aug  5 14:49:25.633: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Aug  5 14:49:25.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-8191" for this suite.
â€¢{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":356,"completed":166,"skipped":2995,"failed":0}

------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:49:25.640: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
Aug  5 14:49:25.659: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
Aug  5 14:49:25.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1608" for this suite.
â€¢{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":356,"completed":167,"skipped":2995,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:49:25.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug  5 14:49:25.695: INFO: Waiting up to 5m0s for pod "pod-ca549546-637c-4949-9ce0-20b5184b229f" in namespace "emptydir-2580" to be "Succeeded or Failed"
Aug  5 14:49:25.697: INFO: Pod "pod-ca549546-637c-4949-9ce0-20b5184b229f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.900548ms
Aug  5 14:49:27.707: INFO: Pod "pod-ca549546-637c-4949-9ce0-20b5184b229f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011855053s
Aug  5 14:49:29.711: INFO: Pod "pod-ca549546-637c-4949-9ce0-20b5184b229f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01614997s
STEP: Saw pod success
Aug  5 14:49:29.711: INFO: Pod "pod-ca549546-637c-4949-9ce0-20b5184b229f" satisfied condition "Succeeded or Failed"
Aug  5 14:49:29.713: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-ca549546-637c-4949-9ce0-20b5184b229f container test-container: <nil>
STEP: delete the pod
Aug  5 14:49:29.731: INFO: Waiting for pod pod-ca549546-637c-4949-9ce0-20b5184b229f to disappear
Aug  5 14:49:29.733: INFO: Pod pod-ca549546-637c-4949-9ce0-20b5184b229f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 14:49:29.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2580" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":168,"skipped":3031,"failed":0}

------------------------------
[sig-apps] CronJob 
  should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:49:29.738: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug  5 14:49:29.756: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Aug  5 14:49:29.758: INFO: starting watch
STEP: patching
STEP: updating
Aug  5 14:49:29.774: INFO: waiting for watch events with expected annotations
Aug  5 14:49:29.774: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Aug  5 14:49:29.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-8595" for this suite.
â€¢{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":356,"completed":169,"skipped":3031,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:49:29.801: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption is created
Aug  5 14:49:29.814: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:49:31.821: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Aug  5 14:49:32.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2487" for this suite.
â€¢{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":356,"completed":170,"skipped":3043,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:49:32.837: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug  5 14:49:32.854: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8291  604dc1c2-9e57-45da-8da0-eb8d4c71accc 18166 0 2022-08-05 14:49:32 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-08-05 14:49:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 14:49:32.855: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8291  604dc1c2-9e57-45da-8da0-eb8d4c71accc 18167 0 2022-08-05 14:49:32 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-08-05 14:49:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug  5 14:49:32.861: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8291  604dc1c2-9e57-45da-8da0-eb8d4c71accc 18168 0 2022-08-05 14:49:32 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-08-05 14:49:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 14:49:32.861: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8291  604dc1c2-9e57-45da-8da0-eb8d4c71accc 18169 0 2022-08-05 14:49:32 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-08-05 14:49:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Aug  5 14:49:32.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8291" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":356,"completed":171,"skipped":3044,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:49:32.866: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-6006
Aug  5 14:49:32.884: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:49:34.890: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Aug  5 14:49:34.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6006 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Aug  5 14:49:35.010: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Aug  5 14:49:35.010: INFO: stdout: "iptables"
Aug  5 14:49:35.010: INFO: proxyMode: iptables
Aug  5 14:49:35.015: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug  5 14:49:35.017: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-6006
STEP: creating replication controller affinity-nodeport-timeout in namespace services-6006
I0805 14:49:35.027107      18 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-6006, replica count: 3
I0805 14:49:38.077719      18 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 14:49:38.087: INFO: Creating new exec pod
Aug  5 14:49:41.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6006 exec execpod-affinityks5c7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Aug  5 14:49:41.207: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Aug  5 14:49:41.207: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 14:49:41.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6006 exec execpod-affinityks5c7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.111.241.137 80'
Aug  5 14:49:41.332: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.111.241.137 80\nConnection to 10.111.241.137 80 port [tcp/http] succeeded!\n"
Aug  5 14:49:41.332: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 14:49:41.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6006 exec execpod-affinityks5c7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.4 30835'
Aug  5 14:49:41.522: INFO: stderr: "+ nc -v -t -w 2 10.1.96.4 30835\nConnection to 10.1.96.4 30835 port [tcp/*] succeeded!\n+ echo hostName\n"
Aug  5 14:49:41.522: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 14:49:41.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6006 exec execpod-affinityks5c7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.5 30835'
Aug  5 14:49:41.654: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.96.5 30835\nConnection to 10.1.96.5 30835 port [tcp/*] succeeded!\n"
Aug  5 14:49:41.654: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 14:49:41.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6006 exec execpod-affinityks5c7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.96.4:30835/ ; done'
Aug  5 14:49:41.818: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n"
Aug  5 14:49:41.818: INFO: stdout: "\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w\naffinity-nodeport-timeout-6bh9w"
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Received response from host: affinity-nodeport-timeout-6bh9w
Aug  5 14:49:41.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6006 exec execpod-affinityks5c7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.1.96.4:30835/'
Aug  5 14:49:41.926: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n"
Aug  5 14:49:41.926: INFO: stdout: "affinity-nodeport-timeout-6bh9w"
Aug  5 14:50:01.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6006 exec execpod-affinityks5c7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.1.96.4:30835/'
Aug  5 14:50:02.031: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n"
Aug  5 14:50:02.031: INFO: stdout: "affinity-nodeport-timeout-6bh9w"
Aug  5 14:50:22.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-6006 exec execpod-affinityks5c7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.1.96.4:30835/'
Aug  5 14:50:22.152: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.1.96.4:30835/\n"
Aug  5 14:50:22.152: INFO: stdout: "affinity-nodeport-timeout-thbvm"
Aug  5 14:50:22.153: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-6006, will wait for the garbage collector to delete the pods
Aug  5 14:50:22.222: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 4.093435ms
Aug  5 14:50:22.322: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.67356ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 14:50:24.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6006" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:51.273 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":172,"skipped":3076,"failed":0}
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:50:24.140: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Aug  5 14:50:24.157: INFO: Waiting up to 5m0s for pod "downward-api-b4600870-5a1d-4ca5-9127-c9c74c1b6375" in namespace "downward-api-7771" to be "Succeeded or Failed"
Aug  5 14:50:24.159: INFO: Pod "downward-api-b4600870-5a1d-4ca5-9127-c9c74c1b6375": Phase="Pending", Reason="", readiness=false. Elapsed: 1.798889ms
Aug  5 14:50:26.165: INFO: Pod "downward-api-b4600870-5a1d-4ca5-9127-c9c74c1b6375": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007131146s
Aug  5 14:50:28.170: INFO: Pod "downward-api-b4600870-5a1d-4ca5-9127-c9c74c1b6375": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01218682s
STEP: Saw pod success
Aug  5 14:50:28.170: INFO: Pod "downward-api-b4600870-5a1d-4ca5-9127-c9c74c1b6375" satisfied condition "Succeeded or Failed"
Aug  5 14:50:28.172: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downward-api-b4600870-5a1d-4ca5-9127-c9c74c1b6375 container dapi-container: <nil>
STEP: delete the pod
Aug  5 14:50:28.182: INFO: Waiting for pod downward-api-b4600870-5a1d-4ca5-9127-c9c74c1b6375 to disappear
Aug  5 14:50:28.184: INFO: Pod downward-api-b4600870-5a1d-4ca5-9127-c9c74c1b6375 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Aug  5 14:50:28.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7771" for this suite.
â€¢{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":356,"completed":173,"skipped":3076,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:50:28.191: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:50:28.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4701" for this suite.
â€¢{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":356,"completed":174,"skipped":3102,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:50:28.231: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:50:30.262: INFO: Deleting pod "var-expansion-b2c47c32-8b18-40db-9f90-6aeee18e669b" in namespace "var-expansion-4737"
Aug  5 14:50:30.265: INFO: Wait up to 5m0s for pod "var-expansion-b2c47c32-8b18-40db-9f90-6aeee18e669b" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Aug  5 14:50:32.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4737" for this suite.
â€¢{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":356,"completed":175,"skipped":3128,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:50:32.282: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-8ccd39c5-fcb4-4e80-ab09-921655ad47c3
STEP: Creating a pod to test consume secrets
Aug  5 14:50:32.308: INFO: Waiting up to 5m0s for pod "pod-secrets-459c28b2-6a4b-406f-9cd3-44b397d778f0" in namespace "secrets-7677" to be "Succeeded or Failed"
Aug  5 14:50:32.309: INFO: Pod "pod-secrets-459c28b2-6a4b-406f-9cd3-44b397d778f0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.385912ms
Aug  5 14:50:34.315: INFO: Pod "pod-secrets-459c28b2-6a4b-406f-9cd3-44b397d778f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007035734s
Aug  5 14:50:36.320: INFO: Pod "pod-secrets-459c28b2-6a4b-406f-9cd3-44b397d778f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012489859s
STEP: Saw pod success
Aug  5 14:50:36.320: INFO: Pod "pod-secrets-459c28b2-6a4b-406f-9cd3-44b397d778f0" satisfied condition "Succeeded or Failed"
Aug  5 14:50:36.322: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-secrets-459c28b2-6a4b-406f-9cd3-44b397d778f0 container secret-volume-test: <nil>
STEP: delete the pod
Aug  5 14:50:36.331: INFO: Waiting for pod pod-secrets-459c28b2-6a4b-406f-9cd3-44b397d778f0 to disappear
Aug  5 14:50:36.332: INFO: Pod pod-secrets-459c28b2-6a4b-406f-9cd3-44b397d778f0 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:50:36.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7677" for this suite.
STEP: Destroying namespace "secret-namespace-5357" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":356,"completed":176,"skipped":3139,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:50:36.340: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug  5 14:50:36.356: INFO: Pod name pod-release: Found 0 pods out of 1
Aug  5 14:50:41.361: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Aug  5 14:50:42.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1787" for this suite.

â€¢ [SLOW TEST:6.038 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":356,"completed":177,"skipped":3188,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version 
  should find the server version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:50:42.380: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should find the server version [Conformance]
  test/e2e/framework/framework.go:652
STEP: Request ServerVersion
STEP: Confirm major version
Aug  5 14:50:42.390: INFO: Major version: 1
STEP: Confirm minor version
Aug  5 14:50:42.390: INFO: cleanMinorVersion: 24
Aug  5 14:50:42.390: INFO: Minor version: 24
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:188
Aug  5 14:50:42.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-7268" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":356,"completed":178,"skipped":3248,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:50:42.395: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-232
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-232
I0805 14:50:42.427227      18 runners.go:193] Created replication controller with name: externalname-service, namespace: services-232, replica count: 2
I0805 14:50:45.479055      18 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 14:50:45.479: INFO: Creating new exec pod
Aug  5 14:50:48.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-232 exec execpodwf9gd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug  5 14:50:48.642: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug  5 14:50:48.642: INFO: stdout: "externalname-service-mtb2v"
Aug  5 14:50:48.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-232 exec execpodwf9gd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.105.173.229 80'
Aug  5 14:50:48.758: INFO: stderr: "+ nc -v -t -w 2 10.105.173.229 80\n+ echo hostName\nConnection to 10.105.173.229 80 port [tcp/http] succeeded!\n"
Aug  5 14:50:48.758: INFO: stdout: "externalname-service-mtb2v"
Aug  5 14:50:48.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-232 exec execpodwf9gd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.4 30269'
Aug  5 14:50:48.874: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.96.4 30269\nConnection to 10.1.96.4 30269 port [tcp/*] succeeded!\n"
Aug  5 14:50:48.874: INFO: stdout: ""
Aug  5 14:50:49.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-232 exec execpodwf9gd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.4 30269'
Aug  5 14:50:49.976: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.96.4 30269\nConnection to 10.1.96.4 30269 port [tcp/*] succeeded!\n"
Aug  5 14:50:49.976: INFO: stdout: "externalname-service-mtv4l"
Aug  5 14:50:49.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-232 exec execpodwf9gd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.5 30269'
Aug  5 14:50:50.086: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.96.5 30269\nConnection to 10.1.96.5 30269 port [tcp/*] succeeded!\n"
Aug  5 14:50:50.086: INFO: stdout: "externalname-service-mtv4l"
Aug  5 14:50:50.086: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 14:50:50.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-232" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:7.708 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":356,"completed":179,"skipped":3251,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:50:50.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Aug  5 14:50:56.150: INFO: 80 pods remaining
Aug  5 14:50:56.150: INFO: 80 pods has nil DeletionTimestamp
Aug  5 14:50:56.150: INFO: 
Aug  5 14:50:57.143: INFO: 70 pods remaining
Aug  5 14:50:57.143: INFO: 70 pods has nil DeletionTimestamp
Aug  5 14:50:57.143: INFO: 
Aug  5 14:50:58.142: INFO: 60 pods remaining
Aug  5 14:50:58.142: INFO: 60 pods has nil DeletionTimestamp
Aug  5 14:50:58.142: INFO: 
Aug  5 14:50:59.146: INFO: 40 pods remaining
Aug  5 14:50:59.146: INFO: 40 pods has nil DeletionTimestamp
Aug  5 14:50:59.146: INFO: 
Aug  5 14:51:00.157: INFO: 30 pods remaining
Aug  5 14:51:00.157: INFO: 30 pods has nil DeletionTimestamp
Aug  5 14:51:00.157: INFO: 
Aug  5 14:51:01.139: INFO: 20 pods remaining
Aug  5 14:51:01.139: INFO: 20 pods has nil DeletionTimestamp
Aug  5 14:51:01.139: INFO: 
STEP: Gathering metrics
Aug  5 14:51:02.152: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0805 14:51:02.152611      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Aug  5 14:51:02.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7555" for this suite.

â€¢ [SLOW TEST:12.059 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":356,"completed":180,"skipped":3257,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:51:02.163: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:51:02.754: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug  5 14:51:04.766: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  5 14:51:06.772: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  5 14:51:08.773: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 14, 51, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:51:11.776: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:51:11.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3446" for this suite.
STEP: Destroying namespace "webhook-3446-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

â€¢ [SLOW TEST:9.686 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":356,"completed":181,"skipped":3276,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:51:11.870: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Aug  5 14:51:18.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5286" for this suite.

â€¢ [SLOW TEST:7.047 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":356,"completed":182,"skipped":3398,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:51:18.917: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:51:19.694: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:51:22.708: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:51:34.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2682" for this suite.
STEP: Destroying namespace "webhook-2682-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

â€¢ [SLOW TEST:15.907 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":356,"completed":183,"skipped":3419,"failed":0}
SSS
------------------------------
[sig-architecture] Conformance Tests 
  should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:51:34.826: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename conformance-tests
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
STEP: Getting node addresses
Aug  5 14:51:34.865: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:188
Aug  5 14:51:34.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-4801" for this suite.
â€¢{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","total":356,"completed":184,"skipped":3422,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:51:34.897: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 14:51:35.760: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 14:51:38.774: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 14:51:38.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-333" for this suite.
STEP: Destroying namespace "webhook-333-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":356,"completed":185,"skipped":3455,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:51:38.826: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-ceff6c67-c77e-47e0-bac1-616d574003c6 in namespace container-probe-8250
Aug  5 14:51:40.878: INFO: Started pod busybox-ceff6c67-c77e-47e0-bac1-616d574003c6 in namespace container-probe-8250
STEP: checking the pod's current state and verifying that restartCount is present
Aug  5 14:51:40.880: INFO: Initial restart count of pod busybox-ceff6c67-c77e-47e0-bac1-616d574003c6 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Aug  5 14:55:41.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8250" for this suite.

â€¢ [SLOW TEST:242.863 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":186,"skipped":3467,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:55:41.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-310d6adc-4562-4f94-a066-f7c4a4e82e33
STEP: Creating configMap with name cm-test-opt-upd-a05810fc-9dcd-480d-883a-d5e7df0e6d1b
STEP: Creating the pod
Aug  5 14:55:41.721: INFO: The status of Pod pod-projected-configmaps-ead1e80f-2c84-47b0-8cc4-dd48a54c45c3 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:55:43.727: INFO: The status of Pod pod-projected-configmaps-ead1e80f-2c84-47b0-8cc4-dd48a54c45c3 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-310d6adc-4562-4f94-a066-f7c4a4e82e33
STEP: Updating configmap cm-test-opt-upd-a05810fc-9dcd-480d-883a-d5e7df0e6d1b
STEP: Creating configMap with name cm-test-opt-create-7df2e19b-c9c8-4027-af4c-7110fcc3a7af
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Aug  5 14:55:45.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9356" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":187,"skipped":3487,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:55:45.787: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug  5 14:55:46.142: INFO: Pod name wrapped-volume-race-2204c2db-4477-452d-81c4-cd1ab95743d0: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2204c2db-4477-452d-81c4-cd1ab95743d0 in namespace emptydir-wrapper-9373, will wait for the garbage collector to delete the pods
Aug  5 14:56:02.263: INFO: Deleting ReplicationController wrapped-volume-race-2204c2db-4477-452d-81c4-cd1ab95743d0 took: 3.700763ms
Aug  5 14:56:02.363: INFO: Terminating ReplicationController wrapped-volume-race-2204c2db-4477-452d-81c4-cd1ab95743d0 pods took: 100.116616ms
STEP: Creating RC which spawns configmap-volume pods
Aug  5 14:56:05.578: INFO: Pod name wrapped-volume-race-4ed1b935-e0fb-4a07-bcbf-1e0beac0b688: Found 0 pods out of 5
Aug  5 14:56:10.586: INFO: Pod name wrapped-volume-race-4ed1b935-e0fb-4a07-bcbf-1e0beac0b688: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4ed1b935-e0fb-4a07-bcbf-1e0beac0b688 in namespace emptydir-wrapper-9373, will wait for the garbage collector to delete the pods
Aug  5 14:56:22.666: INFO: Deleting ReplicationController wrapped-volume-race-4ed1b935-e0fb-4a07-bcbf-1e0beac0b688 took: 4.23677ms
Aug  5 14:56:22.766: INFO: Terminating ReplicationController wrapped-volume-race-4ed1b935-e0fb-4a07-bcbf-1e0beac0b688 pods took: 100.531489ms
STEP: Creating RC which spawns configmap-volume pods
Aug  5 14:56:25.978: INFO: Pod name wrapped-volume-race-8e37f1e8-b7ba-402e-bdd0-40ca420e5a2a: Found 0 pods out of 5
Aug  5 14:56:30.985: INFO: Pod name wrapped-volume-race-8e37f1e8-b7ba-402e-bdd0-40ca420e5a2a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8e37f1e8-b7ba-402e-bdd0-40ca420e5a2a in namespace emptydir-wrapper-9373, will wait for the garbage collector to delete the pods
Aug  5 14:56:41.056: INFO: Deleting ReplicationController wrapped-volume-race-8e37f1e8-b7ba-402e-bdd0-40ca420e5a2a took: 2.822079ms
Aug  5 14:56:41.157: INFO: Terminating ReplicationController wrapped-volume-race-8e37f1e8-b7ba-402e-bdd0-40ca420e5a2a pods took: 100.795896ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
Aug  5 14:56:44.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9373" for this suite.

â€¢ [SLOW TEST:58.980 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":356,"completed":188,"skipped":3515,"failed":0}
SSSSS
------------------------------
[sig-node] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:56:44.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:56:44.786: INFO: The status of Pod server-envvars-72336376-9236-4570-a781-3fc714f8c726 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:56:46.792: INFO: The status of Pod server-envvars-72336376-9236-4570-a781-3fc714f8c726 is Running (Ready = true)
Aug  5 14:56:46.803: INFO: Waiting up to 5m0s for pod "client-envvars-237acc11-9866-484c-b494-954b1215fd19" in namespace "pods-3478" to be "Succeeded or Failed"
Aug  5 14:56:46.809: INFO: Pod "client-envvars-237acc11-9866-484c-b494-954b1215fd19": Phase="Pending", Reason="", readiness=false. Elapsed: 5.124329ms
Aug  5 14:56:48.815: INFO: Pod "client-envvars-237acc11-9866-484c-b494-954b1215fd19": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011549801s
Aug  5 14:56:50.819: INFO: Pod "client-envvars-237acc11-9866-484c-b494-954b1215fd19": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015123151s
STEP: Saw pod success
Aug  5 14:56:50.819: INFO: Pod "client-envvars-237acc11-9866-484c-b494-954b1215fd19" satisfied condition "Succeeded or Failed"
Aug  5 14:56:50.820: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod client-envvars-237acc11-9866-484c-b494-954b1215fd19 container env3cont: <nil>
STEP: delete the pod
Aug  5 14:56:50.830: INFO: Waiting for pod client-envvars-237acc11-9866-484c-b494-954b1215fd19 to disappear
Aug  5 14:56:50.832: INFO: Pod client-envvars-237acc11-9866-484c-b494-954b1215fd19 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Aug  5 14:56:50.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3478" for this suite.

â€¢ [SLOW TEST:6.069 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":356,"completed":189,"skipped":3520,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:56:50.839: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-1f9b9dd0-4a3d-49ca-81fc-75f2091f3d42
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 14:56:52.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8419" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":190,"skipped":3532,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:56:52.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Starting the proxy
Aug  5 14:56:52.898: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5764 proxy --unix-socket=/tmp/kubectl-proxy-unix512215089/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:56:52.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5764" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":356,"completed":191,"skipped":3549,"failed":0}
S
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:56:52.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-64
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-64
I0805 14:56:52.967704      18 runners.go:193] Created replication controller with name: externalname-service, namespace: services-64, replica count: 2
Aug  5 14:56:56.019: INFO: Creating new exec pod
I0805 14:56:56.019212      18 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 14:56:59.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-64 exec execpod2rlkx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug  5 14:56:59.147: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug  5 14:56:59.147: INFO: stdout: "externalname-service-98qs5"
Aug  5 14:56:59.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-64 exec execpod2rlkx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.48.17 80'
Aug  5 14:56:59.292: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.98.48.17 80\nConnection to 10.98.48.17 80 port [tcp/http] succeeded!\n"
Aug  5 14:56:59.292: INFO: stdout: "externalname-service-98qs5"
Aug  5 14:56:59.292: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 14:56:59.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-64" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:6.362 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":356,"completed":192,"skipped":3550,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:56:59.306: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-secret-wsl6
STEP: Creating a pod to test atomic-volume-subpath
Aug  5 14:56:59.332: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-wsl6" in namespace "subpath-6702" to be "Succeeded or Failed"
Aug  5 14:56:59.333: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.911484ms
Aug  5 14:57:01.339: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=true. Elapsed: 2.007907292s
Aug  5 14:57:03.346: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=true. Elapsed: 4.014363967s
Aug  5 14:57:05.350: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=true. Elapsed: 6.018320595s
Aug  5 14:57:07.356: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=true. Elapsed: 8.024963013s
Aug  5 14:57:09.363: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=true. Elapsed: 10.031515711s
Aug  5 14:57:11.369: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=true. Elapsed: 12.037177419s
Aug  5 14:57:13.374: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=true. Elapsed: 14.04290311s
Aug  5 14:57:15.381: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=true. Elapsed: 16.049296083s
Aug  5 14:57:17.387: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=true. Elapsed: 18.05582746s
Aug  5 14:57:19.393: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=true. Elapsed: 20.061186119s
Aug  5 14:57:21.397: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Running", Reason="", readiness=false. Elapsed: 22.065516991s
Aug  5 14:57:23.404: INFO: Pod "pod-subpath-test-secret-wsl6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.072165347s
STEP: Saw pod success
Aug  5 14:57:23.404: INFO: Pod "pod-subpath-test-secret-wsl6" satisfied condition "Succeeded or Failed"
Aug  5 14:57:23.406: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-subpath-test-secret-wsl6 container test-container-subpath-secret-wsl6: <nil>
STEP: delete the pod
Aug  5 14:57:23.420: INFO: Waiting for pod pod-subpath-test-secret-wsl6 to disappear
Aug  5 14:57:23.422: INFO: Pod pod-subpath-test-secret-wsl6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-wsl6
Aug  5 14:57:23.422: INFO: Deleting pod "pod-subpath-test-secret-wsl6" in namespace "subpath-6702"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Aug  5 14:57:23.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6702" for this suite.

â€¢ [SLOW TEST:24.124 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","total":356,"completed":193,"skipped":3553,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:57:23.431: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override arguments
Aug  5 14:57:23.453: INFO: Waiting up to 5m0s for pod "client-containers-bf1a60a1-e7b8-4838-ba6d-21db9ffea883" in namespace "containers-4222" to be "Succeeded or Failed"
Aug  5 14:57:23.456: INFO: Pod "client-containers-bf1a60a1-e7b8-4838-ba6d-21db9ffea883": Phase="Pending", Reason="", readiness=false. Elapsed: 2.127743ms
Aug  5 14:57:25.461: INFO: Pod "client-containers-bf1a60a1-e7b8-4838-ba6d-21db9ffea883": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007708362s
Aug  5 14:57:27.468: INFO: Pod "client-containers-bf1a60a1-e7b8-4838-ba6d-21db9ffea883": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014668983s
STEP: Saw pod success
Aug  5 14:57:27.468: INFO: Pod "client-containers-bf1a60a1-e7b8-4838-ba6d-21db9ffea883" satisfied condition "Succeeded or Failed"
Aug  5 14:57:27.470: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod client-containers-bf1a60a1-e7b8-4838-ba6d-21db9ffea883 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 14:57:27.478: INFO: Waiting for pod client-containers-bf1a60a1-e7b8-4838-ba6d-21db9ffea883 to disappear
Aug  5 14:57:27.480: INFO: Pod client-containers-bf1a60a1-e7b8-4838-ba6d-21db9ffea883 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Aug  5 14:57:27.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4222" for this suite.
â€¢{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","total":356,"completed":194,"skipped":3566,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:57:27.484: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug  5 14:57:27.500: INFO: Waiting up to 5m0s for pod "pod-18cde3e0-3323-444e-b1f5-9b6c01b03342" in namespace "emptydir-105" to be "Succeeded or Failed"
Aug  5 14:57:27.502: INFO: Pod "pod-18cde3e0-3323-444e-b1f5-9b6c01b03342": Phase="Pending", Reason="", readiness=false. Elapsed: 1.819167ms
Aug  5 14:57:29.508: INFO: Pod "pod-18cde3e0-3323-444e-b1f5-9b6c01b03342": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007271016s
Aug  5 14:57:31.527: INFO: Pod "pod-18cde3e0-3323-444e-b1f5-9b6c01b03342": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026612462s
STEP: Saw pod success
Aug  5 14:57:31.527: INFO: Pod "pod-18cde3e0-3323-444e-b1f5-9b6c01b03342" satisfied condition "Succeeded or Failed"
Aug  5 14:57:31.530: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-18cde3e0-3323-444e-b1f5-9b6c01b03342 container test-container: <nil>
STEP: delete the pod
Aug  5 14:57:31.545: INFO: Waiting for pod pod-18cde3e0-3323-444e-b1f5-9b6c01b03342 to disappear
Aug  5 14:57:31.548: INFO: Pod pod-18cde3e0-3323-444e-b1f5-9b6c01b03342 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 14:57:31.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-105" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":195,"skipped":3567,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:57:31.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a pod template
STEP: Replace a pod template
Aug  5 14:57:31.579: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Aug  5 14:57:31.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-3669" for this suite.
â€¢{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","total":356,"completed":196,"skipped":3587,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:57:31.584: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating all guestbook components
Aug  5 14:57:31.594: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Aug  5 14:57:31.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 create -f -'
Aug  5 14:57:31.731: INFO: stderr: ""
Aug  5 14:57:31.731: INFO: stdout: "service/agnhost-replica created\n"
Aug  5 14:57:31.732: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Aug  5 14:57:31.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 create -f -'
Aug  5 14:57:31.923: INFO: stderr: ""
Aug  5 14:57:31.923: INFO: stdout: "service/agnhost-primary created\n"
Aug  5 14:57:31.923: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug  5 14:57:31.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 create -f -'
Aug  5 14:57:32.049: INFO: stderr: ""
Aug  5 14:57:32.049: INFO: stdout: "service/frontend created\n"
Aug  5 14:57:32.049: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Aug  5 14:57:32.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 create -f -'
Aug  5 14:57:32.173: INFO: stderr: ""
Aug  5 14:57:32.173: INFO: stdout: "deployment.apps/frontend created\n"
Aug  5 14:57:32.173: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug  5 14:57:32.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 create -f -'
Aug  5 14:57:32.309: INFO: stderr: ""
Aug  5 14:57:32.309: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Aug  5 14:57:32.309: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug  5 14:57:32.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 create -f -'
Aug  5 14:57:32.444: INFO: stderr: ""
Aug  5 14:57:32.444: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
Aug  5 14:57:32.444: INFO: Waiting for all frontend pods to be Running.
Aug  5 14:57:37.496: INFO: Waiting for frontend to serve content.
Aug  5 14:57:37.506: INFO: Trying to add a new entry to the guestbook.
Aug  5 14:57:37.515: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug  5 14:57:37.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 delete --grace-period=0 --force -f -'
Aug  5 14:57:37.580: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  5 14:57:37.580: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
Aug  5 14:57:37.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 delete --grace-period=0 --force -f -'
Aug  5 14:57:37.645: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  5 14:57:37.645: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Aug  5 14:57:37.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 delete --grace-period=0 --force -f -'
Aug  5 14:57:37.696: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  5 14:57:37.696: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug  5 14:57:37.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 delete --grace-period=0 --force -f -'
Aug  5 14:57:37.757: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  5 14:57:37.758: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug  5 14:57:37.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 delete --grace-period=0 --force -f -'
Aug  5 14:57:37.838: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  5 14:57:37.838: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Aug  5 14:57:37.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5589 delete --grace-period=0 --force -f -'
Aug  5 14:57:37.972: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  5 14:57:37.972: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 14:57:37.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5589" for this suite.

â€¢ [SLOW TEST:6.393 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:340
    should create and stop a working application  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":356,"completed":197,"skipped":3590,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:57:37.977: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-cqlv
STEP: Creating a pod to test atomic-volume-subpath
Aug  5 14:57:38.015: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-cqlv" in namespace "subpath-5698" to be "Succeeded or Failed"
Aug  5 14:57:38.018: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.771637ms
Aug  5 14:57:40.022: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007081397s
Aug  5 14:57:42.028: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Running", Reason="", readiness=true. Elapsed: 4.01282453s
Aug  5 14:57:44.033: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Running", Reason="", readiness=true. Elapsed: 6.0185573s
Aug  5 14:57:46.039: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Running", Reason="", readiness=true. Elapsed: 8.024485876s
Aug  5 14:57:48.046: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Running", Reason="", readiness=true. Elapsed: 10.0312349s
Aug  5 14:57:50.050: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Running", Reason="", readiness=true. Elapsed: 12.035384577s
Aug  5 14:57:52.056: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Running", Reason="", readiness=true. Elapsed: 14.0410396s
Aug  5 14:57:54.062: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Running", Reason="", readiness=true. Elapsed: 16.047308216s
Aug  5 14:57:56.067: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Running", Reason="", readiness=true. Elapsed: 18.052632953s
Aug  5 14:57:58.074: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Running", Reason="", readiness=true. Elapsed: 20.059092452s
Aug  5 14:58:00.077: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Running", Reason="", readiness=false. Elapsed: 22.062364049s
Aug  5 14:58:02.083: INFO: Pod "pod-subpath-test-configmap-cqlv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.068347421s
STEP: Saw pod success
Aug  5 14:58:02.083: INFO: Pod "pod-subpath-test-configmap-cqlv" satisfied condition "Succeeded or Failed"
Aug  5 14:58:02.085: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-subpath-test-configmap-cqlv container test-container-subpath-configmap-cqlv: <nil>
STEP: delete the pod
Aug  5 14:58:02.096: INFO: Waiting for pod pod-subpath-test-configmap-cqlv to disappear
Aug  5 14:58:02.098: INFO: Pod pod-subpath-test-configmap-cqlv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-cqlv
Aug  5 14:58:02.098: INFO: Deleting pod "pod-subpath-test-configmap-cqlv" in namespace "subpath-5698"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Aug  5 14:58:02.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5698" for this suite.

â€¢ [SLOW TEST:24.128 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","total":356,"completed":198,"skipped":3627,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:58:02.108: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 14:58:02.127: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0c625775-43d1-4246-ab35-f9f2a4243d36" in namespace "projected-1545" to be "Succeeded or Failed"
Aug  5 14:58:02.129: INFO: Pod "downwardapi-volume-0c625775-43d1-4246-ab35-f9f2a4243d36": Phase="Pending", Reason="", readiness=false. Elapsed: 1.703956ms
Aug  5 14:58:04.135: INFO: Pod "downwardapi-volume-0c625775-43d1-4246-ab35-f9f2a4243d36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008491265s
Aug  5 14:58:06.141: INFO: Pod "downwardapi-volume-0c625775-43d1-4246-ab35-f9f2a4243d36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014072368s
STEP: Saw pod success
Aug  5 14:58:06.141: INFO: Pod "downwardapi-volume-0c625775-43d1-4246-ab35-f9f2a4243d36" satisfied condition "Succeeded or Failed"
Aug  5 14:58:06.143: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-0c625775-43d1-4246-ab35-f9f2a4243d36 container client-container: <nil>
STEP: delete the pod
Aug  5 14:58:06.152: INFO: Waiting for pod downwardapi-volume-0c625775-43d1-4246-ab35-f9f2a4243d36 to disappear
Aug  5 14:58:06.154: INFO: Pod downwardapi-volume-0c625775-43d1-4246-ab35-f9f2a4243d36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 14:58:06.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1545" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":199,"skipped":3656,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:58:06.161: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-598fba1f-09f4-452e-8fdd-f7142e2232a3
STEP: Creating a pod to test consume secrets
Aug  5 14:58:06.184: INFO: Waiting up to 5m0s for pod "pod-secrets-f558cd0f-9d47-474c-be66-cad22b242f9a" in namespace "secrets-8277" to be "Succeeded or Failed"
Aug  5 14:58:06.186: INFO: Pod "pod-secrets-f558cd0f-9d47-474c-be66-cad22b242f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.902322ms
Aug  5 14:58:08.192: INFO: Pod "pod-secrets-f558cd0f-9d47-474c-be66-cad22b242f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007845454s
Aug  5 14:58:10.195: INFO: Pod "pod-secrets-f558cd0f-9d47-474c-be66-cad22b242f9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011308701s
STEP: Saw pod success
Aug  5 14:58:10.195: INFO: Pod "pod-secrets-f558cd0f-9d47-474c-be66-cad22b242f9a" satisfied condition "Succeeded or Failed"
Aug  5 14:58:10.197: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-secrets-f558cd0f-9d47-474c-be66-cad22b242f9a container secret-volume-test: <nil>
STEP: delete the pod
Aug  5 14:58:10.206: INFO: Waiting for pod pod-secrets-f558cd0f-9d47-474c-be66-cad22b242f9a to disappear
Aug  5 14:58:10.207: INFO: Pod pod-secrets-f558cd0f-9d47-474c-be66-cad22b242f9a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Aug  5 14:58:10.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8277" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":200,"skipped":3721,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:58:10.212: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-b06bfbbb-78d5-4c8c-9c41-4a33c34ded87
STEP: Creating configMap with name cm-test-opt-upd-33b501d3-36da-4ef1-aed3-bd3ca0510bad
STEP: Creating the pod
Aug  5 14:58:10.232: INFO: The status of Pod pod-configmaps-a4692b15-df0d-4840-be6e-2b4ecf7fa482 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:58:12.238: INFO: The status of Pod pod-configmaps-a4692b15-df0d-4840-be6e-2b4ecf7fa482 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-b06bfbbb-78d5-4c8c-9c41-4a33c34ded87
STEP: Updating configmap cm-test-opt-upd-33b501d3-36da-4ef1-aed3-bd3ca0510bad
STEP: Creating configMap with name cm-test-opt-create-d48fd9b9-a78a-41b3-b2ac-591e86bcac69
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 14:58:14.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5574" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":201,"skipped":3734,"failed":0}
SSSSS
------------------------------
[sig-apps] DisruptionController 
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:58:14.289: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Aug  5 14:58:16.327: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Aug  5 14:58:18.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1028" for this suite.
â€¢{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":356,"completed":202,"skipped":3739,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:58:18.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 14:58:18.361: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug  5 14:58:23.364: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
Aug  5 14:58:23.368: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
Aug  5 14:58:23.382: INFO: observed ReplicaSet test-rs in namespace replicaset-3858 with ReadyReplicas 1, AvailableReplicas 1
Aug  5 14:58:23.387: INFO: observed ReplicaSet test-rs in namespace replicaset-3858 with ReadyReplicas 1, AvailableReplicas 1
Aug  5 14:58:23.399: INFO: observed ReplicaSet test-rs in namespace replicaset-3858 with ReadyReplicas 1, AvailableReplicas 1
Aug  5 14:58:23.404: INFO: observed ReplicaSet test-rs in namespace replicaset-3858 with ReadyReplicas 1, AvailableReplicas 1
Aug  5 14:58:24.625: INFO: observed ReplicaSet test-rs in namespace replicaset-3858 with ReadyReplicas 2, AvailableReplicas 2
Aug  5 14:58:24.674: INFO: observed Replicaset test-rs in namespace replicaset-3858 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Aug  5 14:58:24.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3858" for this suite.

â€¢ [SLOW TEST:6.360 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":356,"completed":203,"skipped":3813,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:58:24.706: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6123.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6123.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6123.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6123.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  5 14:58:26.745: INFO: DNS probes using dns-6123/dns-test-900ee097-f7db-40e2-8a35-cb8afa1d90ec succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Aug  5 14:58:26.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6123" for this suite.
â€¢{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","total":356,"completed":204,"skipped":3881,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:58:26.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-6edd3954-b322-486f-962e-a50b986ee5ac in namespace container-probe-6656
Aug  5 14:58:28.808: INFO: Started pod busybox-6edd3954-b322-486f-962e-a50b986ee5ac in namespace container-probe-6656
STEP: checking the pod's current state and verifying that restartCount is present
Aug  5 14:58:28.810: INFO: Initial restart count of pod busybox-6edd3954-b322-486f-962e-a50b986ee5ac is 0
Aug  5 14:59:18.954: INFO: Restart count of pod container-probe-6656/busybox-6edd3954-b322-486f-962e-a50b986ee5ac is now 1 (50.144747045s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Aug  5 14:59:18.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6656" for this suite.

â€¢ [SLOW TEST:52.192 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":205,"skipped":3922,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:59:18.968: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service nodeport-test with type=NodePort in namespace services-7210
STEP: creating replication controller nodeport-test in namespace services-7210
I0805 14:59:19.004573      18 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-7210, replica count: 2
I0805 14:59:22.056291      18 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 14:59:22.056: INFO: Creating new exec pod
Aug  5 14:59:25.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-7210 exec execpod5vsm5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug  5 14:59:25.201: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug  5 14:59:25.201: INFO: stdout: ""
Aug  5 14:59:26.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-7210 exec execpod5vsm5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug  5 14:59:26.322: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug  5 14:59:26.322: INFO: stdout: "nodeport-test-gn529"
Aug  5 14:59:26.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-7210 exec execpod5vsm5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.143.141 80'
Aug  5 14:59:26.458: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.143.141 80\nConnection to 10.96.143.141 80 port [tcp/http] succeeded!\n"
Aug  5 14:59:26.458: INFO: stdout: ""
Aug  5 14:59:27.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-7210 exec execpod5vsm5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.143.141 80'
Aug  5 14:59:27.569: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.143.141 80\nConnection to 10.96.143.141 80 port [tcp/http] succeeded!\n"
Aug  5 14:59:27.569: INFO: stdout: ""
Aug  5 14:59:28.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-7210 exec execpod5vsm5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.143.141 80'
Aug  5 14:59:28.581: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.143.141 80\nConnection to 10.96.143.141 80 port [tcp/http] succeeded!\n"
Aug  5 14:59:28.581: INFO: stdout: "nodeport-test-gn529"
Aug  5 14:59:28.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-7210 exec execpod5vsm5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.4 30267'
Aug  5 14:59:28.695: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.96.4 30267\nConnection to 10.1.96.4 30267 port [tcp/*] succeeded!\n"
Aug  5 14:59:28.695: INFO: stdout: "nodeport-test-pxm2j"
Aug  5 14:59:28.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-7210 exec execpod5vsm5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.5 30267'
Aug  5 14:59:28.810: INFO: stderr: "+ nc -v -t -w 2 10.1.96.5 30267\n+ echo hostName\nConnection to 10.1.96.5 30267 port [tcp/*] succeeded!\n"
Aug  5 14:59:28.810: INFO: stdout: "nodeport-test-pxm2j"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 14:59:28.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7210" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:9.849 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":356,"completed":206,"skipped":3943,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:59:28.818: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Aug  5 14:59:56.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-923" for this suite.

â€¢ [SLOW TEST:28.050 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":356,"completed":207,"skipped":3957,"failed":0}
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 14:59:56.869: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-2603
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  5 14:59:56.886: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug  5 14:59:56.898: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 14:59:58.902: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:00:00.903: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:00:02.906: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:00:04.904: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:00:06.904: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:00:08.901: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug  5 15:00:08.904: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Aug  5 15:00:10.921: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Aug  5 15:00:10.921: INFO: Going to poll 10.244.18.168 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Aug  5 15:00:10.922: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.18.168 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2603 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 15:00:10.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 15:00:10.923: INFO: ExecWithOptions: Clientset creation
Aug  5 15:00:10.923: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2603/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.18.168+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug  5 15:00:11.990: INFO: Found all 1 expected endpoints: [netserver-0]
Aug  5 15:00:11.991: INFO: Going to poll 10.244.107.155 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Aug  5 15:00:11.995: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.107.155 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2603 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 15:00:11.995: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 15:00:11.995: INFO: ExecWithOptions: Clientset creation
Aug  5 15:00:11.995: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2603/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.107.155+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug  5 15:00:13.080: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Aug  5 15:00:13.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2603" for this suite.

â€¢ [SLOW TEST:16.219 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":208,"skipped":3962,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:00:13.089: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:00:13.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties
Aug  5 15:00:15.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 --namespace=crd-publish-openapi-3563 create -f -'
Aug  5 15:00:15.770: INFO: stderr: ""
Aug  5 15:00:15.770: INFO: stdout: "e2e-test-crd-publish-openapi-226-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug  5 15:00:15.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 --namespace=crd-publish-openapi-3563 delete e2e-test-crd-publish-openapi-226-crds test-foo'
Aug  5 15:00:15.822: INFO: stderr: ""
Aug  5 15:00:15.822: INFO: stdout: "e2e-test-crd-publish-openapi-226-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Aug  5 15:00:15.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 --namespace=crd-publish-openapi-3563 apply -f -'
Aug  5 15:00:15.956: INFO: stderr: ""
Aug  5 15:00:15.956: INFO: stdout: "e2e-test-crd-publish-openapi-226-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug  5 15:00:15.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 --namespace=crd-publish-openapi-3563 delete e2e-test-crd-publish-openapi-226-crds test-foo'
Aug  5 15:00:16.005: INFO: stderr: ""
Aug  5 15:00:16.005: INFO: stdout: "e2e-test-crd-publish-openapi-226-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values
Aug  5 15:00:16.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 --namespace=crd-publish-openapi-3563 create -f -'
Aug  5 15:00:16.135: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Aug  5 15:00:16.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 --namespace=crd-publish-openapi-3563 create -f -'
Aug  5 15:00:16.264: INFO: rc: 1
Aug  5 15:00:16.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 --namespace=crd-publish-openapi-3563 apply -f -'
Aug  5 15:00:16.448: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties
Aug  5 15:00:16.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 --namespace=crd-publish-openapi-3563 create -f -'
Aug  5 15:00:16.635: INFO: rc: 1
Aug  5 15:00:16.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 --namespace=crd-publish-openapi-3563 apply -f -'
Aug  5 15:00:16.803: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Aug  5 15:00:16.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 explain e2e-test-crd-publish-openapi-226-crds'
Aug  5 15:00:16.934: INFO: stderr: ""
Aug  5 15:00:16.934: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-226-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Aug  5 15:00:16.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 explain e2e-test-crd-publish-openapi-226-crds.metadata'
Aug  5 15:00:17.067: INFO: stderr: ""
Aug  5 15:00:17.067: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-226-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     Deprecated: ClusterName is a legacy field that was always cleared by the\n     system and never used; it will be removed completely in 1.25.\n\n     The name in the go struct is changed to help clients detect accidental use.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Aug  5 15:00:17.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 explain e2e-test-crd-publish-openapi-226-crds.spec'
Aug  5 15:00:17.214: INFO: stderr: ""
Aug  5 15:00:17.214: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-226-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Aug  5 15:00:17.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 explain e2e-test-crd-publish-openapi-226-crds.spec.bars'
Aug  5 15:00:17.342: INFO: stderr: ""
Aug  5 15:00:17.342: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-226-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Aug  5 15:00:17.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-3563 explain e2e-test-crd-publish-openapi-226-crds.spec.bars2'
Aug  5 15:00:17.483: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:00:19.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3563" for this suite.

â€¢ [SLOW TEST:6.378 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":356,"completed":209,"skipped":3965,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:00:19.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 15:00:19.888: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 15:00:22.904: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Aug  5 15:00:22.924: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:00:22.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5397" for this suite.
STEP: Destroying namespace "webhook-5397-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":356,"completed":210,"skipped":3967,"failed":0}
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:00:22.963: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-25acfdf7-325a-4dcc-9c1e-125b883637b5
STEP: Creating a pod to test consume secrets
Aug  5 15:00:23.006: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c4cf83a0-c5fa-4813-9e17-efba0af6752e" in namespace "projected-3322" to be "Succeeded or Failed"
Aug  5 15:00:23.008: INFO: Pod "pod-projected-secrets-c4cf83a0-c5fa-4813-9e17-efba0af6752e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.170184ms
Aug  5 15:00:25.014: INFO: Pod "pod-projected-secrets-c4cf83a0-c5fa-4813-9e17-efba0af6752e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008885052s
Aug  5 15:00:27.019: INFO: Pod "pod-projected-secrets-c4cf83a0-c5fa-4813-9e17-efba0af6752e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013817458s
STEP: Saw pod success
Aug  5 15:00:27.019: INFO: Pod "pod-projected-secrets-c4cf83a0-c5fa-4813-9e17-efba0af6752e" satisfied condition "Succeeded or Failed"
Aug  5 15:00:27.021: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-secrets-c4cf83a0-c5fa-4813-9e17-efba0af6752e container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  5 15:00:27.041: INFO: Waiting for pod pod-projected-secrets-c4cf83a0-c5fa-4813-9e17-efba0af6752e to disappear
Aug  5 15:00:27.042: INFO: Pod pod-projected-secrets-c4cf83a0-c5fa-4813-9e17-efba0af6752e no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Aug  5 15:00:27.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3322" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":211,"skipped":3969,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:00:27.048: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-k2jc9 in namespace proxy-3944
I0805 15:00:27.071420      18 runners.go:193] Created replication controller with name: proxy-service-k2jc9, namespace: proxy-3944, replica count: 1
I0805 15:00:28.123067      18 runners.go:193] proxy-service-k2jc9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0805 15:00:29.123581      18 runners.go:193] proxy-service-k2jc9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 15:00:29.128: INFO: setup took 2.066635192s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug  5 15:00:29.143: INFO: (0) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 14.591123ms)
Aug  5 15:00:29.143: INFO: (0) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 14.471026ms)
Aug  5 15:00:29.145: INFO: (0) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 16.529813ms)
Aug  5 15:00:29.145: INFO: (0) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 16.707742ms)
Aug  5 15:00:29.145: INFO: (0) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 16.531438ms)
Aug  5 15:00:29.146: INFO: (0) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 16.62335ms)
Aug  5 15:00:29.146: INFO: (0) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 17.022897ms)
Aug  5 15:00:29.148: INFO: (0) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 19.877378ms)
Aug  5 15:00:29.149: INFO: (0) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 20.1947ms)
Aug  5 15:00:29.150: INFO: (0) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 21.561973ms)
Aug  5 15:00:29.150: INFO: (0) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 21.706069ms)
Aug  5 15:00:29.151: INFO: (0) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 21.804772ms)
Aug  5 15:00:29.150: INFO: (0) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 21.300423ms)
Aug  5 15:00:29.151: INFO: (0) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 22.357222ms)
Aug  5 15:00:29.151: INFO: (0) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 22.253247ms)
Aug  5 15:00:29.151: INFO: (0) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 22.620626ms)
Aug  5 15:00:29.155: INFO: (1) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 3.780927ms)
Aug  5 15:00:29.159: INFO: (1) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 6.746109ms)
Aug  5 15:00:29.159: INFO: (1) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 7.45694ms)
Aug  5 15:00:29.159: INFO: (1) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 7.72919ms)
Aug  5 15:00:29.159: INFO: (1) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 7.650983ms)
Aug  5 15:00:29.160: INFO: (1) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 7.701817ms)
Aug  5 15:00:29.160: INFO: (1) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 7.699716ms)
Aug  5 15:00:29.160: INFO: (1) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 7.854307ms)
Aug  5 15:00:29.160: INFO: (1) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 7.842996ms)
Aug  5 15:00:29.161: INFO: (1) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 8.999666ms)
Aug  5 15:00:29.161: INFO: (1) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 8.931446ms)
Aug  5 15:00:29.161: INFO: (1) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 8.82852ms)
Aug  5 15:00:29.161: INFO: (1) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 8.871109ms)
Aug  5 15:00:29.161: INFO: (1) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 8.783506ms)
Aug  5 15:00:29.162: INFO: (1) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 9.965385ms)
Aug  5 15:00:29.162: INFO: (1) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 10.2195ms)
Aug  5 15:00:29.168: INFO: (2) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 4.808235ms)
Aug  5 15:00:29.168: INFO: (2) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 5.189895ms)
Aug  5 15:00:29.168: INFO: (2) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 5.611911ms)
Aug  5 15:00:29.168: INFO: (2) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 5.391787ms)
Aug  5 15:00:29.169: INFO: (2) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 6.411385ms)
Aug  5 15:00:29.169: INFO: (2) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 6.684226ms)
Aug  5 15:00:29.169: INFO: (2) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 6.179931ms)
Aug  5 15:00:29.169: INFO: (2) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 6.134441ms)
Aug  5 15:00:29.169: INFO: (2) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 6.248953ms)
Aug  5 15:00:29.169: INFO: (2) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 6.044627ms)
Aug  5 15:00:29.169: INFO: (2) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 6.228902ms)
Aug  5 15:00:29.170: INFO: (2) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 7.563045ms)
Aug  5 15:00:29.170: INFO: (2) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 6.855104ms)
Aug  5 15:00:29.170: INFO: (2) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 7.401662ms)
Aug  5 15:00:29.170: INFO: (2) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 7.470118ms)
Aug  5 15:00:29.171: INFO: (2) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 8.652339ms)
Aug  5 15:00:29.175: INFO: (3) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 3.142348ms)
Aug  5 15:00:29.175: INFO: (3) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 4.33594ms)
Aug  5 15:00:29.176: INFO: (3) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 4.02062ms)
Aug  5 15:00:29.177: INFO: (3) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 4.622885ms)
Aug  5 15:00:29.177: INFO: (3) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 5.889345ms)
Aug  5 15:00:29.177: INFO: (3) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 5.537667ms)
Aug  5 15:00:29.178: INFO: (3) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 7.009938ms)
Aug  5 15:00:29.178: INFO: (3) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 5.795269ms)
Aug  5 15:00:29.178: INFO: (3) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 7.110266ms)
Aug  5 15:00:29.178: INFO: (3) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 5.933601ms)
Aug  5 15:00:29.178: INFO: (3) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 6.125872ms)
Aug  5 15:00:29.178: INFO: (3) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 5.747621ms)
Aug  5 15:00:29.179: INFO: (3) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 6.626771ms)
Aug  5 15:00:29.179: INFO: (3) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 7.089867ms)
Aug  5 15:00:29.179: INFO: (3) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 7.848797ms)
Aug  5 15:00:29.179: INFO: (3) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 7.486523ms)
Aug  5 15:00:29.183: INFO: (4) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 3.330414ms)
Aug  5 15:00:29.185: INFO: (4) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 5.381074ms)
Aug  5 15:00:29.185: INFO: (4) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 5.749771ms)
Aug  5 15:00:29.186: INFO: (4) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 5.860081ms)
Aug  5 15:00:29.186: INFO: (4) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 6.208022ms)
Aug  5 15:00:29.186: INFO: (4) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 6.719519ms)
Aug  5 15:00:29.187: INFO: (4) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 6.951372ms)
Aug  5 15:00:29.187: INFO: (4) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 7.036831ms)
Aug  5 15:00:29.187: INFO: (4) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 7.003886ms)
Aug  5 15:00:29.187: INFO: (4) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 7.01927ms)
Aug  5 15:00:29.187: INFO: (4) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 7.642785ms)
Aug  5 15:00:29.187: INFO: (4) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 7.403884ms)
Aug  5 15:00:29.187: INFO: (4) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 7.657646ms)
Aug  5 15:00:29.187: INFO: (4) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 7.828085ms)
Aug  5 15:00:29.187: INFO: (4) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 8.08851ms)
Aug  5 15:00:29.188: INFO: (4) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 8.079021ms)
Aug  5 15:00:29.190: INFO: (5) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 2.564981ms)
Aug  5 15:00:29.191: INFO: (5) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 3.248519ms)
Aug  5 15:00:29.192: INFO: (5) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 4.123063ms)
Aug  5 15:00:29.192: INFO: (5) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 4.142404ms)
Aug  5 15:00:29.192: INFO: (5) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 4.229278ms)
Aug  5 15:00:29.192: INFO: (5) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 4.483665ms)
Aug  5 15:00:29.192: INFO: (5) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 4.448677ms)
Aug  5 15:00:29.192: INFO: (5) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 4.788697ms)
Aug  5 15:00:29.193: INFO: (5) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 5.094783ms)
Aug  5 15:00:29.193: INFO: (5) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 4.949989ms)
Aug  5 15:00:29.193: INFO: (5) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 5.487652ms)
Aug  5 15:00:29.194: INFO: (5) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 6.066366ms)
Aug  5 15:00:29.194: INFO: (5) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 6.210926ms)
Aug  5 15:00:29.194: INFO: (5) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 6.389368ms)
Aug  5 15:00:29.195: INFO: (5) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 6.591971ms)
Aug  5 15:00:29.195: INFO: (5) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 6.679453ms)
Aug  5 15:00:29.198: INFO: (6) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 2.851698ms)
Aug  5 15:00:29.198: INFO: (6) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 2.970903ms)
Aug  5 15:00:29.198: INFO: (6) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 3.515424ms)
Aug  5 15:00:29.198: INFO: (6) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 2.874145ms)
Aug  5 15:00:29.199: INFO: (6) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 3.645629ms)
Aug  5 15:00:29.199: INFO: (6) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 4.02068ms)
Aug  5 15:00:29.201: INFO: (6) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 5.909755ms)
Aug  5 15:00:29.201: INFO: (6) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 5.550872ms)
Aug  5 15:00:29.202: INFO: (6) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 6.624387ms)
Aug  5 15:00:29.202: INFO: (6) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 6.538018ms)
Aug  5 15:00:29.202: INFO: (6) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 7.165428ms)
Aug  5 15:00:29.202: INFO: (6) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 6.828079ms)
Aug  5 15:00:29.202: INFO: (6) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 6.76534ms)
Aug  5 15:00:29.202: INFO: (6) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 6.929656ms)
Aug  5 15:00:29.202: INFO: (6) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 6.913101ms)
Aug  5 15:00:29.202: INFO: (6) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 6.929278ms)
Aug  5 15:00:29.206: INFO: (7) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 3.289175ms)
Aug  5 15:00:29.206: INFO: (7) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 2.922024ms)
Aug  5 15:00:29.207: INFO: (7) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 3.809812ms)
Aug  5 15:00:29.207: INFO: (7) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 3.800235ms)
Aug  5 15:00:29.207: INFO: (7) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 3.994566ms)
Aug  5 15:00:29.208: INFO: (7) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 5.637344ms)
Aug  5 15:00:29.209: INFO: (7) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 6.21991ms)
Aug  5 15:00:29.209: INFO: (7) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 6.189616ms)
Aug  5 15:00:29.209: INFO: (7) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 5.997889ms)
Aug  5 15:00:29.209: INFO: (7) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 5.965917ms)
Aug  5 15:00:29.209: INFO: (7) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 5.891755ms)
Aug  5 15:00:29.209: INFO: (7) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 5.959412ms)
Aug  5 15:00:29.209: INFO: (7) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 5.902813ms)
Aug  5 15:00:29.210: INFO: (7) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 7.141746ms)
Aug  5 15:00:29.210: INFO: (7) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 6.679934ms)
Aug  5 15:00:29.210: INFO: (7) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 7.290493ms)
Aug  5 15:00:29.214: INFO: (8) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 3.736128ms)
Aug  5 15:00:29.214: INFO: (8) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 3.485727ms)
Aug  5 15:00:29.215: INFO: (8) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 4.00759ms)
Aug  5 15:00:29.215: INFO: (8) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 3.95097ms)
Aug  5 15:00:29.216: INFO: (8) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 5.365388ms)
Aug  5 15:00:29.216: INFO: (8) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 4.971116ms)
Aug  5 15:00:29.216: INFO: (8) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 4.96302ms)
Aug  5 15:00:29.217: INFO: (8) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 5.599164ms)
Aug  5 15:00:29.217: INFO: (8) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 6.118443ms)
Aug  5 15:00:29.217: INFO: (8) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 6.023848ms)
Aug  5 15:00:29.217: INFO: (8) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 5.860692ms)
Aug  5 15:00:29.217: INFO: (8) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 5.973222ms)
Aug  5 15:00:29.217: INFO: (8) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 6.644921ms)
Aug  5 15:00:29.217: INFO: (8) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 6.030218ms)
Aug  5 15:00:29.218: INFO: (8) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 6.503958ms)
Aug  5 15:00:29.218: INFO: (8) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 6.356853ms)
Aug  5 15:00:29.224: INFO: (9) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 5.576438ms)
Aug  5 15:00:29.224: INFO: (9) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 5.799193ms)
Aug  5 15:00:29.224: INFO: (9) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 6.410464ms)
Aug  5 15:00:29.225: INFO: (9) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 6.411324ms)
Aug  5 15:00:29.225: INFO: (9) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 6.455354ms)
Aug  5 15:00:29.225: INFO: (9) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 6.597957ms)
Aug  5 15:00:29.225: INFO: (9) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 6.587721ms)
Aug  5 15:00:29.225: INFO: (9) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 6.732602ms)
Aug  5 15:00:29.225: INFO: (9) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 6.651252ms)
Aug  5 15:00:29.225: INFO: (9) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 6.808392ms)
Aug  5 15:00:29.226: INFO: (9) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 7.553503ms)
Aug  5 15:00:29.226: INFO: (9) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 7.781677ms)
Aug  5 15:00:29.226: INFO: (9) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 8.402289ms)
Aug  5 15:00:29.226: INFO: (9) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 8.289968ms)
Aug  5 15:00:29.226: INFO: (9) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 8.467437ms)
Aug  5 15:00:29.226: INFO: (9) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 8.413207ms)
Aug  5 15:00:29.231: INFO: (10) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 4.686903ms)
Aug  5 15:00:29.231: INFO: (10) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 4.611101ms)
Aug  5 15:00:29.231: INFO: (10) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 4.919884ms)
Aug  5 15:00:29.233: INFO: (10) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 5.937831ms)
Aug  5 15:00:29.233: INFO: (10) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 5.879286ms)
Aug  5 15:00:29.233: INFO: (10) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 5.827137ms)
Aug  5 15:00:29.233: INFO: (10) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 5.689815ms)
Aug  5 15:00:29.233: INFO: (10) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 6.515994ms)
Aug  5 15:00:29.234: INFO: (10) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 6.786178ms)
Aug  5 15:00:29.235: INFO: (10) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 8.176792ms)
Aug  5 15:00:29.235: INFO: (10) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 8.035152ms)
Aug  5 15:00:29.236: INFO: (10) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 8.259624ms)
Aug  5 15:00:29.236: INFO: (10) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 8.922338ms)
Aug  5 15:00:29.236: INFO: (10) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 8.636696ms)
Aug  5 15:00:29.236: INFO: (10) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 8.503069ms)
Aug  5 15:00:29.236: INFO: (10) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 9.149236ms)
Aug  5 15:00:29.239: INFO: (11) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 2.777819ms)
Aug  5 15:00:29.239: INFO: (11) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 3.452826ms)
Aug  5 15:00:29.240: INFO: (11) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 3.794875ms)
Aug  5 15:00:29.240: INFO: (11) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 3.851808ms)
Aug  5 15:00:29.240: INFO: (11) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 3.990234ms)
Aug  5 15:00:29.241: INFO: (11) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 5.216238ms)
Aug  5 15:00:29.242: INFO: (11) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 5.716772ms)
Aug  5 15:00:29.242: INFO: (11) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 6.115117ms)
Aug  5 15:00:29.242: INFO: (11) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 6.258342ms)
Aug  5 15:00:29.243: INFO: (11) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 6.514369ms)
Aug  5 15:00:29.243: INFO: (11) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 6.35264ms)
Aug  5 15:00:29.243: INFO: (11) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 6.382492ms)
Aug  5 15:00:29.245: INFO: (11) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 8.563964ms)
Aug  5 15:00:29.245: INFO: (11) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 8.623332ms)
Aug  5 15:00:29.245: INFO: (11) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 8.768732ms)
Aug  5 15:00:29.245: INFO: (11) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 8.84164ms)
Aug  5 15:00:29.249: INFO: (12) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 3.47826ms)
Aug  5 15:00:29.252: INFO: (12) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 5.635398ms)
Aug  5 15:00:29.252: INFO: (12) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 5.502876ms)
Aug  5 15:00:29.252: INFO: (12) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 5.416076ms)
Aug  5 15:00:29.252: INFO: (12) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 5.986741ms)
Aug  5 15:00:29.252: INFO: (12) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 5.852223ms)
Aug  5 15:00:29.252: INFO: (12) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 6.404724ms)
Aug  5 15:00:29.253: INFO: (12) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 6.174218ms)
Aug  5 15:00:29.253: INFO: (12) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 6.337285ms)
Aug  5 15:00:29.253: INFO: (12) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 6.36135ms)
Aug  5 15:00:29.253: INFO: (12) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 6.939009ms)
Aug  5 15:00:29.253: INFO: (12) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 6.730666ms)
Aug  5 15:00:29.253: INFO: (12) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 7.171262ms)
Aug  5 15:00:29.254: INFO: (12) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 8.438588ms)
Aug  5 15:00:29.254: INFO: (12) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 8.514115ms)
Aug  5 15:00:29.254: INFO: (12) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 8.169018ms)
Aug  5 15:00:29.261: INFO: (13) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 5.77652ms)
Aug  5 15:00:29.261: INFO: (13) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 6.285859ms)
Aug  5 15:00:29.262: INFO: (13) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 6.639094ms)
Aug  5 15:00:29.262: INFO: (13) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 6.557577ms)
Aug  5 15:00:29.262: INFO: (13) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 6.712649ms)
Aug  5 15:00:29.262: INFO: (13) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 7.406203ms)
Aug  5 15:00:29.262: INFO: (13) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 7.237223ms)
Aug  5 15:00:29.263: INFO: (13) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 7.580785ms)
Aug  5 15:00:29.263: INFO: (13) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 7.769005ms)
Aug  5 15:00:29.263: INFO: (13) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 7.839053ms)
Aug  5 15:00:29.263: INFO: (13) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 7.9177ms)
Aug  5 15:00:29.263: INFO: (13) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 7.902112ms)
Aug  5 15:00:29.263: INFO: (13) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 7.764914ms)
Aug  5 15:00:29.263: INFO: (13) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 8.293462ms)
Aug  5 15:00:29.263: INFO: (13) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 8.856546ms)
Aug  5 15:00:29.263: INFO: (13) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 8.229252ms)
Aug  5 15:00:29.268: INFO: (14) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 4.582105ms)
Aug  5 15:00:29.268: INFO: (14) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 4.627105ms)
Aug  5 15:00:29.268: INFO: (14) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 4.403591ms)
Aug  5 15:00:29.268: INFO: (14) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 4.586347ms)
Aug  5 15:00:29.269: INFO: (14) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 4.796601ms)
Aug  5 15:00:29.269: INFO: (14) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 4.763716ms)
Aug  5 15:00:29.269: INFO: (14) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 5.067852ms)
Aug  5 15:00:29.270: INFO: (14) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 6.65502ms)
Aug  5 15:00:29.270: INFO: (14) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 6.610284ms)
Aug  5 15:00:29.270: INFO: (14) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 6.600144ms)
Aug  5 15:00:29.270: INFO: (14) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 6.571081ms)
Aug  5 15:00:29.270: INFO: (14) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 6.559896ms)
Aug  5 15:00:29.270: INFO: (14) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 6.669736ms)
Aug  5 15:00:29.270: INFO: (14) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 6.734346ms)
Aug  5 15:00:29.271: INFO: (14) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 7.426549ms)
Aug  5 15:00:29.271: INFO: (14) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 7.453377ms)
Aug  5 15:00:29.275: INFO: (15) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 2.991107ms)
Aug  5 15:00:29.277: INFO: (15) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 4.663091ms)
Aug  5 15:00:29.277: INFO: (15) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 5.025142ms)
Aug  5 15:00:29.278: INFO: (15) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 6.011015ms)
Aug  5 15:00:29.278: INFO: (15) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 5.848314ms)
Aug  5 15:00:29.278: INFO: (15) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 6.302417ms)
Aug  5 15:00:29.278: INFO: (15) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 6.311181ms)
Aug  5 15:00:29.279: INFO: (15) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 6.79181ms)
Aug  5 15:00:29.278: INFO: (15) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 6.464146ms)
Aug  5 15:00:29.279: INFO: (15) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 6.808684ms)
Aug  5 15:00:29.279: INFO: (15) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 7.015657ms)
Aug  5 15:00:29.280: INFO: (15) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 8.014935ms)
Aug  5 15:00:29.281: INFO: (15) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 9.574251ms)
Aug  5 15:00:29.281: INFO: (15) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 9.66323ms)
Aug  5 15:00:29.282: INFO: (15) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 9.73312ms)
Aug  5 15:00:29.282: INFO: (15) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 9.962887ms)
Aug  5 15:00:29.285: INFO: (16) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 2.86037ms)
Aug  5 15:00:29.286: INFO: (16) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 4.047286ms)
Aug  5 15:00:29.287: INFO: (16) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 3.888047ms)
Aug  5 15:00:29.287: INFO: (16) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 4.387861ms)
Aug  5 15:00:29.287: INFO: (16) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 4.603324ms)
Aug  5 15:00:29.287: INFO: (16) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 5.124059ms)
Aug  5 15:00:29.287: INFO: (16) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 4.604873ms)
Aug  5 15:00:29.287: INFO: (16) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 4.591816ms)
Aug  5 15:00:29.287: INFO: (16) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 5.131304ms)
Aug  5 15:00:29.289: INFO: (16) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 6.437897ms)
Aug  5 15:00:29.289: INFO: (16) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 6.150166ms)
Aug  5 15:00:29.289: INFO: (16) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 6.129032ms)
Aug  5 15:00:29.289: INFO: (16) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 6.594348ms)
Aug  5 15:00:29.289: INFO: (16) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 6.178451ms)
Aug  5 15:00:29.289: INFO: (16) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 6.550731ms)
Aug  5 15:00:29.289: INFO: (16) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 6.773445ms)
Aug  5 15:00:29.294: INFO: (17) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 5.028038ms)
Aug  5 15:00:29.295: INFO: (17) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 4.933322ms)
Aug  5 15:00:29.295: INFO: (17) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 5.170083ms)
Aug  5 15:00:29.295: INFO: (17) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 5.017667ms)
Aug  5 15:00:29.295: INFO: (17) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 5.33788ms)
Aug  5 15:00:29.295: INFO: (17) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 5.268326ms)
Aug  5 15:00:29.295: INFO: (17) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 5.82562ms)
Aug  5 15:00:29.295: INFO: (17) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 6.017248ms)
Aug  5 15:00:29.296: INFO: (17) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 5.964196ms)
Aug  5 15:00:29.296: INFO: (17) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 6.187866ms)
Aug  5 15:00:29.296: INFO: (17) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 6.205016ms)
Aug  5 15:00:29.297: INFO: (17) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 7.405258ms)
Aug  5 15:00:29.297: INFO: (17) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 7.487942ms)
Aug  5 15:00:29.297: INFO: (17) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 7.699508ms)
Aug  5 15:00:29.299: INFO: (17) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 9.274648ms)
Aug  5 15:00:29.299: INFO: (17) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 9.206993ms)
Aug  5 15:00:29.302: INFO: (18) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 3.179701ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 7.339551ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 8.53347ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 8.233628ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 8.475088ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 8.385201ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 8.611246ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 8.803622ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 8.180534ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 8.993628ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 8.602976ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 8.977964ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 8.348828ms)
Aug  5 15:00:29.308: INFO: (18) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 9.573865ms)
Aug  5 15:00:29.309: INFO: (18) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 8.505279ms)
Aug  5 15:00:29.309: INFO: (18) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 9.331738ms)
Aug  5 15:00:29.315: INFO: (19) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 5.655038ms)
Aug  5 15:00:29.315: INFO: (19) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">test<... (200; 5.390242ms)
Aug  5 15:00:29.315: INFO: (19) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname2/proxy/: bar (200; 6.082057ms)
Aug  5 15:00:29.315: INFO: (19) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:462/proxy/: tls qux (200; 5.745679ms)
Aug  5 15:00:29.315: INFO: (19) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:1080/proxy/rewriteme">... (200; 5.614958ms)
Aug  5 15:00:29.315: INFO: (19) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:460/proxy/: tls baz (200; 5.848079ms)
Aug  5 15:00:29.315: INFO: (19) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname1/proxy/: tls baz (200; 5.965966ms)
Aug  5 15:00:29.315: INFO: (19) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname1/proxy/: foo (200; 6.427292ms)
Aug  5 15:00:29.315: INFO: (19) /api/v1/namespaces/proxy-3944/services/http:proxy-service-k2jc9:portname1/proxy/: foo (200; 6.080022ms)
Aug  5 15:00:29.318: INFO: (19) /api/v1/namespaces/proxy-3944/services/proxy-service-k2jc9:portname2/proxy/: bar (200; 8.802302ms)
Aug  5 15:00:29.318: INFO: (19) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:162/proxy/: bar (200; 9.015073ms)
Aug  5 15:00:29.318: INFO: (19) /api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/https:proxy-service-k2jc9-cbcx5:443/proxy/tlsrewritem... (200; 8.970085ms)
Aug  5 15:00:29.318: INFO: (19) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/: <a href="/api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5/proxy/rewriteme">test</a> (200; 9.123346ms)
Aug  5 15:00:29.318: INFO: (19) /api/v1/namespaces/proxy-3944/pods/http:proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 9.401153ms)
Aug  5 15:00:29.318: INFO: (19) /api/v1/namespaces/proxy-3944/pods/proxy-service-k2jc9-cbcx5:160/proxy/: foo (200; 8.819751ms)
Aug  5 15:00:29.318: INFO: (19) /api/v1/namespaces/proxy-3944/services/https:proxy-service-k2jc9:tlsportname2/proxy/: tls qux (200; 8.700379ms)
STEP: deleting ReplicationController proxy-service-k2jc9 in namespace proxy-3944, will wait for the garbage collector to delete the pods
Aug  5 15:00:29.375: INFO: Deleting ReplicationController proxy-service-k2jc9 took: 4.829725ms
Aug  5 15:00:29.476: INFO: Terminating ReplicationController proxy-service-k2jc9 pods took: 100.983979ms
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Aug  5 15:00:32.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3944" for this suite.

â€¢ [SLOW TEST:5.036 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":356,"completed":212,"skipped":4034,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:00:32.085: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug  5 15:00:32.102: INFO: Waiting up to 1m0s for all nodes to be ready
Aug  5 15:01:32.120: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
Aug  5 15:01:32.132: INFO: Created pod: pod0-0-sched-preemption-low-priority
Aug  5 15:01:32.134: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Aug  5 15:01:32.142: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Aug  5 15:01:32.145: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:01:46.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7786" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

â€¢ [SLOW TEST:74.140 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":356,"completed":213,"skipped":4058,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:01:46.225: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 15:01:46.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1181" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
â€¢{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":356,"completed":214,"skipped":4071,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:01:46.275: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
Aug  5 15:01:46.285: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:02:01.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9461" for this suite.

â€¢ [SLOW TEST:15.643 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":356,"completed":215,"skipped":4072,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:02:01.918: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-67019990-3fb3-4a26-8031-e8e3cd3d2c24
STEP: Creating a pod to test consume configMaps
Aug  5 15:02:01.937: INFO: Waiting up to 5m0s for pod "pod-configmaps-ef2b28cc-ae40-45ff-bd79-961b98b77eaa" in namespace "configmap-6328" to be "Succeeded or Failed"
Aug  5 15:02:01.939: INFO: Pod "pod-configmaps-ef2b28cc-ae40-45ff-bd79-961b98b77eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 1.922088ms
Aug  5 15:02:03.943: INFO: Pod "pod-configmaps-ef2b28cc-ae40-45ff-bd79-961b98b77eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00619228s
Aug  5 15:02:05.948: INFO: Pod "pod-configmaps-ef2b28cc-ae40-45ff-bd79-961b98b77eaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011281929s
STEP: Saw pod success
Aug  5 15:02:05.948: INFO: Pod "pod-configmaps-ef2b28cc-ae40-45ff-bd79-961b98b77eaa" satisfied condition "Succeeded or Failed"
Aug  5 15:02:05.950: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-configmaps-ef2b28cc-ae40-45ff-bd79-961b98b77eaa container agnhost-container: <nil>
STEP: delete the pod
Aug  5 15:02:05.977: INFO: Waiting for pod pod-configmaps-ef2b28cc-ae40-45ff-bd79-961b98b77eaa to disappear
Aug  5 15:02:05.980: INFO: Pod pod-configmaps-ef2b28cc-ae40-45ff-bd79-961b98b77eaa no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 15:02:05.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6328" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":216,"skipped":4074,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:02:05.986: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 15:02:06.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7868" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
â€¢{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":356,"completed":217,"skipped":4093,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:02:06.008: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug  5 15:02:06.028: INFO: Waiting up to 5m0s for pod "pod-7ce16000-a831-45ed-a22c-76c0ee851266" in namespace "emptydir-8506" to be "Succeeded or Failed"
Aug  5 15:02:06.030: INFO: Pod "pod-7ce16000-a831-45ed-a22c-76c0ee851266": Phase="Pending", Reason="", readiness=false. Elapsed: 1.770778ms
Aug  5 15:02:08.036: INFO: Pod "pod-7ce16000-a831-45ed-a22c-76c0ee851266": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007954008s
Aug  5 15:02:10.040: INFO: Pod "pod-7ce16000-a831-45ed-a22c-76c0ee851266": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01244647s
STEP: Saw pod success
Aug  5 15:02:10.040: INFO: Pod "pod-7ce16000-a831-45ed-a22c-76c0ee851266" satisfied condition "Succeeded or Failed"
Aug  5 15:02:10.043: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-7ce16000-a831-45ed-a22c-76c0ee851266 container test-container: <nil>
STEP: delete the pod
Aug  5 15:02:10.054: INFO: Waiting for pod pod-7ce16000-a831-45ed-a22c-76c0ee851266 to disappear
Aug  5 15:02:10.056: INFO: Pod pod-7ce16000-a831-45ed-a22c-76c0ee851266 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 15:02:10.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8506" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":218,"skipped":4100,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:02:10.062: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
Aug  5 15:02:10.091: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug  5 15:02:15.102: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
Aug  5 15:02:15.105: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
Aug  5 15:02:15.110: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
Aug  5 15:02:15.112: INFO: Observed &ReplicaSet event: ADDED
Aug  5 15:02:15.112: INFO: Observed &ReplicaSet event: MODIFIED
Aug  5 15:02:15.112: INFO: Observed &ReplicaSet event: MODIFIED
Aug  5 15:02:15.112: INFO: Observed &ReplicaSet event: MODIFIED
Aug  5 15:02:15.112: INFO: Found replicaset test-rs in namespace replicaset-8056 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug  5 15:02:15.112: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
Aug  5 15:02:15.112: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug  5 15:02:15.116: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
Aug  5 15:02:15.117: INFO: Observed &ReplicaSet event: ADDED
Aug  5 15:02:15.117: INFO: Observed &ReplicaSet event: MODIFIED
Aug  5 15:02:15.117: INFO: Observed &ReplicaSet event: MODIFIED
Aug  5 15:02:15.118: INFO: Observed &ReplicaSet event: MODIFIED
Aug  5 15:02:15.118: INFO: Observed replicaset test-rs in namespace replicaset-8056 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug  5 15:02:15.118: INFO: Observed &ReplicaSet event: MODIFIED
Aug  5 15:02:15.118: INFO: Found replicaset test-rs in namespace replicaset-8056 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Aug  5 15:02:15.118: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Aug  5 15:02:15.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8056" for this suite.

â€¢ [SLOW TEST:5.062 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":356,"completed":219,"skipped":4110,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:02:15.124: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Aug  5 15:02:46.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4820" for this suite.

â€¢ [SLOW TEST:31.231 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":356,"completed":220,"skipped":4128,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:02:46.355: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 15:02:47.060: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 15:02:50.080: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:02:50.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3195" for this suite.
STEP: Destroying namespace "webhook-3195-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":356,"completed":221,"skipped":4131,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:02:50.117: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:02:50.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:02:51.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3974" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":356,"completed":222,"skipped":4180,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:02:51.173: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Aug  5 15:02:53.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9702" for this suite.
â€¢{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","total":356,"completed":223,"skipped":4200,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:02:53.201: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-2333
STEP: creating service affinity-nodeport in namespace services-2333
STEP: creating replication controller affinity-nodeport in namespace services-2333
I0805 15:02:53.218468      18 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-2333, replica count: 3
I0805 15:02:56.269337      18 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 15:02:56.277: INFO: Creating new exec pod
Aug  5 15:02:59.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2333 exec execpod-affinitykcdm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Aug  5 15:02:59.431: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Aug  5 15:02:59.431: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:02:59.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2333 exec execpod-affinitykcdm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.102.186.49 80'
Aug  5 15:02:59.547: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.102.186.49 80\nConnection to 10.102.186.49 80 port [tcp/http] succeeded!\n"
Aug  5 15:02:59.547: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:02:59.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2333 exec execpod-affinitykcdm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.4 31708'
Aug  5 15:02:59.659: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.96.4 31708\nConnection to 10.1.96.4 31708 port [tcp/*] succeeded!\n"
Aug  5 15:02:59.659: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:02:59.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2333 exec execpod-affinitykcdm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.5 31708'
Aug  5 15:02:59.771: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.96.5 31708\nConnection to 10.1.96.5 31708 port [tcp/*] succeeded!\n"
Aug  5 15:02:59.771: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:02:59.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2333 exec execpod-affinitykcdm7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.96.4:31708/ ; done'
Aug  5 15:02:59.946: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31708/\n"
Aug  5 15:02:59.946: INFO: stdout: "\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk\naffinity-nodeport-x45xk"
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Received response from host: affinity-nodeport-x45xk
Aug  5 15:02:59.946: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-2333, will wait for the garbage collector to delete the pods
Aug  5 15:03:00.012: INFO: Deleting ReplicationController affinity-nodeport took: 3.620979ms
Aug  5 15:03:00.112: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.534311ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 15:03:02.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2333" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:9.229 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":224,"skipped":4214,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:03:02.431: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating cluster-info
Aug  5 15:03:02.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-2454 cluster-info'
Aug  5 15:03:02.518: INFO: stderr: ""
Aug  5 15:03:02.518: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 15:03:02.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2454" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":356,"completed":225,"skipped":4226,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:03:02.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:03:02.544: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:03:05.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6346" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":356,"completed":226,"skipped":4233,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:03:05.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a collection of services
Aug  5 15:03:05.652: INFO: Creating e2e-svc-a-4jr66
Aug  5 15:03:05.657: INFO: Creating e2e-svc-b-lwt5g
Aug  5 15:03:05.663: INFO: Creating e2e-svc-c-zgm4b
STEP: deleting service collection
Aug  5 15:03:05.689: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 15:03:05.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6051" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
â€¢{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","total":356,"completed":227,"skipped":4258,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:03:05.695: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Aug  5 15:03:05.707: INFO: Waiting up to 1m0s for all nodes to be ready
Aug  5 15:04:05.725: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:04:05.728: INFO: Starting informer...
STEP: Starting pods...
Aug  5 15:04:05.940: INFO: Pod1 is running on vke-automated-test-82a4b3cb9b0e. Tainting Node
Aug  5 15:04:08.155: INFO: Pod2 is running on vke-automated-test-82a4b3cb9b0e. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Aug  5 15:04:14.489: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Aug  5 15:04:33.820: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:04:33.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-1474" for this suite.

â€¢ [SLOW TEST:88.149 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":356,"completed":228,"skipped":4277,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:04:33.846: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in volume subpath
Aug  5 15:04:33.863: INFO: Waiting up to 5m0s for pod "var-expansion-030efff8-7630-4ddf-85de-d63404773f17" in namespace "var-expansion-2521" to be "Succeeded or Failed"
Aug  5 15:04:33.865: INFO: Pod "var-expansion-030efff8-7630-4ddf-85de-d63404773f17": Phase="Pending", Reason="", readiness=false. Elapsed: 1.642763ms
Aug  5 15:04:35.869: INFO: Pod "var-expansion-030efff8-7630-4ddf-85de-d63404773f17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006149994s
Aug  5 15:04:37.875: INFO: Pod "var-expansion-030efff8-7630-4ddf-85de-d63404773f17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011907838s
STEP: Saw pod success
Aug  5 15:04:37.875: INFO: Pod "var-expansion-030efff8-7630-4ddf-85de-d63404773f17" satisfied condition "Succeeded or Failed"
Aug  5 15:04:37.877: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod var-expansion-030efff8-7630-4ddf-85de-d63404773f17 container dapi-container: <nil>
STEP: delete the pod
Aug  5 15:04:37.899: INFO: Waiting for pod var-expansion-030efff8-7630-4ddf-85de-d63404773f17 to disappear
Aug  5 15:04:37.901: INFO: Pod var-expansion-030efff8-7630-4ddf-85de-d63404773f17 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Aug  5 15:04:37.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2521" for this suite.
â€¢{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":356,"completed":229,"skipped":4287,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:04:37.913: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
Aug  5 15:04:37.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2198" for this suite.
â€¢{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":230,"skipped":4371,"failed":0}

------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:04:37.965: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-4ee6fafc-c267-4e46-a997-8782092a6252
STEP: Creating a pod to test consume configMaps
Aug  5 15:04:37.985: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c710475e-b586-470e-8f27-770fd6bdd227" in namespace "projected-3130" to be "Succeeded or Failed"
Aug  5 15:04:37.987: INFO: Pod "pod-projected-configmaps-c710475e-b586-470e-8f27-770fd6bdd227": Phase="Pending", Reason="", readiness=false. Elapsed: 2.402192ms
Aug  5 15:04:39.993: INFO: Pod "pod-projected-configmaps-c710475e-b586-470e-8f27-770fd6bdd227": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008482631s
Aug  5 15:04:42.001: INFO: Pod "pod-projected-configmaps-c710475e-b586-470e-8f27-770fd6bdd227": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016678673s
STEP: Saw pod success
Aug  5 15:04:42.001: INFO: Pod "pod-projected-configmaps-c710475e-b586-470e-8f27-770fd6bdd227" satisfied condition "Succeeded or Failed"
Aug  5 15:04:42.004: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-configmaps-c710475e-b586-470e-8f27-770fd6bdd227 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 15:04:42.014: INFO: Waiting for pod pod-projected-configmaps-c710475e-b586-470e-8f27-770fd6bdd227 to disappear
Aug  5 15:04:42.016: INFO: Pod pod-projected-configmaps-c710475e-b586-470e-8f27-770fd6bdd227 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Aug  5 15:04:42.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3130" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":231,"skipped":4371,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:04:42.022: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  5 15:04:46.057: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Aug  5 15:04:46.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6320" for this suite.
â€¢{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":232,"skipped":4398,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:04:46.067: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-ea6319ed-fca3-482f-b737-c83a106afe98
STEP: Creating a pod to test consume secrets
Aug  5 15:04:46.084: INFO: Waiting up to 5m0s for pod "pod-secrets-6d7b3169-6a0d-4eb9-8a77-afdc47417652" in namespace "secrets-1006" to be "Succeeded or Failed"
Aug  5 15:04:46.086: INFO: Pod "pod-secrets-6d7b3169-6a0d-4eb9-8a77-afdc47417652": Phase="Pending", Reason="", readiness=false. Elapsed: 1.747296ms
Aug  5 15:04:48.092: INFO: Pod "pod-secrets-6d7b3169-6a0d-4eb9-8a77-afdc47417652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007770885s
Aug  5 15:04:50.099: INFO: Pod "pod-secrets-6d7b3169-6a0d-4eb9-8a77-afdc47417652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014374377s
STEP: Saw pod success
Aug  5 15:04:50.099: INFO: Pod "pod-secrets-6d7b3169-6a0d-4eb9-8a77-afdc47417652" satisfied condition "Succeeded or Failed"
Aug  5 15:04:50.101: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-secrets-6d7b3169-6a0d-4eb9-8a77-afdc47417652 container secret-volume-test: <nil>
STEP: delete the pod
Aug  5 15:04:50.111: INFO: Waiting for pod pod-secrets-6d7b3169-6a0d-4eb9-8a77-afdc47417652 to disappear
Aug  5 15:04:50.112: INFO: Pod pod-secrets-6d7b3169-6a0d-4eb9-8a77-afdc47417652 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Aug  5 15:04:50.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1006" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":233,"skipped":4406,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:04:50.118: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  5 15:04:50.144: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 15:04:50.144: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 15:04:51.149: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 15:04:51.150: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 15:04:52.149: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug  5 15:04:52.149: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug  5 15:04:52.169: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 15:04:52.170: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 15:04:53.179: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 15:04:53.179: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 15:04:54.179: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug  5 15:04:54.179: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5645, will wait for the garbage collector to delete the pods
Aug  5 15:04:54.237: INFO: Deleting DaemonSet.extensions daemon-set took: 3.238011ms
Aug  5 15:04:54.337: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.560803ms
Aug  5 15:04:56.640: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 15:04:56.641: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug  5 15:04:56.642: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25950"},"items":null}

Aug  5 15:04:56.644: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25950"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:04:56.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5645" for this suite.

â€¢ [SLOW TEST:6.534 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":356,"completed":234,"skipped":4428,"failed":0}
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:04:56.653: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Aug  5 15:04:56.666: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Aug  5 15:04:59.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4584" for this suite.
â€¢{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":356,"completed":235,"skipped":4435,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:04:59.609: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service endpoint-test2 in namespace services-2784
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2784 to expose endpoints map[]
Aug  5 15:04:59.633: INFO: successfully validated that service endpoint-test2 in namespace services-2784 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2784
Aug  5 15:04:59.639: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:05:01.647: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2784 to expose endpoints map[pod1:[80]]
Aug  5 15:05:01.655: INFO: successfully validated that service endpoint-test2 in namespace services-2784 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
Aug  5 15:05:01.655: INFO: Creating new exec pod
Aug  5 15:05:04.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2784 exec execpod8c6ns -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug  5 15:05:04.866: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug  5 15:05:04.866: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:05:04.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2784 exec execpod8c6ns -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.240.57 80'
Aug  5 15:05:05.033: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.106.240.57 80\nConnection to 10.106.240.57 80 port [tcp/http] succeeded!\n"
Aug  5 15:05:05.033: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-2784
Aug  5 15:05:05.038: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:05:07.045: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2784 to expose endpoints map[pod1:[80] pod2:[80]]
Aug  5 15:05:07.054: INFO: successfully validated that service endpoint-test2 in namespace services-2784 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
Aug  5 15:05:08.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2784 exec execpod8c6ns -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug  5 15:05:08.159: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug  5 15:05:08.159: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:05:08.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2784 exec execpod8c6ns -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.240.57 80'
Aug  5 15:05:08.277: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.106.240.57 80\nConnection to 10.106.240.57 80 port [tcp/http] succeeded!\n"
Aug  5 15:05:08.277: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2784
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2784 to expose endpoints map[pod2:[80]]
Aug  5 15:05:08.312: INFO: successfully validated that service endpoint-test2 in namespace services-2784 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
Aug  5 15:05:09.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2784 exec execpod8c6ns -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug  5 15:05:09.446: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug  5 15:05:09.446: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:05:09.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-2784 exec execpod8c6ns -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.240.57 80'
Aug  5 15:05:09.570: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.106.240.57 80\nConnection to 10.106.240.57 80 port [tcp/http] succeeded!\n"
Aug  5 15:05:09.570: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-2784
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2784 to expose endpoints map[]
Aug  5 15:05:10.587: INFO: successfully validated that service endpoint-test2 in namespace services-2784 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 15:05:10.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2784" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:10.992 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":356,"completed":236,"skipped":4443,"failed":0}
SSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:10.601: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:188
Aug  5 15:05:10.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-949" for this suite.
â€¢{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":356,"completed":237,"skipped":4448,"failed":0}
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:10.637: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replication controller my-hostname-basic-c7debd6f-56ed-45cb-a217-26fd63fc20b0
Aug  5 15:05:10.655: INFO: Pod name my-hostname-basic-c7debd6f-56ed-45cb-a217-26fd63fc20b0: Found 0 pods out of 1
Aug  5 15:05:15.663: INFO: Pod name my-hostname-basic-c7debd6f-56ed-45cb-a217-26fd63fc20b0: Found 1 pods out of 1
Aug  5 15:05:15.663: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c7debd6f-56ed-45cb-a217-26fd63fc20b0" are running
Aug  5 15:05:15.665: INFO: Pod "my-hostname-basic-c7debd6f-56ed-45cb-a217-26fd63fc20b0-7hpm8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-05 15:05:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-05 15:05:11 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-05 15:05:11 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-05 15:05:10 +0000 UTC Reason: Message:}])
Aug  5 15:05:15.665: INFO: Trying to dial the pod
Aug  5 15:05:20.681: INFO: Controller my-hostname-basic-c7debd6f-56ed-45cb-a217-26fd63fc20b0: Got expected result from replica 1 [my-hostname-basic-c7debd6f-56ed-45cb-a217-26fd63fc20b0-7hpm8]: "my-hostname-basic-c7debd6f-56ed-45cb-a217-26fd63fc20b0-7hpm8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Aug  5 15:05:20.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9114" for this suite.

â€¢ [SLOW TEST:10.050 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":238,"skipped":4455,"failed":0}
SSSSSS
------------------------------
[sig-network] EndpointSliceMirroring 
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:20.687: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
STEP: mirroring a new custom Endpoint
Aug  5 15:05:20.706: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint
Aug  5 15:05:22.714: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint
Aug  5 15:05:24.724: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:188
Aug  5 15:05:26.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-3000" for this suite.

â€¢ [SLOW TEST:6.047 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":356,"completed":239,"skipped":4461,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:26.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
Aug  5 15:05:26.753: INFO: created test-event-1
Aug  5 15:05:26.755: INFO: created test-event-2
Aug  5 15:05:26.756: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
Aug  5 15:05:26.758: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
Aug  5 15:05:26.764: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
Aug  5 15:05:26.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3738" for this suite.
â€¢{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":356,"completed":240,"skipped":4487,"failed":0}

------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:26.773: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap that has name configmap-test-emptyKey-8d2e7d3a-5864-497d-9a4e-372f73742f86
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 15:05:26.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2821" for this suite.
â€¢{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":356,"completed":241,"skipped":4487,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:26.811: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug  5 15:05:26.831: INFO: Waiting up to 5m0s for pod "pod-63416ec8-8c18-43dd-ba4e-f96a104fef67" in namespace "emptydir-7660" to be "Succeeded or Failed"
Aug  5 15:05:26.833: INFO: Pod "pod-63416ec8-8c18-43dd-ba4e-f96a104fef67": Phase="Pending", Reason="", readiness=false. Elapsed: 1.654184ms
Aug  5 15:05:28.843: INFO: Pod "pod-63416ec8-8c18-43dd-ba4e-f96a104fef67": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01214639s
Aug  5 15:05:30.849: INFO: Pod "pod-63416ec8-8c18-43dd-ba4e-f96a104fef67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01757109s
STEP: Saw pod success
Aug  5 15:05:30.849: INFO: Pod "pod-63416ec8-8c18-43dd-ba4e-f96a104fef67" satisfied condition "Succeeded or Failed"
Aug  5 15:05:30.851: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-63416ec8-8c18-43dd-ba4e-f96a104fef67 container test-container: <nil>
STEP: delete the pod
Aug  5 15:05:30.866: INFO: Waiting for pod pod-63416ec8-8c18-43dd-ba4e-f96a104fef67 to disappear
Aug  5 15:05:30.868: INFO: Pod pod-63416ec8-8c18-43dd-ba4e-f96a104fef67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 15:05:30.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7660" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":242,"skipped":4511,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:30.874: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 15:05:31.328: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 15:05:34.342: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:05:34.346: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:05:37.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5141" for this suite.
STEP: Destroying namespace "webhook-5141-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

â€¢ [SLOW TEST:6.587 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":356,"completed":243,"skipped":4517,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:37.462: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-4170
STEP: creating service affinity-nodeport-transition in namespace services-4170
STEP: creating replication controller affinity-nodeport-transition in namespace services-4170
I0805 15:05:37.498037      18 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4170, replica count: 3
I0805 15:05:40.549705      18 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 15:05:40.559: INFO: Creating new exec pod
Aug  5 15:05:43.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-4170 exec execpod-affinityghd8q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Aug  5 15:05:43.686: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Aug  5 15:05:43.686: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:05:43.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-4170 exec execpod-affinityghd8q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.240.215 80'
Aug  5 15:05:43.811: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.104.240.215 80\nConnection to 10.104.240.215 80 port [tcp/http] succeeded!\n"
Aug  5 15:05:43.811: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:05:43.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-4170 exec execpod-affinityghd8q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.4 31776'
Aug  5 15:05:43.945: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.96.4 31776\nConnection to 10.1.96.4 31776 port [tcp/*] succeeded!\n"
Aug  5 15:05:43.945: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:05:43.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-4170 exec execpod-affinityghd8q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.96.5 31776'
Aug  5 15:05:44.063: INFO: stderr: "+ nc -v -t -w 2 10.1.96.5 31776\n+ echo hostName\nConnection to 10.1.96.5 31776 port [tcp/*] succeeded!\n"
Aug  5 15:05:44.063: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:05:44.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-4170 exec execpod-affinityghd8q -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.96.4:31776/ ; done'
Aug  5 15:05:44.264: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n"
Aug  5 15:05:44.264: INFO: stdout: "\naffinity-nodeport-transition-jwtjq\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-jwtjq\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-bbjpq\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-jwtjq\naffinity-nodeport-transition-jwtjq\naffinity-nodeport-transition-bbjpq\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-jwtjq\naffinity-nodeport-transition-2vfj9"
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-jwtjq
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-jwtjq
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-bbjpq
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-jwtjq
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-jwtjq
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-bbjpq
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-jwtjq
Aug  5 15:05:44.264: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-4170 exec execpod-affinityghd8q -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.96.4:31776/ ; done'
Aug  5 15:05:44.458: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.96.4:31776/\n"
Aug  5 15:05:44.458: INFO: stdout: "\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9\naffinity-nodeport-transition-2vfj9"
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Received response from host: affinity-nodeport-transition-2vfj9
Aug  5 15:05:44.458: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4170, will wait for the garbage collector to delete the pods
Aug  5 15:05:44.525: INFO: Deleting ReplicationController affinity-nodeport-transition took: 3.060871ms
Aug  5 15:05:44.627: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 102.168739ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 15:05:46.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4170" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:9.384 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":244,"skipped":4542,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:46.847: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6100.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6100.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6100.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6100.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  5 15:05:48.883: INFO: DNS probes using dns-test-d354dd9a-49d3-43c3-a7c2-cadf98b0635c succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6100.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6100.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6100.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6100.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  5 15:05:50.931: INFO: File wheezy_udp@dns-test-service-3.dns-6100.svc.cluster.local from pod  dns-6100/dns-test-f3ca98ab-5070-4434-8e6d-a6198846e4e8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  5 15:05:50.934: INFO: File jessie_udp@dns-test-service-3.dns-6100.svc.cluster.local from pod  dns-6100/dns-test-f3ca98ab-5070-4434-8e6d-a6198846e4e8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  5 15:05:50.934: INFO: Lookups using dns-6100/dns-test-f3ca98ab-5070-4434-8e6d-a6198846e4e8 failed for: [wheezy_udp@dns-test-service-3.dns-6100.svc.cluster.local jessie_udp@dns-test-service-3.dns-6100.svc.cluster.local]

Aug  5 15:05:55.941: INFO: DNS probes using dns-test-f3ca98ab-5070-4434-8e6d-a6198846e4e8 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6100.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6100.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6100.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6100.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  5 15:05:58.011: INFO: DNS probes using dns-test-750e8c4a-6f9f-4620-b7ca-c3d043e9eed9 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Aug  5 15:05:58.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6100" for this suite.

â€¢ [SLOW TEST:11.210 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":356,"completed":245,"skipped":4589,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:58.058: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug  5 15:05:59.195: INFO: starting watch
STEP: patching
STEP: updating
Aug  5 15:05:59.201: INFO: waiting for watch events with expected annotations
Aug  5 15:05:59.201: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:05:59.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-4699" for this suite.
â€¢{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":356,"completed":246,"skipped":4601,"failed":0}
SS
------------------------------
[sig-node] Pods 
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:05:59.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
Aug  5 15:05:59.254: INFO: observed Pod pod-test in namespace pods-1943 in phase Pending with labels: map[test-pod-static:true] & conditions []
Aug  5 15:05:59.259: INFO: observed Pod pod-test in namespace pods-1943 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC  }]
Aug  5 15:05:59.265: INFO: observed Pod pod-test in namespace pods-1943 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC  }]
Aug  5 15:05:59.699: INFO: observed Pod pod-test in namespace pods-1943 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC  }]
Aug  5 15:06:00.784: INFO: Found Pod pod-test in namespace pods-1943 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:06:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:06:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:05:59 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
Aug  5 15:06:00.861: INFO: observed event type MODIFIED
Aug  5 15:06:02.792: INFO: observed event type MODIFIED
Aug  5 15:06:03.013: INFO: observed event type MODIFIED
Aug  5 15:06:03.799: INFO: observed event type MODIFIED
Aug  5 15:06:03.802: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Aug  5 15:06:03.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1943" for this suite.
â€¢{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":356,"completed":247,"skipped":4603,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:03.812: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:06:03.834: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:06:05.839: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = false)
Aug  5 15:06:07.841: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = false)
Aug  5 15:06:09.839: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = false)
Aug  5 15:06:11.840: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = false)
Aug  5 15:06:13.840: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = false)
Aug  5 15:06:15.838: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = false)
Aug  5 15:06:17.841: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = false)
Aug  5 15:06:19.842: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = false)
Aug  5 15:06:21.840: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = false)
Aug  5 15:06:23.838: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = false)
Aug  5 15:06:25.839: INFO: The status of Pod test-webserver-e4e343f0-4900-470b-a10d-ab688eef1562 is Running (Ready = true)
Aug  5 15:06:25.841: INFO: Container started at 2022-08-05 15:06:04 +0000 UTC, pod became ready at 2022-08-05 15:06:24 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Aug  5 15:06:25.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6002" for this suite.

â€¢ [SLOW TEST:22.033 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":356,"completed":248,"skipped":4612,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:25.847: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug  5 15:06:25.872: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7786  03a4e372-ca6d-4635-ab3d-8b58a6b00a89 26879 0 2022-08-05 15:06:25 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-08-05 15:06:25 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:06:25.872: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7786  03a4e372-ca6d-4635-ab3d-8b58a6b00a89 26880 0 2022-08-05 15:06:25 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-08-05 15:06:25 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Aug  5 15:06:25.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7786" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":356,"completed":249,"skipped":4613,"failed":0}
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:25.879: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Aug  5 15:06:25.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2070" for this suite.
â€¢{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":356,"completed":250,"skipped":4620,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:25.910: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:06:25.926: INFO: The status of Pod busybox-scheduling-c833db53-db1a-48df-98b5-e0c7b86ab8c8 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:06:27.932: INFO: The status of Pod busybox-scheduling-c833db53-db1a-48df-98b5-e0c7b86ab8c8 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Aug  5 15:06:27.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6339" for this suite.
â€¢{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":356,"completed":251,"skipped":4631,"failed":0}
S
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:27.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Aug  5 15:06:27.958: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Aug  5 15:06:31.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7173" for this suite.
â€¢{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":356,"completed":252,"skipped":4632,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:31.895: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:06:31.907: INFO: Got root ca configmap in namespace "svcaccounts-2795"
Aug  5 15:06:31.909: INFO: Deleted root ca configmap in namespace "svcaccounts-2795"
STEP: waiting for a new root ca configmap created
Aug  5 15:06:32.413: INFO: Recreated root ca configmap in namespace "svcaccounts-2795"
Aug  5 15:06:32.415: INFO: Updated root ca configmap in namespace "svcaccounts-2795"
STEP: waiting for the root ca configmap reconciled
Aug  5 15:06:32.920: INFO: Reconciled root ca configmap in namespace "svcaccounts-2795"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Aug  5 15:06:32.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2795" for this suite.
â€¢{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":356,"completed":253,"skipped":4657,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:32.928: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Aug  5 15:06:43.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5265" for this suite.

â€¢ [SLOW TEST:11.046 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":356,"completed":254,"skipped":4668,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:43.974: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:06:43.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2948" for this suite.
STEP: Destroying namespace "nspatchtest-2c80c927-71ed-4732-a585-0cd22c495d1f-2325" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":356,"completed":255,"skipped":4682,"failed":0}
SS
------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:43.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:188
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug  5 15:06:44.021: INFO: starting watch
STEP: patching
STEP: updating
Aug  5 15:06:44.026: INFO: waiting for watch events with expected annotations
Aug  5 15:06:44.026: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:188
Aug  5 15:06:44.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-1348" for this suite.
â€¢{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":356,"completed":256,"skipped":4684,"failed":0}
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:44.043: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  5 15:06:47.081: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Aug  5 15:06:47.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8803" for this suite.
â€¢{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":257,"skipped":4691,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:47.092: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-b2fda8a1-8413-4d05-beae-e981ae18452b
STEP: Creating a pod to test consume configMaps
Aug  5 15:06:47.110: INFO: Waiting up to 5m0s for pod "pod-configmaps-a0348e69-a73b-4b76-ae78-26b5a841fd66" in namespace "configmap-9888" to be "Succeeded or Failed"
Aug  5 15:06:47.111: INFO: Pod "pod-configmaps-a0348e69-a73b-4b76-ae78-26b5a841fd66": Phase="Pending", Reason="", readiness=false. Elapsed: 1.426186ms
Aug  5 15:06:49.114: INFO: Pod "pod-configmaps-a0348e69-a73b-4b76-ae78-26b5a841fd66": Phase="Running", Reason="", readiness=false. Elapsed: 2.004230713s
Aug  5 15:06:51.119: INFO: Pod "pod-configmaps-a0348e69-a73b-4b76-ae78-26b5a841fd66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009681339s
STEP: Saw pod success
Aug  5 15:06:51.119: INFO: Pod "pod-configmaps-a0348e69-a73b-4b76-ae78-26b5a841fd66" satisfied condition "Succeeded or Failed"
Aug  5 15:06:51.121: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-configmaps-a0348e69-a73b-4b76-ae78-26b5a841fd66 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 15:06:51.130: INFO: Waiting for pod pod-configmaps-a0348e69-a73b-4b76-ae78-26b5a841fd66 to disappear
Aug  5 15:06:51.132: INFO: Pod pod-configmaps-a0348e69-a73b-4b76-ae78-26b5a841fd66 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 15:06:51.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9888" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":258,"skipped":4710,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:51.137: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug  5 15:06:51.151: INFO: Waiting up to 5m0s for pod "pod-30aeba1c-affb-45f9-bec7-ea5d9db763ba" in namespace "emptydir-7701" to be "Succeeded or Failed"
Aug  5 15:06:51.152: INFO: Pod "pod-30aeba1c-affb-45f9-bec7-ea5d9db763ba": Phase="Pending", Reason="", readiness=false. Elapsed: 1.435939ms
Aug  5 15:06:53.156: INFO: Pod "pod-30aeba1c-affb-45f9-bec7-ea5d9db763ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005226478s
Aug  5 15:06:55.159: INFO: Pod "pod-30aeba1c-affb-45f9-bec7-ea5d9db763ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007851436s
STEP: Saw pod success
Aug  5 15:06:55.159: INFO: Pod "pod-30aeba1c-affb-45f9-bec7-ea5d9db763ba" satisfied condition "Succeeded or Failed"
Aug  5 15:06:55.161: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-30aeba1c-affb-45f9-bec7-ea5d9db763ba container test-container: <nil>
STEP: delete the pod
Aug  5 15:06:55.172: INFO: Waiting for pod pod-30aeba1c-affb-45f9-bec7-ea5d9db763ba to disappear
Aug  5 15:06:55.173: INFO: Pod pod-30aeba1c-affb-45f9-bec7-ea5d9db763ba no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 15:06:55.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7701" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":259,"skipped":4711,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:55.178: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:06:55.190: INFO: Creating pod...
Aug  5 15:06:57.202: INFO: Creating service...
Aug  5 15:06:57.208: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/pods/agnhost/proxy/some/path/with/DELETE
Aug  5 15:06:57.216: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug  5 15:06:57.216: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/pods/agnhost/proxy/some/path/with/GET
Aug  5 15:06:57.218: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Aug  5 15:06:57.218: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/pods/agnhost/proxy/some/path/with/HEAD
Aug  5 15:06:57.222: INFO: http.Client request:HEAD | StatusCode:200
Aug  5 15:06:57.222: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/pods/agnhost/proxy/some/path/with/OPTIONS
Aug  5 15:06:57.224: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug  5 15:06:57.224: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/pods/agnhost/proxy/some/path/with/PATCH
Aug  5 15:06:57.226: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug  5 15:06:57.226: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/pods/agnhost/proxy/some/path/with/POST
Aug  5 15:06:57.229: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug  5 15:06:57.229: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/pods/agnhost/proxy/some/path/with/PUT
Aug  5 15:06:57.231: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug  5 15:06:57.231: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/services/test-service/proxy/some/path/with/DELETE
Aug  5 15:06:57.235: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug  5 15:06:57.235: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/services/test-service/proxy/some/path/with/GET
Aug  5 15:06:57.238: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Aug  5 15:06:57.238: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/services/test-service/proxy/some/path/with/HEAD
Aug  5 15:06:57.240: INFO: http.Client request:HEAD | StatusCode:200
Aug  5 15:06:57.240: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/services/test-service/proxy/some/path/with/OPTIONS
Aug  5 15:06:57.247: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug  5 15:06:57.247: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/services/test-service/proxy/some/path/with/PATCH
Aug  5 15:06:57.250: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug  5 15:06:57.250: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/services/test-service/proxy/some/path/with/POST
Aug  5 15:06:57.253: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug  5 15:06:57.253: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9252/services/test-service/proxy/some/path/with/PUT
Aug  5 15:06:57.256: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Aug  5 15:06:57.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9252" for this suite.
â€¢{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":356,"completed":260,"skipped":4772,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:06:57.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-d98599ae-6fb1-4b62-917f-32de1cdc5641
STEP: Creating a pod to test consume secrets
Aug  5 15:06:57.280: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6e1dcd50-e18d-4cbb-ab32-8317b00709ec" in namespace "projected-5972" to be "Succeeded or Failed"
Aug  5 15:06:57.282: INFO: Pod "pod-projected-secrets-6e1dcd50-e18d-4cbb-ab32-8317b00709ec": Phase="Pending", Reason="", readiness=false. Elapsed: 1.63201ms
Aug  5 15:06:59.288: INFO: Pod "pod-projected-secrets-6e1dcd50-e18d-4cbb-ab32-8317b00709ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007176725s
Aug  5 15:07:01.294: INFO: Pod "pod-projected-secrets-6e1dcd50-e18d-4cbb-ab32-8317b00709ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013386128s
STEP: Saw pod success
Aug  5 15:07:01.294: INFO: Pod "pod-projected-secrets-6e1dcd50-e18d-4cbb-ab32-8317b00709ec" satisfied condition "Succeeded or Failed"
Aug  5 15:07:01.296: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-secrets-6e1dcd50-e18d-4cbb-ab32-8317b00709ec container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  5 15:07:01.304: INFO: Waiting for pod pod-projected-secrets-6e1dcd50-e18d-4cbb-ab32-8317b00709ec to disappear
Aug  5 15:07:01.306: INFO: Pod pod-projected-secrets-6e1dcd50-e18d-4cbb-ab32-8317b00709ec no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Aug  5 15:07:01.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5972" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":261,"skipped":4780,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:07:01.312: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:07:14.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3528" for this suite.
STEP: Destroying namespace "nsdeletetest-1959" for this suite.
Aug  5 15:07:14.370: INFO: Namespace nsdeletetest-1959 was already deleted
STEP: Destroying namespace "nsdeletetest-9117" for this suite.

â€¢ [SLOW TEST:13.060 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":356,"completed":262,"skipped":4784,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:07:14.372: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-8036
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  5 15:07:14.383: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug  5 15:07:14.397: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:07:16.402: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:07:18.403: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:07:20.406: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:07:22.403: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:07:24.404: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:07:26.404: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:07:28.406: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:07:30.403: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:07:32.404: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:07:34.406: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug  5 15:07:36.404: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug  5 15:07:36.407: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Aug  5 15:07:48.428: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Aug  5 15:07:48.428: INFO: Going to poll 10.244.18.141 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Aug  5 15:07:48.429: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.18.141:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8036 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 15:07:48.429: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 15:07:48.430: INFO: ExecWithOptions: Clientset creation
Aug  5 15:07:48.430: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-8036/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.18.141%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug  5 15:07:48.501: INFO: Found all 1 expected endpoints: [netserver-0]
Aug  5 15:07:48.501: INFO: Going to poll 10.244.107.137 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Aug  5 15:07:48.504: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.107.137:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8036 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug  5 15:07:48.504: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 15:07:48.505: INFO: ExecWithOptions: Clientset creation
Aug  5 15:07:48.505: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-8036/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.107.137%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug  5 15:07:48.579: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Aug  5 15:07:48.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8036" for this suite.

â€¢ [SLOW TEST:34.213 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":263,"skipped":4807,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:07:48.585: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:07:48.600: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Aug  5 15:07:50.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-5581 --namespace=crd-publish-openapi-5581 create -f -'
Aug  5 15:07:51.224: INFO: stderr: ""
Aug  5 15:07:51.224: INFO: stdout: "e2e-test-crd-publish-openapi-8618-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug  5 15:07:51.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-5581 --namespace=crd-publish-openapi-5581 delete e2e-test-crd-publish-openapi-8618-crds test-cr'
Aug  5 15:07:51.279: INFO: stderr: ""
Aug  5 15:07:51.279: INFO: stdout: "e2e-test-crd-publish-openapi-8618-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Aug  5 15:07:51.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-5581 --namespace=crd-publish-openapi-5581 apply -f -'
Aug  5 15:07:51.443: INFO: stderr: ""
Aug  5 15:07:51.443: INFO: stdout: "e2e-test-crd-publish-openapi-8618-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug  5 15:07:51.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-5581 --namespace=crd-publish-openapi-5581 delete e2e-test-crd-publish-openapi-8618-crds test-cr'
Aug  5 15:07:51.557: INFO: stderr: ""
Aug  5 15:07:51.557: INFO: stdout: "e2e-test-crd-publish-openapi-8618-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Aug  5 15:07:51.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=crd-publish-openapi-5581 explain e2e-test-crd-publish-openapi-8618-crds'
Aug  5 15:07:51.730: INFO: stderr: ""
Aug  5 15:07:51.730: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8618-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:07:53.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5581" for this suite.

â€¢ [SLOW TEST:5.211 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":356,"completed":264,"skipped":4811,"failed":0}
SSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:07:53.796: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Aug  5 15:07:53.828: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Aug  5 15:07:53.832: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug  5 15:07:53.832: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Aug  5 15:07:53.838: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug  5 15:07:53.838: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Aug  5 15:07:53.846: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Aug  5 15:07:53.846: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Aug  5 15:08:00.887: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:188
Aug  5 15:08:00.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-2096" for this suite.

â€¢ [SLOW TEST:7.100 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":356,"completed":265,"skipped":4817,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:00.897: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:08:00.918: INFO: Create a RollingUpdate DaemonSet
Aug  5 15:08:00.921: INFO: Check that daemon pods launch on every node of the cluster
Aug  5 15:08:00.925: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 15:08:00.925: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 15:08:01.932: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug  5 15:08:01.932: INFO: Node vke-automated-test-82a4b3cb9b0e is running 0 daemon pod, expected 1
Aug  5 15:08:02.931: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug  5 15:08:02.931: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
Aug  5 15:08:02.931: INFO: Update the DaemonSet to trigger a rollout
Aug  5 15:08:02.936: INFO: Updating DaemonSet daemon-set
Aug  5 15:08:05.946: INFO: Roll back the DaemonSet before rollout is complete
Aug  5 15:08:05.950: INFO: Updating DaemonSet daemon-set
Aug  5 15:08:05.950: INFO: Make sure DaemonSet rollback is complete
Aug  5 15:08:05.953: INFO: Wrong image for pod: daemon-set-lvql2. Expected: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Aug  5 15:08:05.953: INFO: Pod daemon-set-lvql2 is not available
Aug  5 15:08:08.960: INFO: Pod daemon-set-btlqj is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5508, will wait for the garbage collector to delete the pods
Aug  5 15:08:09.027: INFO: Deleting DaemonSet.extensions daemon-set took: 8.336205ms
Aug  5 15:08:09.128: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.574424ms
Aug  5 15:08:11.234: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug  5 15:08:11.234: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug  5 15:08:11.236: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27806"},"items":null}

Aug  5 15:08:11.238: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27806"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:08:11.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5508" for this suite.

â€¢ [SLOW TEST:10.352 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":356,"completed":266,"skipped":4830,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:11.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 15:08:11.270: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e9f9e78-36ba-4d34-9e56-2393f1a7c8b0" in namespace "downward-api-7899" to be "Succeeded or Failed"
Aug  5 15:08:11.271: INFO: Pod "downwardapi-volume-9e9f9e78-36ba-4d34-9e56-2393f1a7c8b0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.552102ms
Aug  5 15:08:13.275: INFO: Pod "downwardapi-volume-9e9f9e78-36ba-4d34-9e56-2393f1a7c8b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005220941s
Aug  5 15:08:15.278: INFO: Pod "downwardapi-volume-9e9f9e78-36ba-4d34-9e56-2393f1a7c8b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008315969s
STEP: Saw pod success
Aug  5 15:08:15.278: INFO: Pod "downwardapi-volume-9e9f9e78-36ba-4d34-9e56-2393f1a7c8b0" satisfied condition "Succeeded or Failed"
Aug  5 15:08:15.280: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-9e9f9e78-36ba-4d34-9e56-2393f1a7c8b0 container client-container: <nil>
STEP: delete the pod
Aug  5 15:08:15.292: INFO: Waiting for pod downwardapi-volume-9e9f9e78-36ba-4d34-9e56-2393f1a7c8b0 to disappear
Aug  5 15:08:15.294: INFO: Pod downwardapi-volume-9e9f9e78-36ba-4d34-9e56-2393f1a7c8b0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 15:08:15.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7899" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":267,"skipped":4910,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:15.299: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  5 15:08:19.335: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Aug  5 15:08:19.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3798" for this suite.
â€¢{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":356,"completed":268,"skipped":4918,"failed":0}
SS
------------------------------
[sig-node] Security Context 
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:19.347: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Aug  5 15:08:19.364: INFO: Waiting up to 5m0s for pod "security-context-acd5544b-a7a4-45a8-b01b-8569205a0061" in namespace "security-context-5698" to be "Succeeded or Failed"
Aug  5 15:08:19.366: INFO: Pod "security-context-acd5544b-a7a4-45a8-b01b-8569205a0061": Phase="Pending", Reason="", readiness=false. Elapsed: 1.441398ms
Aug  5 15:08:21.372: INFO: Pod "security-context-acd5544b-a7a4-45a8-b01b-8569205a0061": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00714441s
Aug  5 15:08:23.376: INFO: Pod "security-context-acd5544b-a7a4-45a8-b01b-8569205a0061": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01164488s
STEP: Saw pod success
Aug  5 15:08:23.376: INFO: Pod "security-context-acd5544b-a7a4-45a8-b01b-8569205a0061" satisfied condition "Succeeded or Failed"
Aug  5 15:08:23.378: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod security-context-acd5544b-a7a4-45a8-b01b-8569205a0061 container test-container: <nil>
STEP: delete the pod
Aug  5 15:08:23.389: INFO: Waiting for pod security-context-acd5544b-a7a4-45a8-b01b-8569205a0061 to disappear
Aug  5 15:08:23.390: INFO: Pod security-context-acd5544b-a7a4-45a8-b01b-8569205a0061 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Aug  5 15:08:23.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5698" for this suite.
â€¢{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":269,"skipped":4920,"failed":0}
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:23.395: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug  5 15:08:23.421: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  5 15:08:23.426: INFO: Waiting for terminating namespaces to be deleted...
Aug  5 15:08:23.427: INFO: 
Logging pods the apiserver thinks is on node vke-automated-test-82a4b3cb9b0e before test
Aug  5 15:08:23.431: INFO: calico-node-2jtxk from kube-system started at 2022-08-05 14:11:50 +0000 UTC (1 container statuses recorded)
Aug  5 15:08:23.432: INFO: 	Container calico-node ready: true, restart count 0
Aug  5 15:08:23.432: INFO: csi-vultr-node-pmp6m from kube-system started at 2022-08-05 15:04:33 +0000 UTC (2 container statuses recorded)
Aug  5 15:08:23.432: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 15:08:23.432: INFO: 	Container driver-registrar ready: true, restart count 0
Aug  5 15:08:23.432: INFO: konnectivity-agent-rcdln from kube-system started at 2022-08-05 15:04:33 +0000 UTC (1 container statuses recorded)
Aug  5 15:08:23.432: INFO: 	Container konnectivity-agent ready: true, restart count 0
Aug  5 15:08:23.432: INFO: sonobuoy from sonobuoy started at 2022-08-05 14:12:25 +0000 UTC (1 container statuses recorded)
Aug  5 15:08:23.432: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  5 15:08:23.432: INFO: sonobuoy-e2e-job-5437b3f59c524af6 from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 15:08:23.432: INFO: 	Container e2e ready: true, restart count 0
Aug  5 15:08:23.432: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 15:08:23.432: INFO: sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-vnb9h from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 15:08:23.432: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 15:08:23.432: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  5 15:08:23.432: INFO: 
Logging pods the apiserver thinks is on node vke-automated-test-b1f24d775249 before test
Aug  5 15:08:23.437: INFO: calico-kube-controllers-56cdb7c587-zstqt from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 15:08:23.437: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug  5 15:08:23.437: INFO: calico-node-bc7zg from kube-system started at 2022-08-05 14:11:50 +0000 UTC (1 container statuses recorded)
Aug  5 15:08:23.437: INFO: 	Container calico-node ready: true, restart count 0
Aug  5 15:08:23.437: INFO: cluster-autoscaler-595d485b76-4kzzf from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 15:08:23.437: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Aug  5 15:08:23.437: INFO: coredns-75c8969664-pdxjk from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 15:08:23.437: INFO: 	Container coredns ready: true, restart count 0
Aug  5 15:08:23.437: INFO: coredns-75c8969664-xvmdn from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 15:08:23.437: INFO: 	Container coredns ready: true, restart count 0
Aug  5 15:08:23.437: INFO: csi-vultr-controller-0 from kube-system started at 2022-08-05 14:12:02 +0000 UTC (3 container statuses recorded)
Aug  5 15:08:23.437: INFO: 	Container csi-attacher ready: true, restart count 0
Aug  5 15:08:23.437: INFO: 	Container csi-provisioner ready: true, restart count 0
Aug  5 15:08:23.437: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 15:08:23.437: INFO: csi-vultr-node-5xrgd from kube-system started at 2022-08-05 14:12:02 +0000 UTC (2 container statuses recorded)
Aug  5 15:08:23.437: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 15:08:23.437: INFO: 	Container driver-registrar ready: true, restart count 0
Aug  5 15:08:23.437: INFO: konnectivity-agent-c72gb from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 15:08:23.437: INFO: 	Container konnectivity-agent ready: true, restart count 0
Aug  5 15:08:23.437: INFO: sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-zqktm from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 15:08:23.437: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 15:08:23.437: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-175fd2ec-4eb7-4570-922d-bdaf790e5ee8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-175fd2ec-4eb7-4570-922d-bdaf790e5ee8 off the node vke-automated-test-82a4b3cb9b0e
STEP: verifying the node doesn't have the label kubernetes.io/e2e-175fd2ec-4eb7-4570-922d-bdaf790e5ee8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:08:27.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-520" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
â€¢{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":356,"completed":270,"skipped":4921,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:27.533: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Aug  5 15:08:27.548: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
Aug  5 15:08:29.617: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:08:38.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3420" for this suite.

â€¢ [SLOW TEST:10.804 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":356,"completed":271,"skipped":4972,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:38.339: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 15:08:38.961: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 15:08:41.976: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:08:52.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6598" for this suite.
STEP: Destroying namespace "webhook-6598-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

â€¢ [SLOW TEST:13.765 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":356,"completed":272,"skipped":4973,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:52.106: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug  5 15:08:52.496: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 15:08:55.509: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:08:55.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9546" for this suite.
STEP: Destroying namespace "webhook-9546-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":356,"completed":273,"skipped":5022,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:55.580: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug  5 15:08:55.623: INFO: Waiting up to 5m0s for pod "pod-75e87c39-87a2-4ab1-8e34-84c66d5fb85a" in namespace "emptydir-2601" to be "Succeeded or Failed"
Aug  5 15:08:55.629: INFO: Pod "pod-75e87c39-87a2-4ab1-8e34-84c66d5fb85a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.311345ms
Aug  5 15:08:57.636: INFO: Pod "pod-75e87c39-87a2-4ab1-8e34-84c66d5fb85a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013419162s
Aug  5 15:08:59.639: INFO: Pod "pod-75e87c39-87a2-4ab1-8e34-84c66d5fb85a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016445553s
STEP: Saw pod success
Aug  5 15:08:59.640: INFO: Pod "pod-75e87c39-87a2-4ab1-8e34-84c66d5fb85a" satisfied condition "Succeeded or Failed"
Aug  5 15:08:59.641: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-75e87c39-87a2-4ab1-8e34-84c66d5fb85a container test-container: <nil>
STEP: delete the pod
Aug  5 15:08:59.651: INFO: Waiting for pod pod-75e87c39-87a2-4ab1-8e34-84c66d5fb85a to disappear
Aug  5 15:08:59.652: INFO: Pod pod-75e87c39-87a2-4ab1-8e34-84c66d5fb85a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 15:08:59.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2601" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":274,"skipped":5071,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:59.657: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating api versions
Aug  5 15:08:59.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5178 api-versions'
Aug  5 15:08:59.738: INFO: stderr: ""
Aug  5 15:08:59.738: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\ninternal.apiserver.k8s.io/v1alpha1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 15:08:59.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5178" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":356,"completed":275,"skipped":5105,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:59.747: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Aug  5 15:08:59.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4508" for this suite.
â€¢{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":356,"completed":276,"skipped":5134,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:08:59.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:08:59.781: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Creating first CR 
Aug  5 15:09:02.327: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-05T15:09:02Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-05T15:09:02Z]] name:name1 resourceVersion:28330 uid:9f9e8558-68ec-4c9d-a395-dba69f629e8c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Aug  5 15:09:12.337: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-05T15:09:12Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-05T15:09:12Z]] name:name2 resourceVersion:28373 uid:caaa3229-3a04-486f-a348-8156dbc747fb] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Aug  5 15:09:22.353: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-05T15:09:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-05T15:09:22Z]] name:name1 resourceVersion:28398 uid:9f9e8558-68ec-4c9d-a395-dba69f629e8c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Aug  5 15:09:32.367: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-05T15:09:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-05T15:09:32Z]] name:name2 resourceVersion:28423 uid:caaa3229-3a04-486f-a348-8156dbc747fb] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Aug  5 15:09:42.375: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-05T15:09:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-05T15:09:22Z]] name:name1 resourceVersion:28448 uid:9f9e8558-68ec-4c9d-a395-dba69f629e8c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Aug  5 15:09:52.388: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-05T15:09:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-05T15:09:32Z]] name:name2 resourceVersion:28473 uid:caaa3229-3a04-486f-a348-8156dbc747fb] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:10:02.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-9583" for this suite.

â€¢ [SLOW TEST:63.140 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":356,"completed":277,"skipped":5143,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:02.912: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test env composition
Aug  5 15:10:02.933: INFO: Waiting up to 5m0s for pod "var-expansion-8be0c342-100f-4336-9aaf-3093f7dc5bc6" in namespace "var-expansion-8677" to be "Succeeded or Failed"
Aug  5 15:10:02.935: INFO: Pod "var-expansion-8be0c342-100f-4336-9aaf-3093f7dc5bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.963181ms
Aug  5 15:10:04.941: INFO: Pod "var-expansion-8be0c342-100f-4336-9aaf-3093f7dc5bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00842021s
Aug  5 15:10:06.947: INFO: Pod "var-expansion-8be0c342-100f-4336-9aaf-3093f7dc5bc6": Phase="Running", Reason="", readiness=false. Elapsed: 4.013510089s
Aug  5 15:10:08.953: INFO: Pod "var-expansion-8be0c342-100f-4336-9aaf-3093f7dc5bc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019541264s
STEP: Saw pod success
Aug  5 15:10:08.953: INFO: Pod "var-expansion-8be0c342-100f-4336-9aaf-3093f7dc5bc6" satisfied condition "Succeeded or Failed"
Aug  5 15:10:08.955: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod var-expansion-8be0c342-100f-4336-9aaf-3093f7dc5bc6 container dapi-container: <nil>
STEP: delete the pod
Aug  5 15:10:08.967: INFO: Waiting for pod var-expansion-8be0c342-100f-4336-9aaf-3093f7dc5bc6 to disappear
Aug  5 15:10:08.972: INFO: Pod var-expansion-8be0c342-100f-4336-9aaf-3093f7dc5bc6 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Aug  5 15:10:08.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8677" for this suite.

â€¢ [SLOW TEST:6.066 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":356,"completed":278,"skipped":5170,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity 
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:08.980: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename csistoragecapacity
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/storage.k8s.io
STEP: getting /apis/storage.k8s.io/v1
STEP: creating
STEP: watching
Aug  5 15:10:09.005: INFO: starting watch
STEP: getting
STEP: listing in namespace
STEP: listing across namespaces
STEP: patching
STEP: updating
Aug  5 15:10:09.020: INFO: waiting for watch events with expected annotations in namespace
Aug  5 15:10:09.020: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:188
Aug  5 15:10:09.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-2819" for this suite.
â€¢{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","total":356,"completed":279,"skipped":5226,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:09.040: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-379
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-379
STEP: creating replication controller externalsvc in namespace services-379
I0805 15:10:09.067207      18 runners.go:193] Created replication controller with name: externalsvc, namespace: services-379, replica count: 2
I0805 15:10:12.118588      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Aug  5 15:10:12.130: INFO: Creating new exec pod
Aug  5 15:10:14.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-379 exec execpodntlwh -- /bin/sh -x -c nslookup clusterip-service.services-379.svc.cluster.local'
Aug  5 15:10:14.300: INFO: stderr: "+ nslookup clusterip-service.services-379.svc.cluster.local\n"
Aug  5 15:10:14.300: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-379.svc.cluster.local\tcanonical name = externalsvc.services-379.svc.cluster.local.\nName:\texternalsvc.services-379.svc.cluster.local\nAddress: 10.101.244.124\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-379, will wait for the garbage collector to delete the pods
Aug  5 15:10:14.357: INFO: Deleting ReplicationController externalsvc took: 3.465153ms
Aug  5 15:10:14.458: INFO: Terminating ReplicationController externalsvc pods took: 100.648559ms
Aug  5 15:10:16.467: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 15:10:16.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-379" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:7.436 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":356,"completed":280,"skipped":5253,"failed":0}
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:16.477: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-2954/configmap-test-f2fdff13-635a-46d4-b891-602a769377c1
STEP: Creating a pod to test consume configMaps
Aug  5 15:10:16.499: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ade2a86-d302-42a1-ae56-e4d601435215" in namespace "configmap-2954" to be "Succeeded or Failed"
Aug  5 15:10:16.501: INFO: Pod "pod-configmaps-8ade2a86-d302-42a1-ae56-e4d601435215": Phase="Pending", Reason="", readiness=false. Elapsed: 1.712945ms
Aug  5 15:10:18.507: INFO: Pod "pod-configmaps-8ade2a86-d302-42a1-ae56-e4d601435215": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007824635s
Aug  5 15:10:20.516: INFO: Pod "pod-configmaps-8ade2a86-d302-42a1-ae56-e4d601435215": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017146453s
STEP: Saw pod success
Aug  5 15:10:20.516: INFO: Pod "pod-configmaps-8ade2a86-d302-42a1-ae56-e4d601435215" satisfied condition "Succeeded or Failed"
Aug  5 15:10:20.518: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-configmaps-8ade2a86-d302-42a1-ae56-e4d601435215 container env-test: <nil>
STEP: delete the pod
Aug  5 15:10:20.529: INFO: Waiting for pod pod-configmaps-8ade2a86-d302-42a1-ae56-e4d601435215 to disappear
Aug  5 15:10:20.531: INFO: Pod pod-configmaps-8ade2a86-d302-42a1-ae56-e4d601435215 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 15:10:20.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2954" for this suite.
â€¢{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":356,"completed":281,"skipped":5260,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:20.539: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:10:20.557: INFO: Waiting up to 5m0s for pod "busybox-user-65534-abd3054d-4a9d-4e13-8989-85e19da65603" in namespace "security-context-test-739" to be "Succeeded or Failed"
Aug  5 15:10:20.559: INFO: Pod "busybox-user-65534-abd3054d-4a9d-4e13-8989-85e19da65603": Phase="Pending", Reason="", readiness=false. Elapsed: 1.662644ms
Aug  5 15:10:22.566: INFO: Pod "busybox-user-65534-abd3054d-4a9d-4e13-8989-85e19da65603": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008612675s
Aug  5 15:10:24.572: INFO: Pod "busybox-user-65534-abd3054d-4a9d-4e13-8989-85e19da65603": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014624864s
Aug  5 15:10:24.572: INFO: Pod "busybox-user-65534-abd3054d-4a9d-4e13-8989-85e19da65603" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Aug  5 15:10:24.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-739" for this suite.
â€¢{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":282,"skipped":5298,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:24.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 15:10:24.592: INFO: Waiting up to 5m0s for pod "downwardapi-volume-59577011-2888-42e4-a7dc-9cbe6952fc2a" in namespace "downward-api-6398" to be "Succeeded or Failed"
Aug  5 15:10:24.594: INFO: Pod "downwardapi-volume-59577011-2888-42e4-a7dc-9cbe6952fc2a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.465006ms
Aug  5 15:10:26.600: INFO: Pod "downwardapi-volume-59577011-2888-42e4-a7dc-9cbe6952fc2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008141762s
Aug  5 15:10:28.606: INFO: Pod "downwardapi-volume-59577011-2888-42e4-a7dc-9cbe6952fc2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014342962s
STEP: Saw pod success
Aug  5 15:10:28.606: INFO: Pod "downwardapi-volume-59577011-2888-42e4-a7dc-9cbe6952fc2a" satisfied condition "Succeeded or Failed"
Aug  5 15:10:28.608: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-59577011-2888-42e4-a7dc-9cbe6952fc2a container client-container: <nil>
STEP: delete the pod
Aug  5 15:10:28.618: INFO: Waiting for pod downwardapi-volume-59577011-2888-42e4-a7dc-9cbe6952fc2a to disappear
Aug  5 15:10:28.619: INFO: Pod downwardapi-volume-59577011-2888-42e4-a7dc-9cbe6952fc2a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 15:10:28.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6398" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":283,"skipped":5305,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:28.627: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-1d1a85db-2e7a-4849-8e79-e9ea6616f6e9
STEP: Creating a pod to test consume configMaps
Aug  5 15:10:28.645: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-de48d67d-60e9-461a-bcb2-b851840aa235" in namespace "projected-4033" to be "Succeeded or Failed"
Aug  5 15:10:28.647: INFO: Pod "pod-projected-configmaps-de48d67d-60e9-461a-bcb2-b851840aa235": Phase="Pending", Reason="", readiness=false. Elapsed: 1.628555ms
Aug  5 15:10:30.653: INFO: Pod "pod-projected-configmaps-de48d67d-60e9-461a-bcb2-b851840aa235": Phase="Running", Reason="", readiness=false. Elapsed: 2.008120624s
Aug  5 15:10:32.659: INFO: Pod "pod-projected-configmaps-de48d67d-60e9-461a-bcb2-b851840aa235": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014236845s
STEP: Saw pod success
Aug  5 15:10:32.659: INFO: Pod "pod-projected-configmaps-de48d67d-60e9-461a-bcb2-b851840aa235" satisfied condition "Succeeded or Failed"
Aug  5 15:10:32.661: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-configmaps-de48d67d-60e9-461a-bcb2-b851840aa235 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 15:10:32.671: INFO: Waiting for pod pod-projected-configmaps-de48d67d-60e9-461a-bcb2-b851840aa235 to disappear
Aug  5 15:10:32.672: INFO: Pod pod-projected-configmaps-de48d67d-60e9-461a-bcb2-b851840aa235 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Aug  5 15:10:32.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4033" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":284,"skipped":5350,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:32.677: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Aug  5 15:10:43.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-491" for this suite.

â€¢ [SLOW TEST:11.051 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":356,"completed":285,"skipped":5353,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:43.729: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
Aug  5 15:10:43.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 create -f -'
Aug  5 15:10:44.426: INFO: stderr: ""
Aug  5 15:10:44.426: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  5 15:10:44.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug  5 15:10:44.477: INFO: stderr: ""
Aug  5 15:10:44.477: INFO: stdout: "update-demo-nautilus-52jhp update-demo-nautilus-sbwlq "
Aug  5 15:10:44.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 get pods update-demo-nautilus-52jhp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:10:44.523: INFO: stderr: ""
Aug  5 15:10:44.523: INFO: stdout: ""
Aug  5 15:10:44.523: INFO: update-demo-nautilus-52jhp is created but not running
Aug  5 15:10:49.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug  5 15:10:49.593: INFO: stderr: ""
Aug  5 15:10:49.593: INFO: stdout: "update-demo-nautilus-52jhp update-demo-nautilus-sbwlq "
Aug  5 15:10:49.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 get pods update-demo-nautilus-52jhp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:10:49.639: INFO: stderr: ""
Aug  5 15:10:49.640: INFO: stdout: "true"
Aug  5 15:10:49.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 get pods update-demo-nautilus-52jhp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug  5 15:10:49.686: INFO: stderr: ""
Aug  5 15:10:49.686: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug  5 15:10:49.686: INFO: validating pod update-demo-nautilus-52jhp
Aug  5 15:10:49.694: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  5 15:10:49.695: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  5 15:10:49.695: INFO: update-demo-nautilus-52jhp is verified up and running
Aug  5 15:10:49.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 get pods update-demo-nautilus-sbwlq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:10:49.741: INFO: stderr: ""
Aug  5 15:10:49.741: INFO: stdout: "true"
Aug  5 15:10:49.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 get pods update-demo-nautilus-sbwlq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug  5 15:10:49.785: INFO: stderr: ""
Aug  5 15:10:49.785: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug  5 15:10:49.785: INFO: validating pod update-demo-nautilus-sbwlq
Aug  5 15:10:49.792: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  5 15:10:49.792: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  5 15:10:49.792: INFO: update-demo-nautilus-sbwlq is verified up and running
STEP: using delete to clean up resources
Aug  5 15:10:49.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 delete --grace-period=0 --force -f -'
Aug  5 15:10:49.838: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  5 15:10:49.838: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug  5 15:10:49.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 get rc,svc -l name=update-demo --no-headers'
Aug  5 15:10:49.915: INFO: stderr: "No resources found in kubectl-971 namespace.\n"
Aug  5 15:10:49.915: INFO: stdout: ""
Aug  5 15:10:49.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-971 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  5 15:10:49.973: INFO: stderr: ""
Aug  5 15:10:49.973: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 15:10:49.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-971" for this suite.

â€¢ [SLOW TEST:6.249 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should create and stop a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":356,"completed":286,"skipped":5393,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:49.980: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-projected-all-test-volume-f22bdea0-d1e2-4899-9c6e-5a1095725671
STEP: Creating secret with name secret-projected-all-test-volume-4133954a-13e6-405a-9402-c7c08aac88da
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug  5 15:10:50.003: INFO: Waiting up to 5m0s for pod "projected-volume-110a3119-8220-4066-b0a3-454560e27f27" in namespace "projected-1571" to be "Succeeded or Failed"
Aug  5 15:10:50.006: INFO: Pod "projected-volume-110a3119-8220-4066-b0a3-454560e27f27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.444291ms
Aug  5 15:10:52.013: INFO: Pod "projected-volume-110a3119-8220-4066-b0a3-454560e27f27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00940797s
Aug  5 15:10:54.017: INFO: Pod "projected-volume-110a3119-8220-4066-b0a3-454560e27f27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013419332s
STEP: Saw pod success
Aug  5 15:10:54.017: INFO: Pod "projected-volume-110a3119-8220-4066-b0a3-454560e27f27" satisfied condition "Succeeded or Failed"
Aug  5 15:10:54.018: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod projected-volume-110a3119-8220-4066-b0a3-454560e27f27 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug  5 15:10:54.031: INFO: Waiting for pod projected-volume-110a3119-8220-4066-b0a3-454560e27f27 to disappear
Aug  5 15:10:54.032: INFO: Pod projected-volume-110a3119-8220-4066-b0a3-454560e27f27 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:188
Aug  5 15:10:54.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1571" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":356,"completed":287,"skipped":5416,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:54.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-50548154-3260-426d-8368-dc766d1b2606
STEP: Creating a pod to test consume configMaps
Aug  5 15:10:54.059: INFO: Waiting up to 5m0s for pod "pod-configmaps-cb72a99e-2d3f-4f61-8e0a-6d5bc5af848f" in namespace "configmap-4181" to be "Succeeded or Failed"
Aug  5 15:10:54.061: INFO: Pod "pod-configmaps-cb72a99e-2d3f-4f61-8e0a-6d5bc5af848f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003814ms
Aug  5 15:10:56.066: INFO: Pod "pod-configmaps-cb72a99e-2d3f-4f61-8e0a-6d5bc5af848f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006834914s
Aug  5 15:10:58.072: INFO: Pod "pod-configmaps-cb72a99e-2d3f-4f61-8e0a-6d5bc5af848f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012714969s
STEP: Saw pod success
Aug  5 15:10:58.072: INFO: Pod "pod-configmaps-cb72a99e-2d3f-4f61-8e0a-6d5bc5af848f" satisfied condition "Succeeded or Failed"
Aug  5 15:10:58.074: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-configmaps-cb72a99e-2d3f-4f61-8e0a-6d5bc5af848f container agnhost-container: <nil>
STEP: delete the pod
Aug  5 15:10:58.083: INFO: Waiting for pod pod-configmaps-cb72a99e-2d3f-4f61-8e0a-6d5bc5af848f to disappear
Aug  5 15:10:58.084: INFO: Pod pod-configmaps-cb72a99e-2d3f-4f61-8e0a-6d5bc5af848f no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 15:10:58.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4181" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":288,"skipped":5446,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:10:58.089: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug  5 15:10:58.102: INFO: Waiting up to 5m0s for pod "pod-2e6f300c-ce8e-460d-be86-661a0f7f3fc2" in namespace "emptydir-9024" to be "Succeeded or Failed"
Aug  5 15:10:58.104: INFO: Pod "pod-2e6f300c-ce8e-460d-be86-661a0f7f3fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.710565ms
Aug  5 15:11:00.111: INFO: Pod "pod-2e6f300c-ce8e-460d-be86-661a0f7f3fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008404362s
Aug  5 15:11:02.115: INFO: Pod "pod-2e6f300c-ce8e-460d-be86-661a0f7f3fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013191989s
STEP: Saw pod success
Aug  5 15:11:02.115: INFO: Pod "pod-2e6f300c-ce8e-460d-be86-661a0f7f3fc2" satisfied condition "Succeeded or Failed"
Aug  5 15:11:02.117: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-2e6f300c-ce8e-460d-be86-661a0f7f3fc2 container test-container: <nil>
STEP: delete the pod
Aug  5 15:11:02.127: INFO: Waiting for pod pod-2e6f300c-ce8e-460d-be86-661a0f7f3fc2 to disappear
Aug  5 15:11:02.129: INFO: Pod pod-2e6f300c-ce8e-460d-be86-661a0f7f3fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 15:11:02.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9024" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":289,"skipped":5451,"failed":0}

------------------------------
[sig-apps] CronJob 
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:11:02.136: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Aug  5 15:13:00.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7433" for this suite.

â€¢ [SLOW TEST:118.050 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":356,"completed":290,"skipped":5451,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:00.188: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Aug  5 15:13:01.231: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0805 15:13:01.231577      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Aug  5 15:13:01.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9054" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":356,"completed":291,"skipped":5488,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:01.237: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:13:01.248: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: creating the pod
STEP: submitting the pod to kubernetes
Aug  5 15:13:01.254: INFO: The status of Pod pod-exec-websocket-75a409e6-735f-4365-ac5f-b0f80645ca09 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:13:03.261: INFO: The status of Pod pod-exec-websocket-75a409e6-735f-4365-ac5f-b0f80645ca09 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Aug  5 15:13:03.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5134" for this suite.
â€¢{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":356,"completed":292,"skipped":5508,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:03.336: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-ed0b5a71-d0c2-40c6-8009-4ab60a338150
STEP: Creating the pod
Aug  5 15:13:03.371: INFO: The status of Pod pod-configmaps-d2b4c670-7a85-4d5e-9749-d250abe77655 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:13:05.375: INFO: The status of Pod pod-configmaps-d2b4c670-7a85-4d5e-9749-d250abe77655 is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-ed0b5a71-d0c2-40c6-8009-4ab60a338150
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 15:13:07.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3085" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":293,"skipped":5510,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:07.414: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 15:13:07.436: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f16422fb-641a-4e98-895d-2769a626c0b1" in namespace "downward-api-8784" to be "Succeeded or Failed"
Aug  5 15:13:07.438: INFO: Pod "downwardapi-volume-f16422fb-641a-4e98-895d-2769a626c0b1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.677924ms
Aug  5 15:13:09.445: INFO: Pod "downwardapi-volume-f16422fb-641a-4e98-895d-2769a626c0b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008494784s
Aug  5 15:13:11.457: INFO: Pod "downwardapi-volume-f16422fb-641a-4e98-895d-2769a626c0b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021014793s
STEP: Saw pod success
Aug  5 15:13:11.458: INFO: Pod "downwardapi-volume-f16422fb-641a-4e98-895d-2769a626c0b1" satisfied condition "Succeeded or Failed"
Aug  5 15:13:11.461: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-f16422fb-641a-4e98-895d-2769a626c0b1 container client-container: <nil>
STEP: delete the pod
Aug  5 15:13:11.485: INFO: Waiting for pod downwardapi-volume-f16422fb-641a-4e98-895d-2769a626c0b1 to disappear
Aug  5 15:13:11.500: INFO: Pod downwardapi-volume-f16422fb-641a-4e98-895d-2769a626c0b1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 15:13:11.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8784" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":356,"completed":294,"skipped":5514,"failed":0}
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:11.506: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test service account token: 
Aug  5 15:13:11.520: INFO: Waiting up to 5m0s for pod "test-pod-b9a74b39-17e8-45a6-b51f-0ba77e37ea6b" in namespace "svcaccounts-63" to be "Succeeded or Failed"
Aug  5 15:13:11.521: INFO: Pod "test-pod-b9a74b39-17e8-45a6-b51f-0ba77e37ea6b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.252932ms
Aug  5 15:13:13.527: INFO: Pod "test-pod-b9a74b39-17e8-45a6-b51f-0ba77e37ea6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006798316s
Aug  5 15:13:15.530: INFO: Pod "test-pod-b9a74b39-17e8-45a6-b51f-0ba77e37ea6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01015498s
STEP: Saw pod success
Aug  5 15:13:15.530: INFO: Pod "test-pod-b9a74b39-17e8-45a6-b51f-0ba77e37ea6b" satisfied condition "Succeeded or Failed"
Aug  5 15:13:15.532: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod test-pod-b9a74b39-17e8-45a6-b51f-0ba77e37ea6b container agnhost-container: <nil>
STEP: delete the pod
Aug  5 15:13:15.546: INFO: Waiting for pod test-pod-b9a74b39-17e8-45a6-b51f-0ba77e37ea6b to disappear
Aug  5 15:13:15.547: INFO: Pod test-pod-b9a74b39-17e8-45a6-b51f-0ba77e37ea6b no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Aug  5 15:13:15.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-63" for this suite.
â€¢{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":356,"completed":295,"skipped":5524,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:15.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Aug  5 15:13:15.580: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:13:17.587: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Aug  5 15:13:17.594: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:13:19.601: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Aug  5 15:13:19.605: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  5 15:13:19.613: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  5 15:13:21.613: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  5 15:13:21.618: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  5 15:13:23.613: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  5 15:13:23.620: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Aug  5 15:13:23.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2078" for this suite.

â€¢ [SLOW TEST:8.074 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":356,"completed":296,"skipped":5600,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:23.631: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Aug  5 15:13:34.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7596" for this suite.

â€¢ [SLOW TEST:11.079 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":356,"completed":297,"skipped":5608,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:34.711: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pods
Aug  5 15:13:34.725: INFO: created test-pod-1
Aug  5 15:13:34.728: INFO: created test-pod-2
Aug  5 15:13:34.735: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running
Aug  5 15:13:34.735: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-1244' to be running and ready
Aug  5 15:13:34.741: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug  5 15:13:34.741: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug  5 15:13:34.741: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug  5 15:13:34.741: INFO: 0 / 3 pods in namespace 'pods-1244' are running and ready (0 seconds elapsed)
Aug  5 15:13:34.741: INFO: expected 0 pod replicas in namespace 'pods-1244', 0 are Running and Ready.
Aug  5 15:13:34.741: INFO: POD         NODE                             PHASE    GRACE  CONDITIONS
Aug  5 15:13:34.741: INFO: test-pod-1  vke-automated-test-82a4b3cb9b0e  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:13:34 +0000 UTC  }]
Aug  5 15:13:34.741: INFO: test-pod-2  vke-automated-test-82a4b3cb9b0e  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:13:34 +0000 UTC  }]
Aug  5 15:13:34.741: INFO: test-pod-3  vke-automated-test-82a4b3cb9b0e  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-05 15:13:34 +0000 UTC  }]
Aug  5 15:13:34.741: INFO: 
Aug  5 15:13:36.750: INFO: 3 / 3 pods in namespace 'pods-1244' are running and ready (2 seconds elapsed)
Aug  5 15:13:36.750: INFO: expected 0 pod replicas in namespace 'pods-1244', 0 are Running and Ready.
STEP: waiting for all pods to be deleted
Aug  5 15:13:36.760: INFO: Pod quantity 3 is different from expected quantity 0
Aug  5 15:13:37.766: INFO: Pod quantity 3 is different from expected quantity 0
Aug  5 15:13:38.765: INFO: Pod quantity 3 is different from expected quantity 0
Aug  5 15:13:39.765: INFO: Pod quantity 1 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Aug  5 15:13:40.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1244" for this suite.

â€¢ [SLOW TEST:6.060 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":356,"completed":298,"skipped":5658,"failed":0}
S
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:40.772: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-4067
STEP: creating service affinity-clusterip in namespace services-4067
STEP: creating replication controller affinity-clusterip in namespace services-4067
I0805 15:13:40.793943      18 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-4067, replica count: 3
I0805 15:13:43.845220      18 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 15:13:43.852: INFO: Creating new exec pod
Aug  5 15:13:46.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-4067 exec execpod-affinityvkbp9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Aug  5 15:13:47.006: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Aug  5 15:13:47.006: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:13:47.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-4067 exec execpod-affinityvkbp9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.173.137 80'
Aug  5 15:13:47.122: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.173.137 80\nConnection to 10.100.173.137 80 port [tcp/http] succeeded!\n"
Aug  5 15:13:47.122: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:13:47.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-4067 exec execpod-affinityvkbp9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.100.173.137:80/ ; done'
Aug  5 15:13:47.286: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.173.137:80/\n"
Aug  5 15:13:47.286: INFO: stdout: "\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs\naffinity-clusterip-792bs"
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.286: INFO: Received response from host: affinity-clusterip-792bs
Aug  5 15:13:47.287: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-4067, will wait for the garbage collector to delete the pods
Aug  5 15:13:47.365: INFO: Deleting ReplicationController affinity-clusterip took: 3.739575ms
Aug  5 15:13:47.466: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.955611ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 15:13:49.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4067" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:8.809 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":299,"skipped":5659,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:49.582: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-4aa4405c-3bb3-4ba7-9023-81c8e5ede06d
STEP: Creating a pod to test consume configMaps
Aug  5 15:13:49.617: INFO: Waiting up to 5m0s for pod "pod-configmaps-129cc9ea-3e48-45e4-8ad2-d5247839cce2" in namespace "configmap-8817" to be "Succeeded or Failed"
Aug  5 15:13:49.619: INFO: Pod "pod-configmaps-129cc9ea-3e48-45e4-8ad2-d5247839cce2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.117203ms
Aug  5 15:13:51.626: INFO: Pod "pod-configmaps-129cc9ea-3e48-45e4-8ad2-d5247839cce2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008935369s
Aug  5 15:13:53.631: INFO: Pod "pod-configmaps-129cc9ea-3e48-45e4-8ad2-d5247839cce2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01449053s
STEP: Saw pod success
Aug  5 15:13:53.631: INFO: Pod "pod-configmaps-129cc9ea-3e48-45e4-8ad2-d5247839cce2" satisfied condition "Succeeded or Failed"
Aug  5 15:13:53.633: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-configmaps-129cc9ea-3e48-45e4-8ad2-d5247839cce2 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  5 15:13:53.645: INFO: Waiting for pod pod-configmaps-129cc9ea-3e48-45e4-8ad2-d5247839cce2 to disappear
Aug  5 15:13:53.652: INFO: Pod pod-configmaps-129cc9ea-3e48-45e4-8ad2-d5247839cce2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 15:13:53.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8817" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":300,"skipped":5697,"failed":0}
S
------------------------------
[sig-apps] DisruptionController 
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:53.657: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Aug  5 15:13:59.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6487" for this suite.

â€¢ [SLOW TEST:6.052 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":356,"completed":301,"skipped":5698,"failed":0}
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:13:59.712: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-5195/configmap-test-8c74c0ee-24a6-4508-9552-62a428eb0015
STEP: Creating a pod to test consume configMaps
Aug  5 15:13:59.730: INFO: Waiting up to 5m0s for pod "pod-configmaps-c6513a5d-a2b6-4881-b9be-8e7f114fa90b" in namespace "configmap-5195" to be "Succeeded or Failed"
Aug  5 15:13:59.732: INFO: Pod "pod-configmaps-c6513a5d-a2b6-4881-b9be-8e7f114fa90b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.797063ms
Aug  5 15:14:01.739: INFO: Pod "pod-configmaps-c6513a5d-a2b6-4881-b9be-8e7f114fa90b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009254908s
Aug  5 15:14:03.747: INFO: Pod "pod-configmaps-c6513a5d-a2b6-4881-b9be-8e7f114fa90b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016783511s
STEP: Saw pod success
Aug  5 15:14:03.747: INFO: Pod "pod-configmaps-c6513a5d-a2b6-4881-b9be-8e7f114fa90b" satisfied condition "Succeeded or Failed"
Aug  5 15:14:03.749: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-configmaps-c6513a5d-a2b6-4881-b9be-8e7f114fa90b container env-test: <nil>
STEP: delete the pod
Aug  5 15:14:03.760: INFO: Waiting for pod pod-configmaps-c6513a5d-a2b6-4881-b9be-8e7f114fa90b to disappear
Aug  5 15:14:03.762: INFO: Pod pod-configmaps-c6513a5d-a2b6-4881-b9be-8e7f114fa90b no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 15:14:03.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5195" for this suite.
â€¢{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":302,"skipped":5706,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:14:03.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-50a0be5e-be0f-4986-b03c-9fa374f38129
STEP: Creating a pod to test consume secrets
Aug  5 15:14:03.789: INFO: Waiting up to 5m0s for pod "pod-secrets-2a783db1-1024-4ccd-9d93-0684dcd509b4" in namespace "secrets-6630" to be "Succeeded or Failed"
Aug  5 15:14:03.798: INFO: Pod "pod-secrets-2a783db1-1024-4ccd-9d93-0684dcd509b4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.512658ms
Aug  5 15:14:05.803: INFO: Pod "pod-secrets-2a783db1-1024-4ccd-9d93-0684dcd509b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013258818s
Aug  5 15:14:07.808: INFO: Pod "pod-secrets-2a783db1-1024-4ccd-9d93-0684dcd509b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019008637s
STEP: Saw pod success
Aug  5 15:14:07.808: INFO: Pod "pod-secrets-2a783db1-1024-4ccd-9d93-0684dcd509b4" satisfied condition "Succeeded or Failed"
Aug  5 15:14:07.810: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-secrets-2a783db1-1024-4ccd-9d93-0684dcd509b4 container secret-volume-test: <nil>
STEP: delete the pod
Aug  5 15:14:07.822: INFO: Waiting for pod pod-secrets-2a783db1-1024-4ccd-9d93-0684dcd509b4 to disappear
Aug  5 15:14:07.825: INFO: Pod pod-secrets-2a783db1-1024-4ccd-9d93-0684dcd509b4 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Aug  5 15:14:07.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6630" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":303,"skipped":5709,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:14:07.833: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's args
Aug  5 15:14:07.852: INFO: Waiting up to 5m0s for pod "var-expansion-1a2db09b-bef5-467d-84a5-e9647ab3aec0" in namespace "var-expansion-7628" to be "Succeeded or Failed"
Aug  5 15:14:07.857: INFO: Pod "var-expansion-1a2db09b-bef5-467d-84a5-e9647ab3aec0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.69604ms
Aug  5 15:14:09.863: INFO: Pod "var-expansion-1a2db09b-bef5-467d-84a5-e9647ab3aec0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010903463s
Aug  5 15:14:11.870: INFO: Pod "var-expansion-1a2db09b-bef5-467d-84a5-e9647ab3aec0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017916052s
STEP: Saw pod success
Aug  5 15:14:11.870: INFO: Pod "var-expansion-1a2db09b-bef5-467d-84a5-e9647ab3aec0" satisfied condition "Succeeded or Failed"
Aug  5 15:14:11.872: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod var-expansion-1a2db09b-bef5-467d-84a5-e9647ab3aec0 container dapi-container: <nil>
STEP: delete the pod
Aug  5 15:14:11.883: INFO: Waiting for pod var-expansion-1a2db09b-bef5-467d-84a5-e9647ab3aec0 to disappear
Aug  5 15:14:11.885: INFO: Pod var-expansion-1a2db09b-bef5-467d-84a5-e9647ab3aec0 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Aug  5 15:14:11.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7628" for this suite.
â€¢{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":356,"completed":304,"skipped":5799,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:14:11.891: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
Aug  5 15:14:13.968: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Aug  5 15:14:15.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2979" for this suite.
â€¢{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":356,"completed":305,"skipped":5809,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:14:15.994: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Aug  5 15:14:16.008: INFO: Waiting up to 5m0s for pod "security-context-204088e8-9569-4387-8017-09e0c3bcf049" in namespace "security-context-9788" to be "Succeeded or Failed"
Aug  5 15:14:16.010: INFO: Pod "security-context-204088e8-9569-4387-8017-09e0c3bcf049": Phase="Pending", Reason="", readiness=false. Elapsed: 1.583495ms
Aug  5 15:14:18.016: INFO: Pod "security-context-204088e8-9569-4387-8017-09e0c3bcf049": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007423274s
Aug  5 15:14:20.025: INFO: Pod "security-context-204088e8-9569-4387-8017-09e0c3bcf049": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016512107s
STEP: Saw pod success
Aug  5 15:14:20.025: INFO: Pod "security-context-204088e8-9569-4387-8017-09e0c3bcf049" satisfied condition "Succeeded or Failed"
Aug  5 15:14:20.027: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod security-context-204088e8-9569-4387-8017-09e0c3bcf049 container test-container: <nil>
STEP: delete the pod
Aug  5 15:14:20.038: INFO: Waiting for pod security-context-204088e8-9569-4387-8017-09e0c3bcf049 to disappear
Aug  5 15:14:20.040: INFO: Pod security-context-204088e8-9569-4387-8017-09e0c3bcf049 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Aug  5 15:14:20.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-9788" for this suite.
â€¢{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":306,"skipped":5827,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:14:20.046: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug  5 15:14:20.061: INFO: Waiting up to 5m0s for pod "pod-77b93595-3b66-474b-8f3a-d69d85ec1d84" in namespace "emptydir-6309" to be "Succeeded or Failed"
Aug  5 15:14:20.062: INFO: Pod "pod-77b93595-3b66-474b-8f3a-d69d85ec1d84": Phase="Pending", Reason="", readiness=false. Elapsed: 1.56355ms
Aug  5 15:14:22.066: INFO: Pod "pod-77b93595-3b66-474b-8f3a-d69d85ec1d84": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005727692s
Aug  5 15:14:24.073: INFO: Pod "pod-77b93595-3b66-474b-8f3a-d69d85ec1d84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012371791s
STEP: Saw pod success
Aug  5 15:14:24.073: INFO: Pod "pod-77b93595-3b66-474b-8f3a-d69d85ec1d84" satisfied condition "Succeeded or Failed"
Aug  5 15:14:24.075: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-77b93595-3b66-474b-8f3a-d69d85ec1d84 container test-container: <nil>
STEP: delete the pod
Aug  5 15:14:24.085: INFO: Waiting for pod pod-77b93595-3b66-474b-8f3a-d69d85ec1d84 to disappear
Aug  5 15:14:24.086: INFO: Pod pod-77b93595-3b66-474b-8f3a-d69d85ec1d84 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Aug  5 15:14:24.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6309" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":307,"skipped":5883,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:14:24.092: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
Aug  5 15:14:24.107: INFO: Creating simple deployment test-deployment-94dw9
Aug  5 15:14:24.112: INFO: deployment "test-deployment-94dw9" doesn't have the required revision set
STEP: Getting /status
Aug  5 15:14:26.122: INFO: Deployment test-deployment-94dw9 has Conditions: [{Available True 2022-08-05 15:14:25 +0000 UTC 2022-08-05 15:14:25 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-08-05 15:14:25 +0000 UTC 2022-08-05 15:14:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-94dw9-688c4d6789" has successfully progressed.}]
STEP: updating Deployment Status
Aug  5 15:14:26.127: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 15, 14, 25, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 15, 14, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 5, 15, 14, 25, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 5, 15, 14, 24, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-94dw9-688c4d6789\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
Aug  5 15:14:26.128: INFO: Observed &Deployment event: ADDED
Aug  5 15:14:26.128: INFO: Observed Deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-05 15:14:24 +0000 UTC 2022-08-05 15:14:24 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-94dw9-688c4d6789"}
Aug  5 15:14:26.128: INFO: Observed &Deployment event: MODIFIED
Aug  5 15:14:26.128: INFO: Observed Deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-05 15:14:24 +0000 UTC 2022-08-05 15:14:24 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-94dw9-688c4d6789"}
Aug  5 15:14:26.128: INFO: Observed Deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-05 15:14:24 +0000 UTC 2022-08-05 15:14:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug  5 15:14:26.129: INFO: Observed &Deployment event: MODIFIED
Aug  5 15:14:26.129: INFO: Observed Deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-05 15:14:24 +0000 UTC 2022-08-05 15:14:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug  5 15:14:26.129: INFO: Observed Deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-05 15:14:24 +0000 UTC 2022-08-05 15:14:24 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-94dw9-688c4d6789" is progressing.}
Aug  5 15:14:26.129: INFO: Observed &Deployment event: MODIFIED
Aug  5 15:14:26.129: INFO: Observed Deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-05 15:14:25 +0000 UTC 2022-08-05 15:14:25 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug  5 15:14:26.129: INFO: Observed Deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-05 15:14:25 +0000 UTC 2022-08-05 15:14:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-94dw9-688c4d6789" has successfully progressed.}
Aug  5 15:14:26.129: INFO: Observed &Deployment event: MODIFIED
Aug  5 15:14:26.129: INFO: Observed Deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-05 15:14:25 +0000 UTC 2022-08-05 15:14:25 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug  5 15:14:26.129: INFO: Observed Deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-05 15:14:25 +0000 UTC 2022-08-05 15:14:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-94dw9-688c4d6789" has successfully progressed.}
Aug  5 15:14:26.129: INFO: Found Deployment test-deployment-94dw9 in namespace deployment-9660 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug  5 15:14:26.129: INFO: Deployment test-deployment-94dw9 has an updated status
STEP: patching the Statefulset Status
Aug  5 15:14:26.129: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug  5 15:14:26.132: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
Aug  5 15:14:26.134: INFO: Observed &Deployment event: ADDED
Aug  5 15:14:26.134: INFO: Observed deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-05 15:14:24 +0000 UTC 2022-08-05 15:14:24 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-94dw9-688c4d6789"}
Aug  5 15:14:26.134: INFO: Observed &Deployment event: MODIFIED
Aug  5 15:14:26.134: INFO: Observed deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-05 15:14:24 +0000 UTC 2022-08-05 15:14:24 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-94dw9-688c4d6789"}
Aug  5 15:14:26.134: INFO: Observed deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-05 15:14:24 +0000 UTC 2022-08-05 15:14:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug  5 15:14:26.134: INFO: Observed &Deployment event: MODIFIED
Aug  5 15:14:26.134: INFO: Observed deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-05 15:14:24 +0000 UTC 2022-08-05 15:14:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug  5 15:14:26.134: INFO: Observed deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-05 15:14:24 +0000 UTC 2022-08-05 15:14:24 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-94dw9-688c4d6789" is progressing.}
Aug  5 15:14:26.135: INFO: Observed &Deployment event: MODIFIED
Aug  5 15:14:26.135: INFO: Observed deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-05 15:14:25 +0000 UTC 2022-08-05 15:14:25 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug  5 15:14:26.135: INFO: Observed deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-05 15:14:25 +0000 UTC 2022-08-05 15:14:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-94dw9-688c4d6789" has successfully progressed.}
Aug  5 15:14:26.135: INFO: Observed &Deployment event: MODIFIED
Aug  5 15:14:26.135: INFO: Observed deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-05 15:14:25 +0000 UTC 2022-08-05 15:14:25 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug  5 15:14:26.135: INFO: Observed deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-05 15:14:25 +0000 UTC 2022-08-05 15:14:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-94dw9-688c4d6789" has successfully progressed.}
Aug  5 15:14:26.135: INFO: Observed deployment test-deployment-94dw9 in namespace deployment-9660 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug  5 15:14:26.135: INFO: Observed &Deployment event: MODIFIED
Aug  5 15:14:26.135: INFO: Found deployment test-deployment-94dw9 in namespace deployment-9660 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Aug  5 15:14:26.135: INFO: Deployment test-deployment-94dw9 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug  5 15:14:26.137: INFO: Deployment "test-deployment-94dw9":
&Deployment{ObjectMeta:{test-deployment-94dw9  deployment-9660  3ad35264-0ab6-48d2-be2e-8420db054f0a 30466 1 2022-08-05 15:14:24 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-08-05 15:14:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-08-05 15:14:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-08-05 15:14:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001066e08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-94dw9-688c4d6789",LastUpdateTime:2022-08-05 15:14:26 +0000 UTC,LastTransitionTime:2022-08-05 15:14:26 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug  5 15:14:26.139: INFO: New ReplicaSet "test-deployment-94dw9-688c4d6789" of Deployment "test-deployment-94dw9":
&ReplicaSet{ObjectMeta:{test-deployment-94dw9-688c4d6789  deployment-9660  11fe1309-6456-41a6-8e8b-de060869df18 30452 1 2022-08-05 15:14:24 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-94dw9 3ad35264-0ab6-48d2-be2e-8420db054f0a 0xc0035ca500 0xc0035ca501}] []  [{kube-controller-manager Update apps/v1 2022-08-05 15:14:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3ad35264-0ab6-48d2-be2e-8420db054f0a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 15:14:25 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 688c4d6789,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035ca738 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug  5 15:14:26.141: INFO: Pod "test-deployment-94dw9-688c4d6789-p785l" is available:
&Pod{ObjectMeta:{test-deployment-94dw9-688c4d6789-p785l test-deployment-94dw9-688c4d6789- deployment-9660  20b93132-dfce-4a1f-b5a7-4ef03e904507 30451 0 2022-08-05 15:14:24 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[cni.projectcalico.org/containerID:75b6d9ce81d4c606b7d750df1ea0dffbb835fc007d60b2b30e05df9b7af5cabc cni.projectcalico.org/podIP:10.244.18.174/32 cni.projectcalico.org/podIPs:10.244.18.174/32] [{apps/v1 ReplicaSet test-deployment-94dw9-688c4d6789 11fe1309-6456-41a6-8e8b-de060869df18 0xc0035cb827 0xc0035cb828}] []  [{Go-http-client Update v1 2022-08-05 15:14:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-05 15:14:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"11fe1309-6456-41a6-8e8b-de060869df18\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-05 15:14:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.18.174\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dtzgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dtzgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:14:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:14:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:14:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:14:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:10.244.18.174,StartTime:2022-08-05 15:14:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 15:14:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e9941b31a09e0d3b4f8026cbe40177be596f9560664cff306fb1233072e70f89,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.18.174,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Aug  5 15:14:26.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9660" for this suite.
â€¢{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":356,"completed":308,"skipped":5890,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:14:26.148: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating server pod server in namespace prestop-9638
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9638
STEP: Deleting pre-stop pod
Aug  5 15:14:35.192: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:188
Aug  5 15:14:35.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9638" for this suite.

â€¢ [SLOW TEST:9.070 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":356,"completed":309,"skipped":5973,"failed":0}
SSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:14:35.219: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Aug  5 15:14:35.240: INFO: PodSpec: initContainers in spec.initContainers
Aug  5 15:15:15.150: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-dce10dc7-a235-492c-9592-718f34249359", GenerateName:"", Namespace:"init-container-6218", SelfLink:"", UID:"942ecb6d-3f60-4f1c-8ba0-93009b3ecf57", ResourceVersion:"30706", Generation:0, CreationTimestamp:time.Date(2022, time.August, 5, 15, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"240207658"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"8dd8b1941d1ec74e1d35384f7debcb35110694d92269a905cb9a25355ba3e9d7", "cni.projectcalico.org/podIP":"10.244.18.140/32", "cni.projectcalico.org/podIPs":"10.244.18.140/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 5, 15, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0038fe138), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 5, 15, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0038fe168), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 5, 15, 14, 36, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0038fe198), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-b5hm4", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc003098220), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-b5hm4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-b5hm4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.7", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-b5hm4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002c64a28), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"vke-automated-test-82a4b3cb9b0e", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002e04310), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002c64aa0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002c64ac0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002c64ac8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002c64acc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0017ee110), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 5, 15, 14, 35, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 5, 15, 14, 35, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 5, 15, 14, 35, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 5, 15, 14, 35, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.1.96.4", PodIP:"10.244.18.140", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.18.140"}}, StartTime:time.Date(2022, time.August, 5, 15, 14, 35, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002e04460)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002e044d0)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"k8s.gcr.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://bc75e4267b3bc85f7ac10debf8a3458b2f25e9bfc50e05313da4dd2332328324", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003098320), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030982e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.7", ImageID:"", ContainerID:"", Started:(*bool)(0xc002c64b4f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Aug  5 15:15:15.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6218" for this suite.

â€¢ [SLOW TEST:39.939 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":356,"completed":310,"skipped":5976,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:15:15.164: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug  5 15:15:15.177: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  5 15:15:15.181: INFO: Waiting for terminating namespaces to be deleted...
Aug  5 15:15:15.183: INFO: 
Logging pods the apiserver thinks is on node vke-automated-test-82a4b3cb9b0e before test
Aug  5 15:15:15.187: INFO: pod-init-dce10dc7-a235-492c-9592-718f34249359 from init-container-6218 started at 2022-08-05 15:14:35 +0000 UTC (1 container statuses recorded)
Aug  5 15:15:15.187: INFO: 	Container run1 ready: false, restart count 0
Aug  5 15:15:15.187: INFO: calico-node-2jtxk from kube-system started at 2022-08-05 14:11:50 +0000 UTC (1 container statuses recorded)
Aug  5 15:15:15.187: INFO: 	Container calico-node ready: true, restart count 0
Aug  5 15:15:15.187: INFO: csi-vultr-node-pmp6m from kube-system started at 2022-08-05 15:04:33 +0000 UTC (2 container statuses recorded)
Aug  5 15:15:15.187: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 15:15:15.187: INFO: 	Container driver-registrar ready: true, restart count 0
Aug  5 15:15:15.187: INFO: konnectivity-agent-rcdln from kube-system started at 2022-08-05 15:04:33 +0000 UTC (1 container statuses recorded)
Aug  5 15:15:15.187: INFO: 	Container konnectivity-agent ready: true, restart count 0
Aug  5 15:15:15.187: INFO: sonobuoy from sonobuoy started at 2022-08-05 14:12:25 +0000 UTC (1 container statuses recorded)
Aug  5 15:15:15.187: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  5 15:15:15.187: INFO: sonobuoy-e2e-job-5437b3f59c524af6 from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 15:15:15.187: INFO: 	Container e2e ready: true, restart count 0
Aug  5 15:15:15.187: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 15:15:15.187: INFO: sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-vnb9h from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 15:15:15.187: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 15:15:15.187: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  5 15:15:15.187: INFO: 
Logging pods the apiserver thinks is on node vke-automated-test-b1f24d775249 before test
Aug  5 15:15:15.191: INFO: calico-kube-controllers-56cdb7c587-zstqt from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 15:15:15.191: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug  5 15:15:15.191: INFO: calico-node-bc7zg from kube-system started at 2022-08-05 14:11:50 +0000 UTC (1 container statuses recorded)
Aug  5 15:15:15.191: INFO: 	Container calico-node ready: true, restart count 0
Aug  5 15:15:15.191: INFO: cluster-autoscaler-595d485b76-4kzzf from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 15:15:15.191: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Aug  5 15:15:15.191: INFO: coredns-75c8969664-pdxjk from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 15:15:15.191: INFO: 	Container coredns ready: true, restart count 0
Aug  5 15:15:15.191: INFO: coredns-75c8969664-xvmdn from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 15:15:15.191: INFO: 	Container coredns ready: true, restart count 0
Aug  5 15:15:15.191: INFO: csi-vultr-controller-0 from kube-system started at 2022-08-05 14:12:02 +0000 UTC (3 container statuses recorded)
Aug  5 15:15:15.191: INFO: 	Container csi-attacher ready: true, restart count 0
Aug  5 15:15:15.191: INFO: 	Container csi-provisioner ready: true, restart count 0
Aug  5 15:15:15.191: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 15:15:15.191: INFO: csi-vultr-node-5xrgd from kube-system started at 2022-08-05 14:12:02 +0000 UTC (2 container statuses recorded)
Aug  5 15:15:15.191: INFO: 	Container csi-vultr-plugin ready: true, restart count 0
Aug  5 15:15:15.191: INFO: 	Container driver-registrar ready: true, restart count 0
Aug  5 15:15:15.191: INFO: konnectivity-agent-c72gb from kube-system started at 2022-08-05 14:12:02 +0000 UTC (1 container statuses recorded)
Aug  5 15:15:15.191: INFO: 	Container konnectivity-agent ready: true, restart count 0
Aug  5 15:15:15.191: INFO: sonobuoy-systemd-logs-daemon-set-4d82b2ab2d224694-zqktm from sonobuoy started at 2022-08-05 14:12:27 +0000 UTC (2 container statuses recorded)
Aug  5 15:15:15.191: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  5 15:15:15.191: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-09520ab1-bb59-46dd-ad9d-345b161d9526 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.1.96.4 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-09520ab1-bb59-46dd-ad9d-345b161d9526 off the node vke-automated-test-82a4b3cb9b0e
STEP: verifying the node doesn't have the label kubernetes.io/e2e-09520ab1-bb59-46dd-ad9d-345b161d9526
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:20:19.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4828" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83

â€¢ [SLOW TEST:304.132 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":356,"completed":311,"skipped":6003,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:20:19.297: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Aug  5 15:20:19.316: INFO: Waiting up to 5m0s for pod "downward-api-5b6c83e3-ff10-46f9-9927-401b46e18d59" in namespace "downward-api-6079" to be "Succeeded or Failed"
Aug  5 15:20:19.317: INFO: Pod "downward-api-5b6c83e3-ff10-46f9-9927-401b46e18d59": Phase="Pending", Reason="", readiness=false. Elapsed: 1.661012ms
Aug  5 15:20:21.323: INFO: Pod "downward-api-5b6c83e3-ff10-46f9-9927-401b46e18d59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00758317s
Aug  5 15:20:23.328: INFO: Pod "downward-api-5b6c83e3-ff10-46f9-9927-401b46e18d59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012071592s
STEP: Saw pod success
Aug  5 15:20:23.328: INFO: Pod "downward-api-5b6c83e3-ff10-46f9-9927-401b46e18d59" satisfied condition "Succeeded or Failed"
Aug  5 15:20:23.329: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downward-api-5b6c83e3-ff10-46f9-9927-401b46e18d59 container dapi-container: <nil>
STEP: delete the pod
Aug  5 15:20:23.357: INFO: Waiting for pod downward-api-5b6c83e3-ff10-46f9-9927-401b46e18d59 to disappear
Aug  5 15:20:23.358: INFO: Pod downward-api-5b6c83e3-ff10-46f9-9927-401b46e18d59 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Aug  5 15:20:23.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6079" for this suite.
â€¢{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":356,"completed":312,"skipped":6039,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:20:23.364: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:20:23.377: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug  5 15:20:28.380: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  5 15:20:28.380: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug  5 15:20:28.390: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-128  66606dea-2967-4c40-9237-cdb19612ea2a 31592 1 2022-08-05 15:20:28 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2022-08-05 15:20:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00403f678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Aug  5 15:20:28.393: INFO: New ReplicaSet "test-cleanup-deployment-6755c7b765" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-6755c7b765  deployment-128  11a76ee8-7348-4232-a453-db9d94bfe5ae 31595 1 2022-08-05 15:20:28 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 66606dea-2967-4c40-9237-cdb19612ea2a 0xc00403fb27 0xc00403fb28}] []  [{kube-controller-manager Update apps/v1 2022-08-05 15:20:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66606dea-2967-4c40-9237-cdb19612ea2a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6755c7b765,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00403fbb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug  5 15:20:28.393: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Aug  5 15:20:28.393: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-128  cdc555f5-38ac-41ad-9c9c-31fea1f33640 31594 1 2022-08-05 15:20:23 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 66606dea-2967-4c40-9237-cdb19612ea2a 0xc00403f9d7 0xc00403f9d8}] []  [{e2e.test Update apps/v1 2022-08-05 15:20:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 15:20:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-05 15:20:28 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"66606dea-2967-4c40-9237-cdb19612ea2a\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00403fab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug  5 15:20:28.396: INFO: Pod "test-cleanup-controller-7zn8k" is available:
&Pod{ObjectMeta:{test-cleanup-controller-7zn8k test-cleanup-controller- deployment-128  cfd45213-7e0b-4740-82af-f9cbffe6f51d 31569 0 2022-08-05 15:20:23 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:c5de2cb5efa55d0140b628467ca0cfdfa4e262c6769bdf37e0b4a874d959d449 cni.projectcalico.org/podIP:10.244.18.157/32 cni.projectcalico.org/podIPs:10.244.18.157/32] [{apps/v1 ReplicaSet test-cleanup-controller cdc555f5-38ac-41ad-9c9c-31fea1f33640 0xc00425a4f7 0xc00425a4f8}] []  [{Go-http-client Update v1 2022-08-05 15:20:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-05 15:20:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cdc555f5-38ac-41ad-9c9c-31fea1f33640\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-05 15:20:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.18.157\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fckf4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fckf4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:20:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:20:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:20:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:20:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:10.244.18.157,StartTime:2022-08-05 15:20:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-05 15:20:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://85a6504694e3c5f5bf8fedc556b65ab4c1d1c1a8fadc74cc9e98544c8d7a1b1b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.18.157,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug  5 15:20:28.396: INFO: Pod "test-cleanup-deployment-6755c7b765-hllsn" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-6755c7b765-hllsn test-cleanup-deployment-6755c7b765- deployment-128  6e7ffd83-0bab-4940-a214-bd0be393f929 31597 0 2022-08-05 15:20:28 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-6755c7b765 11a76ee8-7348-4232-a453-db9d94bfe5ae 0xc00425adc7 0xc00425adc8}] []  [{kube-controller-manager Update v1 2022-08-05 15:20:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"11a76ee8-7348-4232-a453-db9d94bfe5ae\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-smjz7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-smjz7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Aug  5 15:20:28.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-128" for this suite.

â€¢ [SLOW TEST:5.041 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":356,"completed":313,"skipped":6046,"failed":0}
[sig-node] Containers 
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:20:28.407: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override command
Aug  5 15:20:28.422: INFO: Waiting up to 5m0s for pod "client-containers-aa96c55a-305c-4f20-ae61-45cbe27fa983" in namespace "containers-3877" to be "Succeeded or Failed"
Aug  5 15:20:28.424: INFO: Pod "client-containers-aa96c55a-305c-4f20-ae61-45cbe27fa983": Phase="Pending", Reason="", readiness=false. Elapsed: 1.503834ms
Aug  5 15:20:30.431: INFO: Pod "client-containers-aa96c55a-305c-4f20-ae61-45cbe27fa983": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008220763s
Aug  5 15:20:32.438: INFO: Pod "client-containers-aa96c55a-305c-4f20-ae61-45cbe27fa983": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015391152s
STEP: Saw pod success
Aug  5 15:20:32.438: INFO: Pod "client-containers-aa96c55a-305c-4f20-ae61-45cbe27fa983" satisfied condition "Succeeded or Failed"
Aug  5 15:20:32.439: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod client-containers-aa96c55a-305c-4f20-ae61-45cbe27fa983 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 15:20:32.448: INFO: Waiting for pod client-containers-aa96c55a-305c-4f20-ae61-45cbe27fa983 to disappear
Aug  5 15:20:32.449: INFO: Pod client-containers-aa96c55a-305c-4f20-ae61-45cbe27fa983 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Aug  5 15:20:32.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3877" for this suite.
â€¢{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","total":356,"completed":314,"skipped":6046,"failed":0}

------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:20:32.454: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:20:32.464: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:20:38.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7181" for this suite.

â€¢ [SLOW TEST:6.158 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":356,"completed":315,"skipped":6046,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:20:38.615: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug  5 15:20:38.639: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2069  47bf5738-53a9-48f9-9ce3-02b2651fdec4 31750 0 2022-08-05 15:20:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-05 15:20:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:20:38.640: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2069  47bf5738-53a9-48f9-9ce3-02b2651fdec4 31751 0 2022-08-05 15:20:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-05 15:20:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:20:38.640: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2069  47bf5738-53a9-48f9-9ce3-02b2651fdec4 31752 0 2022-08-05 15:20:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-05 15:20:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug  5 15:20:48.659: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2069  47bf5738-53a9-48f9-9ce3-02b2651fdec4 31783 0 2022-08-05 15:20:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-05 15:20:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:20:48.659: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2069  47bf5738-53a9-48f9-9ce3-02b2651fdec4 31784 0 2022-08-05 15:20:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-05 15:20:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:20:48.659: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2069  47bf5738-53a9-48f9-9ce3-02b2651fdec4 31785 0 2022-08-05 15:20:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-05 15:20:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Aug  5 15:20:48.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2069" for this suite.

â€¢ [SLOW TEST:10.048 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":356,"completed":316,"skipped":6047,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:20:48.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 15:20:48.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7607afed-7ecc-4f86-99fd-323458763ab5" in namespace "projected-5741" to be "Succeeded or Failed"
Aug  5 15:20:48.679: INFO: Pod "downwardapi-volume-7607afed-7ecc-4f86-99fd-323458763ab5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.340698ms
Aug  5 15:20:50.687: INFO: Pod "downwardapi-volume-7607afed-7ecc-4f86-99fd-323458763ab5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008613552s
Aug  5 15:20:52.692: INFO: Pod "downwardapi-volume-7607afed-7ecc-4f86-99fd-323458763ab5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01422817s
STEP: Saw pod success
Aug  5 15:20:52.692: INFO: Pod "downwardapi-volume-7607afed-7ecc-4f86-99fd-323458763ab5" satisfied condition "Succeeded or Failed"
Aug  5 15:20:52.694: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-7607afed-7ecc-4f86-99fd-323458763ab5 container client-container: <nil>
STEP: delete the pod
Aug  5 15:20:52.712: INFO: Waiting for pod downwardapi-volume-7607afed-7ecc-4f86-99fd-323458763ab5 to disappear
Aug  5 15:20:52.714: INFO: Pod downwardapi-volume-7607afed-7ecc-4f86-99fd-323458763ab5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 15:20:52.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5741" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":317,"skipped":6064,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:20:52.720: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-62298b8c-52f3-4751-8693-6732ccc2bcc0
STEP: Creating a pod to test consume configMaps
Aug  5 15:20:52.739: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3fd830e-c342-4af3-a47d-34fd81ca63ba" in namespace "configmap-5543" to be "Succeeded or Failed"
Aug  5 15:20:52.741: INFO: Pod "pod-configmaps-e3fd830e-c342-4af3-a47d-34fd81ca63ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085351ms
Aug  5 15:20:54.748: INFO: Pod "pod-configmaps-e3fd830e-c342-4af3-a47d-34fd81ca63ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00918739s
Aug  5 15:20:56.753: INFO: Pod "pod-configmaps-e3fd830e-c342-4af3-a47d-34fd81ca63ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014296203s
STEP: Saw pod success
Aug  5 15:20:56.753: INFO: Pod "pod-configmaps-e3fd830e-c342-4af3-a47d-34fd81ca63ba" satisfied condition "Succeeded or Failed"
Aug  5 15:20:56.756: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-configmaps-e3fd830e-c342-4af3-a47d-34fd81ca63ba container agnhost-container: <nil>
STEP: delete the pod
Aug  5 15:20:56.769: INFO: Waiting for pod pod-configmaps-e3fd830e-c342-4af3-a47d-34fd81ca63ba to disappear
Aug  5 15:20:56.770: INFO: Pod pod-configmaps-e3fd830e-c342-4af3-a47d-34fd81ca63ba no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Aug  5 15:20:56.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5543" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":318,"skipped":6065,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:20:56.777: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
Aug  5 15:20:56.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 create -f -'
Aug  5 15:20:57.563: INFO: stderr: ""
Aug  5 15:20:57.563: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  5 15:20:57.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug  5 15:20:57.617: INFO: stderr: ""
Aug  5 15:20:57.617: INFO: stdout: "update-demo-nautilus-f5mj9 update-demo-nautilus-rktvp "
Aug  5 15:20:57.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-f5mj9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:20:57.665: INFO: stderr: ""
Aug  5 15:20:57.665: INFO: stdout: ""
Aug  5 15:20:57.665: INFO: update-demo-nautilus-f5mj9 is created but not running
Aug  5 15:21:02.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug  5 15:21:02.720: INFO: stderr: ""
Aug  5 15:21:02.720: INFO: stdout: "update-demo-nautilus-f5mj9 update-demo-nautilus-rktvp "
Aug  5 15:21:02.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-f5mj9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:21:02.766: INFO: stderr: ""
Aug  5 15:21:02.766: INFO: stdout: "true"
Aug  5 15:21:02.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-f5mj9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug  5 15:21:02.813: INFO: stderr: ""
Aug  5 15:21:02.814: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug  5 15:21:02.814: INFO: validating pod update-demo-nautilus-f5mj9
Aug  5 15:21:02.821: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  5 15:21:02.821: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  5 15:21:02.821: INFO: update-demo-nautilus-f5mj9 is verified up and running
Aug  5 15:21:02.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-rktvp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:21:02.867: INFO: stderr: ""
Aug  5 15:21:02.867: INFO: stdout: "true"
Aug  5 15:21:02.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-rktvp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug  5 15:21:02.914: INFO: stderr: ""
Aug  5 15:21:02.914: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug  5 15:21:02.914: INFO: validating pod update-demo-nautilus-rktvp
Aug  5 15:21:02.921: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  5 15:21:02.921: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  5 15:21:02.921: INFO: update-demo-nautilus-rktvp is verified up and running
STEP: scaling down the replication controller
Aug  5 15:21:02.923: INFO: scanned /root for discovery docs: <nil>
Aug  5 15:21:02.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Aug  5 15:21:03.989: INFO: stderr: ""
Aug  5 15:21:03.989: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  5 15:21:03.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug  5 15:21:04.036: INFO: stderr: ""
Aug  5 15:21:04.036: INFO: stdout: "update-demo-nautilus-f5mj9 "
Aug  5 15:21:04.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-f5mj9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:21:04.081: INFO: stderr: ""
Aug  5 15:21:04.081: INFO: stdout: "true"
Aug  5 15:21:04.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-f5mj9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug  5 15:21:04.127: INFO: stderr: ""
Aug  5 15:21:04.127: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug  5 15:21:04.127: INFO: validating pod update-demo-nautilus-f5mj9
Aug  5 15:21:04.131: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  5 15:21:04.131: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  5 15:21:04.131: INFO: update-demo-nautilus-f5mj9 is verified up and running
STEP: scaling up the replication controller
Aug  5 15:21:04.132: INFO: scanned /root for discovery docs: <nil>
Aug  5 15:21:04.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Aug  5 15:21:05.193: INFO: stderr: ""
Aug  5 15:21:05.193: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  5 15:21:05.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug  5 15:21:05.241: INFO: stderr: ""
Aug  5 15:21:05.241: INFO: stdout: "update-demo-nautilus-f5mj9 update-demo-nautilus-pzm57 "
Aug  5 15:21:05.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-f5mj9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:21:05.288: INFO: stderr: ""
Aug  5 15:21:05.288: INFO: stdout: "true"
Aug  5 15:21:05.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-f5mj9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug  5 15:21:05.333: INFO: stderr: ""
Aug  5 15:21:05.333: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug  5 15:21:05.333: INFO: validating pod update-demo-nautilus-f5mj9
Aug  5 15:21:05.337: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  5 15:21:05.337: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  5 15:21:05.337: INFO: update-demo-nautilus-f5mj9 is verified up and running
Aug  5 15:21:05.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-pzm57 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:21:05.384: INFO: stderr: ""
Aug  5 15:21:05.384: INFO: stdout: ""
Aug  5 15:21:05.384: INFO: update-demo-nautilus-pzm57 is created but not running
Aug  5 15:21:10.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug  5 15:21:10.445: INFO: stderr: ""
Aug  5 15:21:10.445: INFO: stdout: "update-demo-nautilus-f5mj9 update-demo-nautilus-pzm57 "
Aug  5 15:21:10.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-f5mj9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:21:10.503: INFO: stderr: ""
Aug  5 15:21:10.503: INFO: stdout: "true"
Aug  5 15:21:10.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-f5mj9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug  5 15:21:10.555: INFO: stderr: ""
Aug  5 15:21:10.556: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug  5 15:21:10.557: INFO: validating pod update-demo-nautilus-f5mj9
Aug  5 15:21:10.563: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  5 15:21:10.564: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  5 15:21:10.564: INFO: update-demo-nautilus-f5mj9 is verified up and running
Aug  5 15:21:10.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-pzm57 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug  5 15:21:10.610: INFO: stderr: ""
Aug  5 15:21:10.610: INFO: stdout: "true"
Aug  5 15:21:10.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods update-demo-nautilus-pzm57 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug  5 15:21:10.661: INFO: stderr: ""
Aug  5 15:21:10.661: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug  5 15:21:10.661: INFO: validating pod update-demo-nautilus-pzm57
Aug  5 15:21:10.670: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  5 15:21:10.670: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  5 15:21:10.670: INFO: update-demo-nautilus-pzm57 is verified up and running
STEP: using delete to clean up resources
Aug  5 15:21:10.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 delete --grace-period=0 --force -f -'
Aug  5 15:21:10.726: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  5 15:21:10.726: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug  5 15:21:10.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get rc,svc -l name=update-demo --no-headers'
Aug  5 15:21:10.832: INFO: stderr: "No resources found in kubectl-8525 namespace.\n"
Aug  5 15:21:10.832: INFO: stdout: ""
Aug  5 15:21:10.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-8525 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  5 15:21:10.907: INFO: stderr: ""
Aug  5 15:21:10.907: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 15:21:10.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8525" for this suite.

â€¢ [SLOW TEST:14.137 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should scale a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":356,"completed":319,"skipped":6068,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:21:10.914: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-5636cf04-3251-40d4-88ef-f83ba9c723e4
STEP: Creating a pod to test consume configMaps
Aug  5 15:21:10.940: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c6c83775-a4f1-4c6a-9648-04993265fef4" in namespace "projected-8487" to be "Succeeded or Failed"
Aug  5 15:21:10.941: INFO: Pod "pod-projected-configmaps-c6c83775-a4f1-4c6a-9648-04993265fef4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.510706ms
Aug  5 15:21:12.949: INFO: Pod "pod-projected-configmaps-c6c83775-a4f1-4c6a-9648-04993265fef4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009050704s
Aug  5 15:21:14.956: INFO: Pod "pod-projected-configmaps-c6c83775-a4f1-4c6a-9648-04993265fef4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015921829s
STEP: Saw pod success
Aug  5 15:21:14.956: INFO: Pod "pod-projected-configmaps-c6c83775-a4f1-4c6a-9648-04993265fef4" satisfied condition "Succeeded or Failed"
Aug  5 15:21:14.957: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-configmaps-c6c83775-a4f1-4c6a-9648-04993265fef4 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 15:21:14.969: INFO: Waiting for pod pod-projected-configmaps-c6c83775-a4f1-4c6a-9648-04993265fef4 to disappear
Aug  5 15:21:14.971: INFO: Pod pod-projected-configmaps-c6c83775-a4f1-4c6a-9648-04993265fef4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Aug  5 15:21:14.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8487" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":320,"skipped":6071,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:21:14.975: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 15:21:14.998: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b92c0599-a779-49a1-8b34-9677ab4979de" in namespace "projected-5766" to be "Succeeded or Failed"
Aug  5 15:21:15.000: INFO: Pod "downwardapi-volume-b92c0599-a779-49a1-8b34-9677ab4979de": Phase="Pending", Reason="", readiness=false. Elapsed: 1.701601ms
Aug  5 15:21:17.006: INFO: Pod "downwardapi-volume-b92c0599-a779-49a1-8b34-9677ab4979de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007400374s
Aug  5 15:21:19.012: INFO: Pod "downwardapi-volume-b92c0599-a779-49a1-8b34-9677ab4979de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013255994s
STEP: Saw pod success
Aug  5 15:21:19.012: INFO: Pod "downwardapi-volume-b92c0599-a779-49a1-8b34-9677ab4979de" satisfied condition "Succeeded or Failed"
Aug  5 15:21:19.014: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-b92c0599-a779-49a1-8b34-9677ab4979de container client-container: <nil>
STEP: delete the pod
Aug  5 15:21:19.024: INFO: Waiting for pod downwardapi-volume-b92c0599-a779-49a1-8b34-9677ab4979de to disappear
Aug  5 15:21:19.025: INFO: Pod downwardapi-volume-b92c0599-a779-49a1-8b34-9677ab4979de no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 15:21:19.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5766" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":321,"skipped":6094,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:21:19.031: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:21:19.043: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9669
I0805 15:21:19.047877      18 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9669, replica count: 1
I0805 15:21:20.098820      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 15:21:20.206: INFO: Created: latency-svc-22qbg
Aug  5 15:21:20.210: INFO: Got endpoints: latency-svc-22qbg [9.968737ms]
Aug  5 15:21:20.218: INFO: Created: latency-svc-t4mkd
Aug  5 15:21:20.219: INFO: Got endpoints: latency-svc-t4mkd [9.142713ms]
Aug  5 15:21:20.221: INFO: Created: latency-svc-z8qf9
Aug  5 15:21:20.223: INFO: Got endpoints: latency-svc-z8qf9 [12.63701ms]
Aug  5 15:21:20.225: INFO: Created: latency-svc-lnplg
Aug  5 15:21:20.227: INFO: Created: latency-svc-9g9hp
Aug  5 15:21:20.228: INFO: Got endpoints: latency-svc-lnplg [17.29614ms]
Aug  5 15:21:20.231: INFO: Got endpoints: latency-svc-9g9hp [20.037291ms]
Aug  5 15:21:20.235: INFO: Created: latency-svc-xhmdj
Aug  5 15:21:20.235: INFO: Created: latency-svc-ddh92
Aug  5 15:21:20.235: INFO: Got endpoints: latency-svc-ddh92 [24.068995ms]
Aug  5 15:21:20.237: INFO: Got endpoints: latency-svc-xhmdj [26.186795ms]
Aug  5 15:21:20.237: INFO: Created: latency-svc-kbnxl
Aug  5 15:21:20.247: INFO: Got endpoints: latency-svc-kbnxl [35.71395ms]
Aug  5 15:21:20.251: INFO: Created: latency-svc-fg8mr
Aug  5 15:21:20.254: INFO: Got endpoints: latency-svc-fg8mr [43.074177ms]
Aug  5 15:21:20.255: INFO: Created: latency-svc-swhqg
Aug  5 15:21:20.258: INFO: Got endpoints: latency-svc-swhqg [47.210734ms]
Aug  5 15:21:20.262: INFO: Created: latency-svc-lxf6d
Aug  5 15:21:20.267: INFO: Got endpoints: latency-svc-lxf6d [55.969285ms]
Aug  5 15:21:20.269: INFO: Created: latency-svc-fwqgj
Aug  5 15:21:20.271: INFO: Got endpoints: latency-svc-fwqgj [60.170609ms]
Aug  5 15:21:20.272: INFO: Created: latency-svc-jcvdc
Aug  5 15:21:20.274: INFO: Got endpoints: latency-svc-jcvdc [63.017675ms]
Aug  5 15:21:20.276: INFO: Created: latency-svc-dq7mx
Aug  5 15:21:20.278: INFO: Got endpoints: latency-svc-dq7mx [66.857334ms]
Aug  5 15:21:20.279: INFO: Created: latency-svc-xj4ml
Aug  5 15:21:20.281: INFO: Got endpoints: latency-svc-xj4ml [70.030238ms]
Aug  5 15:21:20.283: INFO: Created: latency-svc-rmt6x
Aug  5 15:21:20.285: INFO: Got endpoints: latency-svc-rmt6x [73.996818ms]
Aug  5 15:21:20.288: INFO: Created: latency-svc-hg9ln
Aug  5 15:21:20.289: INFO: Got endpoints: latency-svc-hg9ln [69.677592ms]
Aug  5 15:21:20.289: INFO: Created: latency-svc-2n9lz
Aug  5 15:21:20.294: INFO: Got endpoints: latency-svc-2n9lz [70.654414ms]
Aug  5 15:21:20.296: INFO: Created: latency-svc-r6kxn
Aug  5 15:21:20.298: INFO: Got endpoints: latency-svc-r6kxn [69.630474ms]
Aug  5 15:21:20.299: INFO: Created: latency-svc-dckzx
Aug  5 15:21:20.302: INFO: Got endpoints: latency-svc-dckzx [71.105446ms]
Aug  5 15:21:20.302: INFO: Created: latency-svc-4wjth
Aug  5 15:21:20.305: INFO: Got endpoints: latency-svc-4wjth [70.621786ms]
Aug  5 15:21:20.306: INFO: Created: latency-svc-plk77
Aug  5 15:21:20.309: INFO: Created: latency-svc-5nzsm
Aug  5 15:21:20.312: INFO: Created: latency-svc-cvrbp
Aug  5 15:21:20.312: INFO: Got endpoints: latency-svc-5nzsm [65.537789ms]
Aug  5 15:21:20.312: INFO: Got endpoints: latency-svc-plk77 [75.228388ms]
Aug  5 15:21:20.315: INFO: Got endpoints: latency-svc-cvrbp [60.225031ms]
Aug  5 15:21:20.316: INFO: Created: latency-svc-xln54
Aug  5 15:21:20.318: INFO: Got endpoints: latency-svc-xln54 [59.469648ms]
Aug  5 15:21:20.320: INFO: Created: latency-svc-xsxjk
Aug  5 15:21:20.329: INFO: Created: latency-svc-7qb5b
Aug  5 15:21:20.330: INFO: Got endpoints: latency-svc-7qb5b [58.087907ms]
Aug  5 15:21:20.329: INFO: Created: latency-svc-b6lzq
Aug  5 15:21:20.330: INFO: Got endpoints: latency-svc-b6lzq [55.658234ms]
Aug  5 15:21:20.329: INFO: Got endpoints: latency-svc-xsxjk [62.05555ms]
Aug  5 15:21:20.332: INFO: Created: latency-svc-pjltb
Aug  5 15:21:20.334: INFO: Got endpoints: latency-svc-pjltb [56.065842ms]
Aug  5 15:21:20.335: INFO: Created: latency-svc-kjkcm
Aug  5 15:21:20.336: INFO: Got endpoints: latency-svc-kjkcm [55.04669ms]
Aug  5 15:21:20.339: INFO: Created: latency-svc-czkwp
Aug  5 15:21:20.341: INFO: Got endpoints: latency-svc-czkwp [55.898174ms]
Aug  5 15:21:20.380: INFO: Created: latency-svc-2psf4
Aug  5 15:21:20.381: INFO: Created: latency-svc-qfgff
Aug  5 15:21:20.381: INFO: Created: latency-svc-vz2n6
Aug  5 15:21:20.381: INFO: Created: latency-svc-rg66c
Aug  5 15:21:20.382: INFO: Created: latency-svc-vvg5s
Aug  5 15:21:20.382: INFO: Created: latency-svc-qhfs8
Aug  5 15:21:20.383: INFO: Created: latency-svc-wcppg
Aug  5 15:21:20.383: INFO: Created: latency-svc-cnf6w
Aug  5 15:21:20.383: INFO: Created: latency-svc-4nvhd
Aug  5 15:21:20.383: INFO: Created: latency-svc-5hll9
Aug  5 15:21:20.383: INFO: Created: latency-svc-xr4nf
Aug  5 15:21:20.383: INFO: Created: latency-svc-ssg6g
Aug  5 15:21:20.383: INFO: Created: latency-svc-wvrzl
Aug  5 15:21:20.384: INFO: Created: latency-svc-mjs5p
Aug  5 15:21:20.384: INFO: Created: latency-svc-mlv8f
Aug  5 15:21:20.384: INFO: Got endpoints: latency-svc-2psf4 [95.002376ms]
Aug  5 15:21:20.384: INFO: Got endpoints: latency-svc-5hll9 [53.707724ms]
Aug  5 15:21:20.389: INFO: Created: latency-svc-prlfs
Aug  5 15:21:20.391: INFO: Created: latency-svc-cbxqc
Aug  5 15:21:20.409: INFO: Got endpoints: latency-svc-mlv8f [103.929784ms]
Aug  5 15:21:20.417: INFO: Created: latency-svc-bnkzb
Aug  5 15:21:20.460: INFO: Got endpoints: latency-svc-qhfs8 [129.968049ms]
Aug  5 15:21:20.466: INFO: Created: latency-svc-lz9hf
Aug  5 15:21:20.511: INFO: Got endpoints: latency-svc-xr4nf [208.373808ms]
Aug  5 15:21:20.520: INFO: Created: latency-svc-2tqnq
Aug  5 15:21:20.559: INFO: Got endpoints: latency-svc-ssg6g [265.4883ms]
Aug  5 15:21:20.566: INFO: Created: latency-svc-84hsb
Aug  5 15:21:20.610: INFO: Got endpoints: latency-svc-wcppg [291.762745ms]
Aug  5 15:21:20.618: INFO: Created: latency-svc-md27n
Aug  5 15:21:20.659: INFO: Got endpoints: latency-svc-cnf6w [346.965572ms]
Aug  5 15:21:20.667: INFO: Created: latency-svc-dqc4v
Aug  5 15:21:20.710: INFO: Got endpoints: latency-svc-4nvhd [397.106183ms]
Aug  5 15:21:20.716: INFO: Created: latency-svc-62zp2
Aug  5 15:21:20.760: INFO: Got endpoints: latency-svc-qfgff [445.207231ms]
Aug  5 15:21:20.768: INFO: Created: latency-svc-bg8mq
Aug  5 15:21:20.810: INFO: Got endpoints: latency-svc-rg66c [468.568738ms]
Aug  5 15:21:20.817: INFO: Created: latency-svc-9zsdf
Aug  5 15:21:20.859: INFO: Got endpoints: latency-svc-vvg5s [524.747099ms]
Aug  5 15:21:20.866: INFO: Created: latency-svc-95r5l
Aug  5 15:21:20.911: INFO: Got endpoints: latency-svc-vz2n6 [574.203089ms]
Aug  5 15:21:20.918: INFO: Created: latency-svc-vv5p5
Aug  5 15:21:20.959: INFO: Got endpoints: latency-svc-wvrzl [661.683019ms]
Aug  5 15:21:20.966: INFO: Created: latency-svc-tk6ls
Aug  5 15:21:21.009: INFO: Got endpoints: latency-svc-mjs5p [679.696754ms]
Aug  5 15:21:21.016: INFO: Created: latency-svc-pknt9
Aug  5 15:21:21.059: INFO: Got endpoints: latency-svc-prlfs [675.35011ms]
Aug  5 15:21:21.068: INFO: Created: latency-svc-6vnnx
Aug  5 15:21:21.114: INFO: Got endpoints: latency-svc-cbxqc [729.616156ms]
Aug  5 15:21:21.120: INFO: Created: latency-svc-clfrl
Aug  5 15:21:21.160: INFO: Got endpoints: latency-svc-bnkzb [750.307518ms]
Aug  5 15:21:21.166: INFO: Created: latency-svc-zt2sf
Aug  5 15:21:21.209: INFO: Got endpoints: latency-svc-lz9hf [749.405059ms]
Aug  5 15:21:21.216: INFO: Created: latency-svc-k6jbm
Aug  5 15:21:21.258: INFO: Got endpoints: latency-svc-2tqnq [747.878264ms]
Aug  5 15:21:21.264: INFO: Created: latency-svc-cl9mj
Aug  5 15:21:21.309: INFO: Got endpoints: latency-svc-84hsb [749.324875ms]
Aug  5 15:21:21.315: INFO: Created: latency-svc-fvx46
Aug  5 15:21:21.359: INFO: Got endpoints: latency-svc-md27n [749.140714ms]
Aug  5 15:21:21.365: INFO: Created: latency-svc-gcrsj
Aug  5 15:21:21.409: INFO: Got endpoints: latency-svc-dqc4v [749.911731ms]
Aug  5 15:21:21.414: INFO: Created: latency-svc-544r4
Aug  5 15:21:21.460: INFO: Got endpoints: latency-svc-62zp2 [749.774012ms]
Aug  5 15:21:21.466: INFO: Created: latency-svc-hq6km
Aug  5 15:21:21.515: INFO: Got endpoints: latency-svc-bg8mq [754.945404ms]
Aug  5 15:21:21.532: INFO: Created: latency-svc-wstgt
Aug  5 15:21:21.559: INFO: Got endpoints: latency-svc-9zsdf [749.076343ms]
Aug  5 15:21:21.565: INFO: Created: latency-svc-rv8p9
Aug  5 15:21:21.610: INFO: Got endpoints: latency-svc-95r5l [750.337533ms]
Aug  5 15:21:21.616: INFO: Created: latency-svc-g6qmm
Aug  5 15:21:21.660: INFO: Got endpoints: latency-svc-vv5p5 [749.287902ms]
Aug  5 15:21:21.667: INFO: Created: latency-svc-2tnsc
Aug  5 15:21:21.710: INFO: Got endpoints: latency-svc-tk6ls [749.685541ms]
Aug  5 15:21:21.716: INFO: Created: latency-svc-5dc8q
Aug  5 15:21:21.761: INFO: Got endpoints: latency-svc-pknt9 [751.449119ms]
Aug  5 15:21:21.768: INFO: Created: latency-svc-csmgz
Aug  5 15:21:21.810: INFO: Got endpoints: latency-svc-6vnnx [750.317378ms]
Aug  5 15:21:21.816: INFO: Created: latency-svc-lbb5r
Aug  5 15:21:21.860: INFO: Got endpoints: latency-svc-clfrl [746.220778ms]
Aug  5 15:21:21.867: INFO: Created: latency-svc-qp4rz
Aug  5 15:21:21.911: INFO: Got endpoints: latency-svc-zt2sf [750.699518ms]
Aug  5 15:21:21.918: INFO: Created: latency-svc-529wk
Aug  5 15:21:21.961: INFO: Got endpoints: latency-svc-k6jbm [750.899198ms]
Aug  5 15:21:21.968: INFO: Created: latency-svc-ct2ql
Aug  5 15:21:22.011: INFO: Got endpoints: latency-svc-cl9mj [751.97097ms]
Aug  5 15:21:22.018: INFO: Created: latency-svc-z9bs8
Aug  5 15:21:22.060: INFO: Got endpoints: latency-svc-fvx46 [750.747356ms]
Aug  5 15:21:22.068: INFO: Created: latency-svc-z2ksc
Aug  5 15:21:22.110: INFO: Got endpoints: latency-svc-gcrsj [750.779173ms]
Aug  5 15:21:22.119: INFO: Created: latency-svc-464px
Aug  5 15:21:22.159: INFO: Got endpoints: latency-svc-544r4 [749.889934ms]
Aug  5 15:21:22.166: INFO: Created: latency-svc-xhbff
Aug  5 15:21:22.209: INFO: Got endpoints: latency-svc-hq6km [749.593052ms]
Aug  5 15:21:22.215: INFO: Created: latency-svc-lk7qr
Aug  5 15:21:22.259: INFO: Got endpoints: latency-svc-wstgt [744.147531ms]
Aug  5 15:21:22.265: INFO: Created: latency-svc-lwg7h
Aug  5 15:21:22.309: INFO: Got endpoints: latency-svc-rv8p9 [749.311692ms]
Aug  5 15:21:22.316: INFO: Created: latency-svc-d2b4h
Aug  5 15:21:22.359: INFO: Got endpoints: latency-svc-g6qmm [749.267802ms]
Aug  5 15:21:22.366: INFO: Created: latency-svc-l62mp
Aug  5 15:21:22.410: INFO: Got endpoints: latency-svc-2tnsc [750.065052ms]
Aug  5 15:21:22.417: INFO: Created: latency-svc-vqzqw
Aug  5 15:21:22.460: INFO: Got endpoints: latency-svc-5dc8q [750.047084ms]
Aug  5 15:21:22.468: INFO: Created: latency-svc-zmsb8
Aug  5 15:21:22.510: INFO: Got endpoints: latency-svc-csmgz [749.379019ms]
Aug  5 15:21:22.525: INFO: Created: latency-svc-hc6zf
Aug  5 15:21:22.560: INFO: Got endpoints: latency-svc-lbb5r [750.014667ms]
Aug  5 15:21:22.566: INFO: Created: latency-svc-jgcjb
Aug  5 15:21:22.610: INFO: Got endpoints: latency-svc-qp4rz [749.411515ms]
Aug  5 15:21:22.616: INFO: Created: latency-svc-jnn4f
Aug  5 15:21:22.659: INFO: Got endpoints: latency-svc-529wk [748.335778ms]
Aug  5 15:21:22.665: INFO: Created: latency-svc-2cl2k
Aug  5 15:21:22.709: INFO: Got endpoints: latency-svc-ct2ql [748.049786ms]
Aug  5 15:21:22.715: INFO: Created: latency-svc-tzj9s
Aug  5 15:21:22.760: INFO: Got endpoints: latency-svc-z9bs8 [749.072817ms]
Aug  5 15:21:22.766: INFO: Created: latency-svc-v76j8
Aug  5 15:21:22.810: INFO: Got endpoints: latency-svc-z2ksc [750.59116ms]
Aug  5 15:21:22.817: INFO: Created: latency-svc-bw8t7
Aug  5 15:21:22.860: INFO: Got endpoints: latency-svc-464px [749.615505ms]
Aug  5 15:21:22.867: INFO: Created: latency-svc-nq8px
Aug  5 15:21:22.910: INFO: Got endpoints: latency-svc-xhbff [749.715385ms]
Aug  5 15:21:22.917: INFO: Created: latency-svc-86jt6
Aug  5 15:21:22.960: INFO: Got endpoints: latency-svc-lk7qr [750.418183ms]
Aug  5 15:21:22.967: INFO: Created: latency-svc-cc5cq
Aug  5 15:21:23.010: INFO: Got endpoints: latency-svc-lwg7h [750.528385ms]
Aug  5 15:21:23.016: INFO: Created: latency-svc-d8fgf
Aug  5 15:21:23.059: INFO: Got endpoints: latency-svc-d2b4h [749.729678ms]
Aug  5 15:21:23.066: INFO: Created: latency-svc-c6sxq
Aug  5 15:21:23.110: INFO: Got endpoints: latency-svc-l62mp [750.730366ms]
Aug  5 15:21:23.117: INFO: Created: latency-svc-qnlnm
Aug  5 15:21:23.159: INFO: Got endpoints: latency-svc-vqzqw [748.933132ms]
Aug  5 15:21:23.167: INFO: Created: latency-svc-mw2x8
Aug  5 15:21:23.212: INFO: Got endpoints: latency-svc-zmsb8 [751.754436ms]
Aug  5 15:21:23.220: INFO: Created: latency-svc-2d758
Aug  5 15:21:23.261: INFO: Got endpoints: latency-svc-hc6zf [750.61586ms]
Aug  5 15:21:23.268: INFO: Created: latency-svc-zqkwh
Aug  5 15:21:23.310: INFO: Got endpoints: latency-svc-jgcjb [750.068629ms]
Aug  5 15:21:23.317: INFO: Created: latency-svc-s8ddc
Aug  5 15:21:23.361: INFO: Got endpoints: latency-svc-jnn4f [750.80531ms]
Aug  5 15:21:23.368: INFO: Created: latency-svc-clx8k
Aug  5 15:21:23.411: INFO: Got endpoints: latency-svc-2cl2k [751.506133ms]
Aug  5 15:21:23.418: INFO: Created: latency-svc-khtnl
Aug  5 15:21:23.460: INFO: Got endpoints: latency-svc-tzj9s [750.468658ms]
Aug  5 15:21:23.466: INFO: Created: latency-svc-8vgnv
Aug  5 15:21:23.509: INFO: Got endpoints: latency-svc-v76j8 [749.421883ms]
Aug  5 15:21:23.516: INFO: Created: latency-svc-6l854
Aug  5 15:21:23.559: INFO: Got endpoints: latency-svc-bw8t7 [748.356252ms]
Aug  5 15:21:23.564: INFO: Created: latency-svc-lbsdg
Aug  5 15:21:23.609: INFO: Got endpoints: latency-svc-nq8px [749.70505ms]
Aug  5 15:21:23.617: INFO: Created: latency-svc-h8hds
Aug  5 15:21:23.660: INFO: Got endpoints: latency-svc-86jt6 [749.989952ms]
Aug  5 15:21:23.667: INFO: Created: latency-svc-b465r
Aug  5 15:21:23.710: INFO: Got endpoints: latency-svc-cc5cq [749.747679ms]
Aug  5 15:21:23.715: INFO: Created: latency-svc-wt5gl
Aug  5 15:21:23.759: INFO: Got endpoints: latency-svc-d8fgf [749.135709ms]
Aug  5 15:21:23.765: INFO: Created: latency-svc-r5hld
Aug  5 15:21:23.809: INFO: Got endpoints: latency-svc-c6sxq [749.946026ms]
Aug  5 15:21:23.816: INFO: Created: latency-svc-9vcmk
Aug  5 15:21:23.859: INFO: Got endpoints: latency-svc-qnlnm [748.686076ms]
Aug  5 15:21:23.866: INFO: Created: latency-svc-hdz9t
Aug  5 15:21:23.909: INFO: Got endpoints: latency-svc-mw2x8 [749.951193ms]
Aug  5 15:21:23.915: INFO: Created: latency-svc-vjk2d
Aug  5 15:21:23.960: INFO: Got endpoints: latency-svc-2d758 [748.068546ms]
Aug  5 15:21:23.966: INFO: Created: latency-svc-6gdxl
Aug  5 15:21:24.009: INFO: Got endpoints: latency-svc-zqkwh [748.081726ms]
Aug  5 15:21:24.015: INFO: Created: latency-svc-4x57h
Aug  5 15:21:24.058: INFO: Got endpoints: latency-svc-s8ddc [748.01322ms]
Aug  5 15:21:24.064: INFO: Created: latency-svc-k5jtq
Aug  5 15:21:24.109: INFO: Got endpoints: latency-svc-clx8k [748.165818ms]
Aug  5 15:21:24.115: INFO: Created: latency-svc-fc9dq
Aug  5 15:21:24.160: INFO: Got endpoints: latency-svc-khtnl [749.069709ms]
Aug  5 15:21:24.165: INFO: Created: latency-svc-8sbtz
Aug  5 15:21:24.210: INFO: Got endpoints: latency-svc-8vgnv [750.066499ms]
Aug  5 15:21:24.218: INFO: Created: latency-svc-4t4rt
Aug  5 15:21:24.260: INFO: Got endpoints: latency-svc-6l854 [750.13352ms]
Aug  5 15:21:24.267: INFO: Created: latency-svc-g2vd8
Aug  5 15:21:24.310: INFO: Got endpoints: latency-svc-lbsdg [751.532202ms]
Aug  5 15:21:24.317: INFO: Created: latency-svc-qj9g6
Aug  5 15:21:24.360: INFO: Got endpoints: latency-svc-h8hds [750.114761ms]
Aug  5 15:21:24.366: INFO: Created: latency-svc-jjh2c
Aug  5 15:21:24.409: INFO: Got endpoints: latency-svc-b465r [749.865151ms]
Aug  5 15:21:24.418: INFO: Created: latency-svc-48hhj
Aug  5 15:21:24.459: INFO: Got endpoints: latency-svc-wt5gl [748.471789ms]
Aug  5 15:21:24.465: INFO: Created: latency-svc-cdxcg
Aug  5 15:21:24.509: INFO: Got endpoints: latency-svc-r5hld [750.116973ms]
Aug  5 15:21:24.516: INFO: Created: latency-svc-r6x7m
Aug  5 15:21:24.559: INFO: Got endpoints: latency-svc-9vcmk [750.055546ms]
Aug  5 15:21:24.564: INFO: Created: latency-svc-t6962
Aug  5 15:21:24.610: INFO: Got endpoints: latency-svc-hdz9t [750.506358ms]
Aug  5 15:21:24.617: INFO: Created: latency-svc-lkdvl
Aug  5 15:21:24.659: INFO: Got endpoints: latency-svc-vjk2d [749.988104ms]
Aug  5 15:21:24.667: INFO: Created: latency-svc-6tqdt
Aug  5 15:21:24.710: INFO: Got endpoints: latency-svc-6gdxl [750.095995ms]
Aug  5 15:21:24.721: INFO: Created: latency-svc-x7msn
Aug  5 15:21:24.759: INFO: Got endpoints: latency-svc-4x57h [749.627193ms]
Aug  5 15:21:24.766: INFO: Created: latency-svc-dkq75
Aug  5 15:21:24.810: INFO: Got endpoints: latency-svc-k5jtq [751.376462ms]
Aug  5 15:21:24.815: INFO: Created: latency-svc-6zq4q
Aug  5 15:21:24.859: INFO: Got endpoints: latency-svc-fc9dq [749.767714ms]
Aug  5 15:21:24.865: INFO: Created: latency-svc-qpknb
Aug  5 15:21:24.910: INFO: Got endpoints: latency-svc-8sbtz [750.335417ms]
Aug  5 15:21:24.916: INFO: Created: latency-svc-njlcw
Aug  5 15:21:24.959: INFO: Got endpoints: latency-svc-4t4rt [749.163673ms]
Aug  5 15:21:24.977: INFO: Created: latency-svc-c6q6f
Aug  5 15:21:25.011: INFO: Got endpoints: latency-svc-g2vd8 [751.029655ms]
Aug  5 15:21:25.019: INFO: Created: latency-svc-4rmp7
Aug  5 15:21:25.059: INFO: Got endpoints: latency-svc-qj9g6 [749.146579ms]
Aug  5 15:21:25.065: INFO: Created: latency-svc-jfhzw
Aug  5 15:21:25.109: INFO: Got endpoints: latency-svc-jjh2c [749.070848ms]
Aug  5 15:21:25.115: INFO: Created: latency-svc-zzmgf
Aug  5 15:21:25.159: INFO: Got endpoints: latency-svc-48hhj [749.606271ms]
Aug  5 15:21:25.166: INFO: Created: latency-svc-pbjhh
Aug  5 15:21:25.210: INFO: Got endpoints: latency-svc-cdxcg [751.056098ms]
Aug  5 15:21:25.219: INFO: Created: latency-svc-zwfpp
Aug  5 15:21:25.260: INFO: Got endpoints: latency-svc-r6x7m [750.941976ms]
Aug  5 15:21:25.267: INFO: Created: latency-svc-jn8fk
Aug  5 15:21:25.310: INFO: Got endpoints: latency-svc-t6962 [751.222147ms]
Aug  5 15:21:25.317: INFO: Created: latency-svc-n5dxl
Aug  5 15:21:25.360: INFO: Got endpoints: latency-svc-lkdvl [749.638382ms]
Aug  5 15:21:25.367: INFO: Created: latency-svc-8sffm
Aug  5 15:21:25.409: INFO: Got endpoints: latency-svc-6tqdt [749.55618ms]
Aug  5 15:21:25.415: INFO: Created: latency-svc-z5pck
Aug  5 15:21:25.460: INFO: Got endpoints: latency-svc-x7msn [749.730454ms]
Aug  5 15:21:25.465: INFO: Created: latency-svc-zc7c2
Aug  5 15:21:25.511: INFO: Got endpoints: latency-svc-dkq75 [751.993218ms]
Aug  5 15:21:25.517: INFO: Created: latency-svc-6t2zq
Aug  5 15:21:25.559: INFO: Got endpoints: latency-svc-6zq4q [749.518191ms]
Aug  5 15:21:25.565: INFO: Created: latency-svc-kkqz5
Aug  5 15:21:25.609: INFO: Got endpoints: latency-svc-qpknb [749.801906ms]
Aug  5 15:21:25.617: INFO: Created: latency-svc-9244p
Aug  5 15:21:25.660: INFO: Got endpoints: latency-svc-njlcw [749.416295ms]
Aug  5 15:21:25.666: INFO: Created: latency-svc-ggz4t
Aug  5 15:21:25.717: INFO: Got endpoints: latency-svc-c6q6f [757.627117ms]
Aug  5 15:21:25.724: INFO: Created: latency-svc-vvq7v
Aug  5 15:21:25.760: INFO: Got endpoints: latency-svc-4rmp7 [749.292738ms]
Aug  5 15:21:25.766: INFO: Created: latency-svc-6drr6
Aug  5 15:21:25.810: INFO: Got endpoints: latency-svc-jfhzw [750.616411ms]
Aug  5 15:21:25.817: INFO: Created: latency-svc-vq87r
Aug  5 15:21:25.859: INFO: Got endpoints: latency-svc-zzmgf [749.63547ms]
Aug  5 15:21:25.865: INFO: Created: latency-svc-nqrnc
Aug  5 15:21:25.911: INFO: Got endpoints: latency-svc-pbjhh [751.340357ms]
Aug  5 15:21:25.919: INFO: Created: latency-svc-hsmfm
Aug  5 15:21:25.959: INFO: Got endpoints: latency-svc-zwfpp [749.252872ms]
Aug  5 15:21:25.966: INFO: Created: latency-svc-hp49m
Aug  5 15:21:26.010: INFO: Got endpoints: latency-svc-jn8fk [749.628504ms]
Aug  5 15:21:26.016: INFO: Created: latency-svc-8l5x6
Aug  5 15:21:26.061: INFO: Got endpoints: latency-svc-n5dxl [750.569967ms]
Aug  5 15:21:26.067: INFO: Created: latency-svc-smw92
Aug  5 15:21:26.110: INFO: Got endpoints: latency-svc-8sffm [750.041871ms]
Aug  5 15:21:26.115: INFO: Created: latency-svc-kg2hf
Aug  5 15:21:26.160: INFO: Got endpoints: latency-svc-z5pck [750.678178ms]
Aug  5 15:21:26.165: INFO: Created: latency-svc-m6gsg
Aug  5 15:21:26.210: INFO: Got endpoints: latency-svc-zc7c2 [750.003019ms]
Aug  5 15:21:26.216: INFO: Created: latency-svc-w6nxw
Aug  5 15:21:26.260: INFO: Got endpoints: latency-svc-6t2zq [748.677338ms]
Aug  5 15:21:26.266: INFO: Created: latency-svc-6sbjk
Aug  5 15:21:26.310: INFO: Got endpoints: latency-svc-kkqz5 [750.85885ms]
Aug  5 15:21:26.317: INFO: Created: latency-svc-svnmw
Aug  5 15:21:26.360: INFO: Got endpoints: latency-svc-9244p [750.748851ms]
Aug  5 15:21:26.365: INFO: Created: latency-svc-n8cjm
Aug  5 15:21:26.409: INFO: Got endpoints: latency-svc-ggz4t [749.350869ms]
Aug  5 15:21:26.414: INFO: Created: latency-svc-68pgn
Aug  5 15:21:26.459: INFO: Got endpoints: latency-svc-vvq7v [741.593621ms]
Aug  5 15:21:26.465: INFO: Created: latency-svc-ccf89
Aug  5 15:21:26.509: INFO: Got endpoints: latency-svc-6drr6 [748.456108ms]
Aug  5 15:21:26.514: INFO: Created: latency-svc-k7nlz
Aug  5 15:21:26.559: INFO: Got endpoints: latency-svc-vq87r [748.923173ms]
Aug  5 15:21:26.565: INFO: Created: latency-svc-z457x
Aug  5 15:21:26.609: INFO: Got endpoints: latency-svc-nqrnc [750.619515ms]
Aug  5 15:21:26.614: INFO: Created: latency-svc-6b5dj
Aug  5 15:21:26.660: INFO: Got endpoints: latency-svc-hsmfm [748.992429ms]
Aug  5 15:21:26.665: INFO: Created: latency-svc-s4v76
Aug  5 15:21:26.710: INFO: Got endpoints: latency-svc-hp49m [750.108682ms]
Aug  5 15:21:26.715: INFO: Created: latency-svc-frfhz
Aug  5 15:21:26.759: INFO: Got endpoints: latency-svc-8l5x6 [749.327995ms]
Aug  5 15:21:26.765: INFO: Created: latency-svc-qxj5l
Aug  5 15:21:26.809: INFO: Got endpoints: latency-svc-smw92 [748.046037ms]
Aug  5 15:21:26.814: INFO: Created: latency-svc-zxvtb
Aug  5 15:21:26.860: INFO: Got endpoints: latency-svc-kg2hf [749.685119ms]
Aug  5 15:21:26.865: INFO: Created: latency-svc-98xw8
Aug  5 15:21:26.909: INFO: Got endpoints: latency-svc-m6gsg [749.651366ms]
Aug  5 15:21:26.914: INFO: Created: latency-svc-qtcgp
Aug  5 15:21:26.962: INFO: Got endpoints: latency-svc-w6nxw [751.766591ms]
Aug  5 15:21:26.970: INFO: Created: latency-svc-vw9fc
Aug  5 15:21:27.009: INFO: Got endpoints: latency-svc-6sbjk [749.157069ms]
Aug  5 15:21:27.015: INFO: Created: latency-svc-vp2lr
Aug  5 15:21:27.059: INFO: Got endpoints: latency-svc-svnmw [748.75768ms]
Aug  5 15:21:27.065: INFO: Created: latency-svc-9smt8
Aug  5 15:21:27.109: INFO: Got endpoints: latency-svc-n8cjm [749.214333ms]
Aug  5 15:21:27.124: INFO: Created: latency-svc-2cmjf
Aug  5 15:21:27.160: INFO: Got endpoints: latency-svc-68pgn [751.253012ms]
Aug  5 15:21:27.167: INFO: Created: latency-svc-b6h65
Aug  5 15:21:27.209: INFO: Got endpoints: latency-svc-ccf89 [750.044117ms]
Aug  5 15:21:27.215: INFO: Created: latency-svc-njpkc
Aug  5 15:21:27.259: INFO: Got endpoints: latency-svc-k7nlz [749.566219ms]
Aug  5 15:21:27.264: INFO: Created: latency-svc-xdbmm
Aug  5 15:21:27.310: INFO: Got endpoints: latency-svc-z457x [750.314128ms]
Aug  5 15:21:27.316: INFO: Created: latency-svc-zqt2v
Aug  5 15:21:27.360: INFO: Got endpoints: latency-svc-6b5dj [750.820424ms]
Aug  5 15:21:27.366: INFO: Created: latency-svc-nsblb
Aug  5 15:21:27.410: INFO: Got endpoints: latency-svc-s4v76 [750.10673ms]
Aug  5 15:21:27.416: INFO: Created: latency-svc-zr2rx
Aug  5 15:21:27.459: INFO: Got endpoints: latency-svc-frfhz [748.959564ms]
Aug  5 15:21:27.465: INFO: Created: latency-svc-6v55w
Aug  5 15:21:27.509: INFO: Got endpoints: latency-svc-qxj5l [749.968147ms]
Aug  5 15:21:27.516: INFO: Created: latency-svc-9b7jw
Aug  5 15:21:27.560: INFO: Got endpoints: latency-svc-zxvtb [750.562207ms]
Aug  5 15:21:27.566: INFO: Created: latency-svc-f7rs6
Aug  5 15:21:27.614: INFO: Got endpoints: latency-svc-98xw8 [754.338261ms]
Aug  5 15:21:27.623: INFO: Created: latency-svc-lzfnt
Aug  5 15:21:27.660: INFO: Got endpoints: latency-svc-qtcgp [750.213674ms]
Aug  5 15:21:27.667: INFO: Created: latency-svc-69h6t
Aug  5 15:21:27.710: INFO: Got endpoints: latency-svc-vw9fc [748.013961ms]
Aug  5 15:21:27.718: INFO: Created: latency-svc-qfsp9
Aug  5 15:21:27.759: INFO: Got endpoints: latency-svc-vp2lr [750.076316ms]
Aug  5 15:21:27.767: INFO: Created: latency-svc-pdvqg
Aug  5 15:21:27.809: INFO: Got endpoints: latency-svc-9smt8 [750.036887ms]
Aug  5 15:21:27.816: INFO: Created: latency-svc-gkncd
Aug  5 15:21:27.859: INFO: Got endpoints: latency-svc-2cmjf [750.215777ms]
Aug  5 15:21:27.867: INFO: Created: latency-svc-cm5fl
Aug  5 15:21:27.910: INFO: Got endpoints: latency-svc-b6h65 [749.757114ms]
Aug  5 15:21:27.917: INFO: Created: latency-svc-4npwt
Aug  5 15:21:27.959: INFO: Got endpoints: latency-svc-njpkc [749.885448ms]
Aug  5 15:21:27.966: INFO: Created: latency-svc-f8sxw
Aug  5 15:21:28.010: INFO: Got endpoints: latency-svc-xdbmm [751.332784ms]
Aug  5 15:21:28.018: INFO: Created: latency-svc-kns9l
Aug  5 15:21:28.060: INFO: Got endpoints: latency-svc-zqt2v [750.657941ms]
Aug  5 15:21:28.109: INFO: Got endpoints: latency-svc-nsblb [748.502461ms]
Aug  5 15:21:28.159: INFO: Got endpoints: latency-svc-zr2rx [748.740143ms]
Aug  5 15:21:28.210: INFO: Got endpoints: latency-svc-6v55w [750.947332ms]
Aug  5 15:21:28.261: INFO: Got endpoints: latency-svc-9b7jw [751.301497ms]
Aug  5 15:21:28.310: INFO: Got endpoints: latency-svc-f7rs6 [750.473631ms]
Aug  5 15:21:28.359: INFO: Got endpoints: latency-svc-lzfnt [744.896194ms]
Aug  5 15:21:28.411: INFO: Got endpoints: latency-svc-69h6t [750.872368ms]
Aug  5 15:21:28.460: INFO: Got endpoints: latency-svc-qfsp9 [749.534856ms]
Aug  5 15:21:28.509: INFO: Got endpoints: latency-svc-pdvqg [749.200922ms]
Aug  5 15:21:28.559: INFO: Got endpoints: latency-svc-gkncd [749.677523ms]
Aug  5 15:21:28.609: INFO: Got endpoints: latency-svc-cm5fl [750.271054ms]
Aug  5 15:21:28.659: INFO: Got endpoints: latency-svc-4npwt [748.426051ms]
Aug  5 15:21:28.710: INFO: Got endpoints: latency-svc-f8sxw [750.158654ms]
Aug  5 15:21:28.759: INFO: Got endpoints: latency-svc-kns9l [748.751052ms]
Aug  5 15:21:28.759: INFO: Latencies: [9.142713ms 12.63701ms 17.29614ms 20.037291ms 24.068995ms 26.186795ms 35.71395ms 43.074177ms 47.210734ms 53.707724ms 55.04669ms 55.658234ms 55.898174ms 55.969285ms 56.065842ms 58.087907ms 59.469648ms 60.170609ms 60.225031ms 62.05555ms 63.017675ms 65.537789ms 66.857334ms 69.630474ms 69.677592ms 70.030238ms 70.621786ms 70.654414ms 71.105446ms 73.996818ms 75.228388ms 95.002376ms 103.929784ms 129.968049ms 208.373808ms 265.4883ms 291.762745ms 346.965572ms 397.106183ms 445.207231ms 468.568738ms 524.747099ms 574.203089ms 661.683019ms 675.35011ms 679.696754ms 729.616156ms 741.593621ms 744.147531ms 744.896194ms 746.220778ms 747.878264ms 748.01322ms 748.013961ms 748.046037ms 748.049786ms 748.068546ms 748.081726ms 748.165818ms 748.335778ms 748.356252ms 748.426051ms 748.456108ms 748.471789ms 748.502461ms 748.677338ms 748.686076ms 748.740143ms 748.751052ms 748.75768ms 748.923173ms 748.933132ms 748.959564ms 748.992429ms 749.069709ms 749.070848ms 749.072817ms 749.076343ms 749.135709ms 749.140714ms 749.146579ms 749.157069ms 749.163673ms 749.200922ms 749.214333ms 749.252872ms 749.267802ms 749.287902ms 749.292738ms 749.311692ms 749.324875ms 749.327995ms 749.350869ms 749.379019ms 749.405059ms 749.411515ms 749.416295ms 749.421883ms 749.518191ms 749.534856ms 749.55618ms 749.566219ms 749.593052ms 749.606271ms 749.615505ms 749.627193ms 749.628504ms 749.63547ms 749.638382ms 749.651366ms 749.677523ms 749.685119ms 749.685541ms 749.70505ms 749.715385ms 749.729678ms 749.730454ms 749.747679ms 749.757114ms 749.767714ms 749.774012ms 749.801906ms 749.865151ms 749.885448ms 749.889934ms 749.911731ms 749.946026ms 749.951193ms 749.968147ms 749.988104ms 749.989952ms 750.003019ms 750.014667ms 750.036887ms 750.041871ms 750.044117ms 750.047084ms 750.055546ms 750.065052ms 750.066499ms 750.068629ms 750.076316ms 750.095995ms 750.10673ms 750.108682ms 750.114761ms 750.116973ms 750.13352ms 750.158654ms 750.213674ms 750.215777ms 750.271054ms 750.307518ms 750.314128ms 750.317378ms 750.335417ms 750.337533ms 750.418183ms 750.468658ms 750.473631ms 750.506358ms 750.528385ms 750.562207ms 750.569967ms 750.59116ms 750.61586ms 750.616411ms 750.619515ms 750.657941ms 750.678178ms 750.699518ms 750.730366ms 750.747356ms 750.748851ms 750.779173ms 750.80531ms 750.820424ms 750.85885ms 750.872368ms 750.899198ms 750.941976ms 750.947332ms 751.029655ms 751.056098ms 751.222147ms 751.253012ms 751.301497ms 751.332784ms 751.340357ms 751.376462ms 751.449119ms 751.506133ms 751.532202ms 751.754436ms 751.766591ms 751.97097ms 751.993218ms 754.338261ms 754.945404ms 757.627117ms]
Aug  5 15:21:28.759: INFO: 50 %ile: 749.55618ms
Aug  5 15:21:28.759: INFO: 90 %ile: 750.941976ms
Aug  5 15:21:28.759: INFO: 99 %ile: 754.945404ms
Aug  5 15:21:28.759: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:188
Aug  5 15:21:28.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9669" for this suite.

â€¢ [SLOW TEST:9.736 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":356,"completed":322,"skipped":6123,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:21:28.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Aug  5 15:21:30.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6252" for this suite.
â€¢{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":356,"completed":323,"skipped":6139,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:21:30.806: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:21:30.842: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"7e052774-18dd-46d9-b96a-f0e8a4b501e6", Controller:(*bool)(0xc0034e44e6), BlockOwnerDeletion:(*bool)(0xc0034e44e7)}}
Aug  5 15:21:30.845: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f3933be7-b42c-4fe9-9041-f49d22a94713", Controller:(*bool)(0xc002f0160e), BlockOwnerDeletion:(*bool)(0xc002f0160f)}}
Aug  5 15:21:30.848: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"0daf61b9-2e01-4699-9790-84cfb9a1db60", Controller:(*bool)(0xc002f0186e), BlockOwnerDeletion:(*bool)(0xc002f0186f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Aug  5 15:21:35.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8039" for this suite.

â€¢ [SLOW TEST:5.085 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":356,"completed":324,"skipped":6148,"failed":0}
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:21:35.892: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug  5 15:21:35.910: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7723  58dac251-50f8-4ba9-aac3-d03f76f5673d 33938 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:21:35.910: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7723  58dac251-50f8-4ba9-aac3-d03f76f5673d 33938 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug  5 15:21:35.918: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7723  58dac251-50f8-4ba9-aac3-d03f76f5673d 33939 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:21:35.918: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7723  58dac251-50f8-4ba9-aac3-d03f76f5673d 33939 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug  5 15:21:35.921: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7723  58dac251-50f8-4ba9-aac3-d03f76f5673d 33940 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:21:35.921: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7723  58dac251-50f8-4ba9-aac3-d03f76f5673d 33940 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug  5 15:21:35.924: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7723  58dac251-50f8-4ba9-aac3-d03f76f5673d 33941 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:21:35.924: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7723  58dac251-50f8-4ba9-aac3-d03f76f5673d 33941 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug  5 15:21:35.926: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7723  ea47ef04-0445-4d38-b188-b7610894de52 33942 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:21:35.926: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7723  ea47ef04-0445-4d38-b188-b7610894de52 33942 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug  5 15:21:45.931: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7723  ea47ef04-0445-4d38-b188-b7610894de52 33985 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug  5 15:21:45.931: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7723  ea47ef04-0445-4d38-b188-b7610894de52 33985 0 2022-08-05 15:21:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-08-05 15:21:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Aug  5 15:21:55.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7723" for this suite.

â€¢ [SLOW TEST:20.048 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":356,"completed":325,"skipped":6150,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:21:55.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:21:55.951: INFO: Creating deployment "test-recreate-deployment"
Aug  5 15:21:55.953: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug  5 15:21:55.959: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug  5 15:21:57.966: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug  5 15:21:57.967: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug  5 15:21:57.972: INFO: Updating deployment test-recreate-deployment
Aug  5 15:21:57.972: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug  5 15:21:58.017: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5533  63e9d234-8464-4b22-95c0-165f16fcc1ef 34061 2 2022-08-05 15:21:55 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-08-05 15:21:57 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 15:21:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001066cd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-05 15:21:58 +0000 UTC,LastTransitionTime:2022-08-05 15:21:58 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-cd8586fc7" is progressing.,LastUpdateTime:2022-08-05 15:21:58 +0000 UTC,LastTransitionTime:2022-08-05 15:21:55 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Aug  5 15:21:58.019: INFO: New ReplicaSet "test-recreate-deployment-cd8586fc7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-cd8586fc7  deployment-5533  ac869836-6f9e-418e-8201-c7f38c706f5b 34060 1 2022-08-05 15:21:57 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 63e9d234-8464-4b22-95c0-165f16fcc1ef 0xc0044d3520 0xc0044d3521}] []  [{kube-controller-manager Update apps/v1 2022-08-05 15:21:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"63e9d234-8464-4b22-95c0-165f16fcc1ef\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 15:21:58 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: cd8586fc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0044d35c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug  5 15:21:58.019: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug  5 15:21:58.019: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-845d658455  deployment-5533  d1893759-4ddd-4cfd-a815-afaae3618125 34050 2 2022-08-05 15:21:55 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:845d658455] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 63e9d234-8464-4b22-95c0-165f16fcc1ef 0xc0044d3407 0xc0044d3408}] []  [{kube-controller-manager Update apps/v1 2022-08-05 15:21:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"63e9d234-8464-4b22-95c0-165f16fcc1ef\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-05 15:21:57 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 845d658455,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:845d658455] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0044d34b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug  5 15:21:58.021: INFO: Pod "test-recreate-deployment-cd8586fc7-r24gj" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-cd8586fc7-r24gj test-recreate-deployment-cd8586fc7- deployment-5533  141a06f5-1843-42a6-970d-852d03bfb3ab 34062 0 2022-08-05 15:21:57 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-cd8586fc7 ac869836-6f9e-418e-8201-c7f38c706f5b 0xc001067070 0xc001067071}] []  [{kube-controller-manager Update v1 2022-08-05 15:21:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac869836-6f9e-418e-8201-c7f38c706f5b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-05 15:21:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gsdr6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gsdr6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vke-automated-test-82a4b3cb9b0e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:21:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:21:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:21:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-05 15:21:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.96.4,PodIP:,StartTime:2022-08-05 15:21:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Aug  5 15:21:58.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5533" for this suite.
â€¢{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":326,"skipped":6183,"failed":0}
S
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:21:58.028: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a job [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-5397, will wait for the garbage collector to delete the pods
Aug  5 15:22:00.104: INFO: Deleting Job.batch foo took: 3.094124ms
Aug  5 15:22:00.205: INFO: Terminating Job.batch foo pods took: 100.641047ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Aug  5 15:22:32.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5397" for this suite.

â€¢ [SLOW TEST:34.092 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":356,"completed":327,"skipped":6184,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:22:32.120: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 15:22:32.136: INFO: Waiting up to 5m0s for pod "downwardapi-volume-473e3867-f999-4ab1-8fb3-4136f7e1ee2e" in namespace "downward-api-1641" to be "Succeeded or Failed"
Aug  5 15:22:32.138: INFO: Pod "downwardapi-volume-473e3867-f999-4ab1-8fb3-4136f7e1ee2e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.576209ms
Aug  5 15:22:34.144: INFO: Pod "downwardapi-volume-473e3867-f999-4ab1-8fb3-4136f7e1ee2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007519304s
Aug  5 15:22:36.148: INFO: Pod "downwardapi-volume-473e3867-f999-4ab1-8fb3-4136f7e1ee2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01206613s
STEP: Saw pod success
Aug  5 15:22:36.148: INFO: Pod "downwardapi-volume-473e3867-f999-4ab1-8fb3-4136f7e1ee2e" satisfied condition "Succeeded or Failed"
Aug  5 15:22:36.151: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-473e3867-f999-4ab1-8fb3-4136f7e1ee2e container client-container: <nil>
STEP: delete the pod
Aug  5 15:22:36.163: INFO: Waiting for pod downwardapi-volume-473e3867-f999-4ab1-8fb3-4136f7e1ee2e to disappear
Aug  5 15:22:36.165: INFO: Pod downwardapi-volume-473e3867-f999-4ab1-8fb3-4136f7e1ee2e no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Aug  5 15:22:36.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1641" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":328,"skipped":6199,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:22:36.173: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Aug  5 15:22:36.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2856" for this suite.
â€¢{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":329,"skipped":6221,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:22:36.199: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Aug  5 15:22:52.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7600" for this suite.

â€¢ [SLOW TEST:16.093 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":356,"completed":330,"skipped":6231,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:22:52.293: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:22:54.316: INFO: Deleting pod "var-expansion-1995fff1-dc45-4645-9662-b9190ef861c3" in namespace "var-expansion-2654"
Aug  5 15:22:54.321: INFO: Wait up to 5m0s for pod "var-expansion-1995fff1-dc45-4645-9662-b9190ef861c3" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Aug  5 15:22:56.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2654" for this suite.
â€¢{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":356,"completed":331,"skipped":6272,"failed":0}

------------------------------
[sig-node] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:22:56.341: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-a3ab7185-8ae1-42fa-a56a-ca9f92952881 in namespace container-probe-4065
Aug  5 15:22:58.368: INFO: Started pod liveness-a3ab7185-8ae1-42fa-a56a-ca9f92952881 in namespace container-probe-4065
STEP: checking the pod's current state and verifying that restartCount is present
Aug  5 15:22:58.370: INFO: Initial restart count of pod liveness-a3ab7185-8ae1-42fa-a56a-ca9f92952881 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Aug  5 15:26:59.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4065" for this suite.

â€¢ [SLOW TEST:242.730 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":356,"completed":332,"skipped":6272,"failed":0}
SS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:26:59.072: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod test-webserver-b510bbeb-e147-4c9d-8b51-525afc3d8006 in namespace container-probe-1170
Aug  5 15:27:01.129: INFO: Started pod test-webserver-b510bbeb-e147-4c9d-8b51-525afc3d8006 in namespace container-probe-1170
STEP: checking the pod's current state and verifying that restartCount is present
Aug  5 15:27:01.131: INFO: Initial restart count of pod test-webserver-b510bbeb-e147-4c9d-8b51-525afc3d8006 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Aug  5 15:31:01.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1170" for this suite.

â€¢ [SLOW TEST:242.761 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":333,"skipped":6274,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:31:01.834: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
Aug  5 15:31:01.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-9438 create -f -'
Aug  5 15:31:02.063: INFO: stderr: ""
Aug  5 15:31:02.063: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Aug  5 15:31:03.068: INFO: Selector matched 1 pods for map[app:agnhost]
Aug  5 15:31:03.068: INFO: Found 0 / 1
Aug  5 15:31:04.067: INFO: Selector matched 1 pods for map[app:agnhost]
Aug  5 15:31:04.067: INFO: Found 1 / 1
Aug  5 15:31:04.067: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug  5 15:31:04.069: INFO: Selector matched 1 pods for map[app:agnhost]
Aug  5 15:31:04.069: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  5 15:31:04.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-9438 patch pod agnhost-primary-wjqm9 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug  5 15:31:04.121: INFO: stderr: ""
Aug  5 15:31:04.121: INFO: stdout: "pod/agnhost-primary-wjqm9 patched\n"
STEP: checking annotations
Aug  5 15:31:04.123: INFO: Selector matched 1 pods for map[app:agnhost]
Aug  5 15:31:04.123: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 15:31:04.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9438" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":356,"completed":334,"skipped":6295,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:31:04.129: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Aug  5 15:31:04.138: INFO: Waiting up to 1m0s for all nodes to be ready
Aug  5 15:32:04.159: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:32:04.162: INFO: Starting informer...
STEP: Starting pod...
Aug  5 15:32:04.372: INFO: Pod is running on vke-automated-test-82a4b3cb9b0e. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Aug  5 15:32:04.383: INFO: Pod wasn't evicted. Proceeding
Aug  5 15:32:04.383: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Aug  5 15:33:19.420: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:33:19.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8818" for this suite.

â€¢ [SLOW TEST:135.301 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":356,"completed":335,"skipped":6307,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:33:19.431: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-7bbca951-14dc-4b3d-a81e-1b003e1400ed
STEP: Creating secret with name s-test-opt-upd-e023dbfc-2a43-44cc-a0d3-527aa1c802f6
STEP: Creating the pod
Aug  5 15:33:19.456: INFO: The status of Pod pod-projected-secrets-daa54036-75ba-4425-87d6-60f2f7817db5 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:33:21.476: INFO: The status of Pod pod-projected-secrets-daa54036-75ba-4425-87d6-60f2f7817db5 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-7bbca951-14dc-4b3d-a81e-1b003e1400ed
STEP: Updating secret s-test-opt-upd-e023dbfc-2a43-44cc-a0d3-527aa1c802f6
STEP: Creating secret with name s-test-opt-create-da9634be-e809-44bf-a339-afb0f246010d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Aug  5 15:33:25.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6445" for this suite.

â€¢ [SLOW TEST:6.148 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":336,"skipped":6322,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:33:25.581: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-downwardapi-xdhm
STEP: Creating a pod to test atomic-volume-subpath
Aug  5 15:33:25.603: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-xdhm" in namespace "subpath-509" to be "Succeeded or Failed"
Aug  5 15:33:25.605: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Pending", Reason="", readiness=false. Elapsed: 1.845789ms
Aug  5 15:33:27.612: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=true. Elapsed: 2.008650095s
Aug  5 15:33:29.617: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=true. Elapsed: 4.01353123s
Aug  5 15:33:31.623: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=true. Elapsed: 6.019779627s
Aug  5 15:33:33.629: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=true. Elapsed: 8.025349736s
Aug  5 15:33:35.635: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=true. Elapsed: 10.031643825s
Aug  5 15:33:37.640: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=true. Elapsed: 12.037156836s
Aug  5 15:33:39.644: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=true. Elapsed: 14.040643352s
Aug  5 15:33:41.650: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=true. Elapsed: 16.046782473s
Aug  5 15:33:43.656: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=true. Elapsed: 18.052457283s
Aug  5 15:33:45.662: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=true. Elapsed: 20.058386369s
Aug  5 15:33:47.667: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Running", Reason="", readiness=false. Elapsed: 22.063895619s
Aug  5 15:33:49.671: INFO: Pod "pod-subpath-test-downwardapi-xdhm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.06744284s
STEP: Saw pod success
Aug  5 15:33:49.671: INFO: Pod "pod-subpath-test-downwardapi-xdhm" satisfied condition "Succeeded or Failed"
Aug  5 15:33:49.673: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-subpath-test-downwardapi-xdhm container test-container-subpath-downwardapi-xdhm: <nil>
STEP: delete the pod
Aug  5 15:33:49.683: INFO: Waiting for pod pod-subpath-test-downwardapi-xdhm to disappear
Aug  5 15:33:49.685: INFO: Pod pod-subpath-test-downwardapi-xdhm no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-xdhm
Aug  5 15:33:49.685: INFO: Deleting pod "pod-subpath-test-downwardapi-xdhm" in namespace "subpath-509"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Aug  5 15:33:49.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-509" for this suite.

â€¢ [SLOW TEST:24.110 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","total":356,"completed":337,"skipped":6371,"failed":0}
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:33:49.691: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug  5 15:33:49.710: INFO: Waiting up to 1m0s for all nodes to be ready
Aug  5 15:34:49.728: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:34:49.730: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
Aug  5 15:34:51.773: INFO: found a healthy node: vke-automated-test-82a4b3cb9b0e
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:34:59.828: INFO: pods created so far: [1 1 1]
Aug  5 15:34:59.828: INFO: length of pods created so far: 3
Aug  5 15:35:01.838: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:188
Aug  5 15:35:08.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-8249" for this suite.
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:35:08.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8553" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

â€¢ [SLOW TEST:79.203 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":356,"completed":338,"skipped":6371,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:35:08.896: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's command
Aug  5 15:35:08.911: INFO: Waiting up to 5m0s for pod "var-expansion-a153c5ae-6e14-4114-bb0d-a0d34f7d7e1d" in namespace "var-expansion-5886" to be "Succeeded or Failed"
Aug  5 15:35:08.913: INFO: Pod "var-expansion-a153c5ae-6e14-4114-bb0d-a0d34f7d7e1d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.929962ms
Aug  5 15:35:10.917: INFO: Pod "var-expansion-a153c5ae-6e14-4114-bb0d-a0d34f7d7e1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005844798s
Aug  5 15:35:12.926: INFO: Pod "var-expansion-a153c5ae-6e14-4114-bb0d-a0d34f7d7e1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015193901s
STEP: Saw pod success
Aug  5 15:35:12.926: INFO: Pod "var-expansion-a153c5ae-6e14-4114-bb0d-a0d34f7d7e1d" satisfied condition "Succeeded or Failed"
Aug  5 15:35:12.928: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod var-expansion-a153c5ae-6e14-4114-bb0d-a0d34f7d7e1d container dapi-container: <nil>
STEP: delete the pod
Aug  5 15:35:12.939: INFO: Waiting for pod var-expansion-a153c5ae-6e14-4114-bb0d-a0d34f7d7e1d to disappear
Aug  5 15:35:12.941: INFO: Pod var-expansion-a153c5ae-6e14-4114-bb0d-a0d34f7d7e1d no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Aug  5 15:35:12.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5886" for this suite.
â€¢{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":356,"completed":339,"skipped":6383,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:35:12.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption-release is created
Aug  5 15:35:12.964: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:35:14.971: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug  5 15:35:15.985: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Aug  5 15:35:16.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9588" for this suite.
â€¢{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":356,"completed":340,"skipped":6406,"failed":0}
SSSSSS
------------------------------
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:35:17.005: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug  5 15:35:17.034: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Aug  5 15:35:17.036: INFO: starting watch
STEP: patching
STEP: updating
Aug  5 15:35:17.045: INFO: waiting for watch events with expected annotations
Aug  5 15:35:17.045: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:188
Aug  5 15:35:17.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-1840" for this suite.
â€¢{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":356,"completed":341,"skipped":6412,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:35:17.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-220855fd-19a4-4712-9190-091b6aca9b49
STEP: Creating a pod to test consume configMaps
Aug  5 15:35:17.092: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-673a4423-7f07-471d-a529-1127ce842792" in namespace "projected-4234" to be "Succeeded or Failed"
Aug  5 15:35:17.094: INFO: Pod "pod-projected-configmaps-673a4423-7f07-471d-a529-1127ce842792": Phase="Pending", Reason="", readiness=false. Elapsed: 1.859533ms
Aug  5 15:35:19.100: INFO: Pod "pod-projected-configmaps-673a4423-7f07-471d-a529-1127ce842792": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008119602s
Aug  5 15:35:21.105: INFO: Pod "pod-projected-configmaps-673a4423-7f07-471d-a529-1127ce842792": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012894248s
STEP: Saw pod success
Aug  5 15:35:21.105: INFO: Pod "pod-projected-configmaps-673a4423-7f07-471d-a529-1127ce842792" satisfied condition "Succeeded or Failed"
Aug  5 15:35:21.107: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod pod-projected-configmaps-673a4423-7f07-471d-a529-1127ce842792 container agnhost-container: <nil>
STEP: delete the pod
Aug  5 15:35:21.117: INFO: Waiting for pod pod-projected-configmaps-673a4423-7f07-471d-a529-1127ce842792 to disappear
Aug  5 15:35:21.119: INFO: Pod pod-projected-configmaps-673a4423-7f07-471d-a529-1127ce842792 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Aug  5 15:35:21.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4234" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":342,"skipped":6463,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:35:21.125: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
Aug  5 15:35:41.203: INFO: EndpointSlice for Service endpointslice-4502/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Aug  5 15:35:51.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4502" for this suite.

â€¢ [SLOW TEST:30.101 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":356,"completed":343,"skipped":6495,"failed":0}
SSSSSS
------------------------------
[sig-apps] Job 
  should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:35:51.230: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensure pods equal to paralellism count is attached to the job
STEP: patching /status
STEP: updating /status
STEP: get /status
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Aug  5 15:35:53.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1045" for this suite.
â€¢{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","total":356,"completed":344,"skipped":6501,"failed":0}
SSSS
------------------------------
[sig-node] Pods 
  should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:35:53.283: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
Aug  5 15:35:53.298: INFO: The status of Pod pod-update-52bfa889-eabd-42a1-8e4d-e388de53a385 is Pending, waiting for it to be Running (with Ready = true)
Aug  5 15:35:55.305: INFO: The status of Pod pod-update-52bfa889-eabd-42a1-8e4d-e388de53a385 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug  5 15:35:55.818: INFO: Successfully updated pod "pod-update-52bfa889-eabd-42a1-8e4d-e388de53a385"
STEP: verifying the updated pod is in kubernetes
Aug  5 15:35:55.832: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Aug  5 15:35:55.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6968" for this suite.
â€¢{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":356,"completed":345,"skipped":6505,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:35:55.836: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 15:35:55.856: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfb7d577-a51b-407f-a38e-1c11ccfa390a" in namespace "projected-991" to be "Succeeded or Failed"
Aug  5 15:35:55.858: INFO: Pod "downwardapi-volume-bfb7d577-a51b-407f-a38e-1c11ccfa390a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.534526ms
Aug  5 15:35:57.864: INFO: Pod "downwardapi-volume-bfb7d577-a51b-407f-a38e-1c11ccfa390a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007395776s
Aug  5 15:35:59.870: INFO: Pod "downwardapi-volume-bfb7d577-a51b-407f-a38e-1c11ccfa390a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013720936s
STEP: Saw pod success
Aug  5 15:35:59.870: INFO: Pod "downwardapi-volume-bfb7d577-a51b-407f-a38e-1c11ccfa390a" satisfied condition "Succeeded or Failed"
Aug  5 15:35:59.872: INFO: Trying to get logs from node vke-automated-test-b1f24d775249 pod downwardapi-volume-bfb7d577-a51b-407f-a38e-1c11ccfa390a container client-container: <nil>
STEP: delete the pod
Aug  5 15:35:59.896: INFO: Waiting for pod downwardapi-volume-bfb7d577-a51b-407f-a38e-1c11ccfa390a to disappear
Aug  5 15:35:59.897: INFO: Pod downwardapi-volume-bfb7d577-a51b-407f-a38e-1c11ccfa390a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 15:35:59.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-991" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":346,"skipped":6532,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:35:59.903: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
Aug  5 15:35:59.918: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug  5 15:36:04.928: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Aug  5 15:36:04.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9769" for this suite.

â€¢ [SLOW TEST:5.042 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":356,"completed":347,"skipped":6561,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:36:04.947: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug  5 15:36:04.965: INFO: Waiting up to 1m0s for all nodes to be ready
Aug  5 15:37:04.985: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
Aug  5 15:37:05.001: INFO: Created pod: pod0-0-sched-preemption-low-priority
Aug  5 15:37:05.005: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Aug  5 15:37:05.017: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Aug  5 15:37:05.020: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Aug  5 15:37:13.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-502" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

â€¢ [SLOW TEST:68.150 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":356,"completed":348,"skipped":6563,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:37:13.099: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
Aug  5 15:37:23.439: INFO: 72 pods remaining
Aug  5 15:37:23.440: INFO: 72 pods has nil DeletionTimestamp
Aug  5 15:37:23.440: INFO: 
STEP: Gathering metrics
W0805 15:37:28.441508      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Aug  5 15:37:28.441: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug  5 15:37:28.441: INFO: Deleting pod "simpletest-rc-to-be-deleted-2575v" in namespace "gc-9680"
Aug  5 15:37:28.471: INFO: Deleting pod "simpletest-rc-to-be-deleted-4jpqn" in namespace "gc-9680"
Aug  5 15:37:28.477: INFO: Deleting pod "simpletest-rc-to-be-deleted-4jxrz" in namespace "gc-9680"
Aug  5 15:37:28.485: INFO: Deleting pod "simpletest-rc-to-be-deleted-4krhg" in namespace "gc-9680"
Aug  5 15:37:28.492: INFO: Deleting pod "simpletest-rc-to-be-deleted-4np8j" in namespace "gc-9680"
Aug  5 15:37:28.496: INFO: Deleting pod "simpletest-rc-to-be-deleted-4z9ph" in namespace "gc-9680"
Aug  5 15:37:28.500: INFO: Deleting pod "simpletest-rc-to-be-deleted-5lzjv" in namespace "gc-9680"
Aug  5 15:37:28.508: INFO: Deleting pod "simpletest-rc-to-be-deleted-5m262" in namespace "gc-9680"
Aug  5 15:37:28.521: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tqbs" in namespace "gc-9680"
Aug  5 15:37:28.526: INFO: Deleting pod "simpletest-rc-to-be-deleted-6cvhx" in namespace "gc-9680"
Aug  5 15:37:28.531: INFO: Deleting pod "simpletest-rc-to-be-deleted-6dfw2" in namespace "gc-9680"
Aug  5 15:37:28.534: INFO: Deleting pod "simpletest-rc-to-be-deleted-6fcfv" in namespace "gc-9680"
Aug  5 15:37:28.543: INFO: Deleting pod "simpletest-rc-to-be-deleted-6j4v4" in namespace "gc-9680"
Aug  5 15:37:28.550: INFO: Deleting pod "simpletest-rc-to-be-deleted-6pvnb" in namespace "gc-9680"
Aug  5 15:37:28.559: INFO: Deleting pod "simpletest-rc-to-be-deleted-6zk2w" in namespace "gc-9680"
Aug  5 15:37:28.590: INFO: Deleting pod "simpletest-rc-to-be-deleted-7lcp8" in namespace "gc-9680"
Aug  5 15:37:28.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-7lcwc" in namespace "gc-9680"
Aug  5 15:37:28.608: INFO: Deleting pod "simpletest-rc-to-be-deleted-82xzh" in namespace "gc-9680"
Aug  5 15:37:28.612: INFO: Deleting pod "simpletest-rc-to-be-deleted-87k4f" in namespace "gc-9680"
Aug  5 15:37:28.616: INFO: Deleting pod "simpletest-rc-to-be-deleted-89h88" in namespace "gc-9680"
Aug  5 15:37:28.619: INFO: Deleting pod "simpletest-rc-to-be-deleted-8mjlq" in namespace "gc-9680"
Aug  5 15:37:28.634: INFO: Deleting pod "simpletest-rc-to-be-deleted-8pzcf" in namespace "gc-9680"
Aug  5 15:37:28.653: INFO: Deleting pod "simpletest-rc-to-be-deleted-8r5wx" in namespace "gc-9680"
Aug  5 15:37:28.659: INFO: Deleting pod "simpletest-rc-to-be-deleted-9wslv" in namespace "gc-9680"
Aug  5 15:37:28.665: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zr49" in namespace "gc-9680"
Aug  5 15:37:28.670: INFO: Deleting pod "simpletest-rc-to-be-deleted-bkbn2" in namespace "gc-9680"
Aug  5 15:37:28.679: INFO: Deleting pod "simpletest-rc-to-be-deleted-bl8tc" in namespace "gc-9680"
Aug  5 15:37:28.685: INFO: Deleting pod "simpletest-rc-to-be-deleted-cf7lf" in namespace "gc-9680"
Aug  5 15:37:28.690: INFO: Deleting pod "simpletest-rc-to-be-deleted-cr9b7" in namespace "gc-9680"
Aug  5 15:37:28.706: INFO: Deleting pod "simpletest-rc-to-be-deleted-ctzc7" in namespace "gc-9680"
Aug  5 15:37:28.725: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5kbp" in namespace "gc-9680"
Aug  5 15:37:28.741: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddqwl" in namespace "gc-9680"
Aug  5 15:37:28.748: INFO: Deleting pod "simpletest-rc-to-be-deleted-dgn47" in namespace "gc-9680"
Aug  5 15:37:28.783: INFO: Deleting pod "simpletest-rc-to-be-deleted-dznqx" in namespace "gc-9680"
Aug  5 15:37:28.788: INFO: Deleting pod "simpletest-rc-to-be-deleted-f4njz" in namespace "gc-9680"
Aug  5 15:37:28.792: INFO: Deleting pod "simpletest-rc-to-be-deleted-f9p7j" in namespace "gc-9680"
Aug  5 15:37:28.796: INFO: Deleting pod "simpletest-rc-to-be-deleted-flbxk" in namespace "gc-9680"
Aug  5 15:37:28.801: INFO: Deleting pod "simpletest-rc-to-be-deleted-g4nlw" in namespace "gc-9680"
Aug  5 15:37:28.804: INFO: Deleting pod "simpletest-rc-to-be-deleted-g8qp6" in namespace "gc-9680"
Aug  5 15:37:28.809: INFO: Deleting pod "simpletest-rc-to-be-deleted-g9hsg" in namespace "gc-9680"
Aug  5 15:37:28.846: INFO: Deleting pod "simpletest-rc-to-be-deleted-grkts" in namespace "gc-9680"
Aug  5 15:37:28.855: INFO: Deleting pod "simpletest-rc-to-be-deleted-gvp2n" in namespace "gc-9680"
Aug  5 15:37:28.860: INFO: Deleting pod "simpletest-rc-to-be-deleted-gxtmk" in namespace "gc-9680"
Aug  5 15:37:28.866: INFO: Deleting pod "simpletest-rc-to-be-deleted-h2tfk" in namespace "gc-9680"
Aug  5 15:37:28.872: INFO: Deleting pod "simpletest-rc-to-be-deleted-hbm6z" in namespace "gc-9680"
Aug  5 15:37:28.881: INFO: Deleting pod "simpletest-rc-to-be-deleted-hspw8" in namespace "gc-9680"
Aug  5 15:37:28.908: INFO: Deleting pod "simpletest-rc-to-be-deleted-hxmd8" in namespace "gc-9680"
Aug  5 15:37:28.913: INFO: Deleting pod "simpletest-rc-to-be-deleted-jbp8p" in namespace "gc-9680"
Aug  5 15:37:28.918: INFO: Deleting pod "simpletest-rc-to-be-deleted-jd2t7" in namespace "gc-9680"
Aug  5 15:37:28.922: INFO: Deleting pod "simpletest-rc-to-be-deleted-jkh6n" in namespace "gc-9680"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Aug  5 15:37:28.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9680" for this suite.

â€¢ [SLOW TEST:15.847 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":356,"completed":349,"skipped":6575,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:37:28.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:37:29.005: INFO: Endpoints addresses: [10.1.96.3] , ports: [6443]
Aug  5 15:37:29.005: INFO: EndpointSlices addresses: [10.1.96.3] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Aug  5 15:37:29.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7950" for this suite.
â€¢{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":356,"completed":350,"skipped":6589,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:37:29.011: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1574
[It] should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Aug  5 15:37:29.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5271 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Aug  5 15:37:29.246: INFO: stderr: ""
Aug  5 15:37:29.246: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Aug  5 15:37:39.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5271 get pod e2e-test-httpd-pod -o json'
Aug  5 15:37:39.361: INFO: stderr: ""
Aug  5 15:37:39.362: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"a82b41b7e9a000b267212b6c56d40a3016584cc4c99508a7d4260fe7f944e03b\",\n            \"cni.projectcalico.org/podIP\": \"10.244.18.188/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.244.18.188/32\"\n        },\n        \"creationTimestamp\": \"2022-08-05T15:37:29Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5271\",\n        \"resourceVersion\": \"39318\",\n        \"uid\": \"fd0224cd-80cd-4c04-87d6-c088d93d7698\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-8vld5\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"vke-automated-test-82a4b3cb9b0e\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-8vld5\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-05T15:37:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-05T15:37:34Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-05T15:37:34Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-05T15:37:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://ed70e3bb08487482357825d020872b3feb4696af00e3a773ef866b6f91451557\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-08-05T15:37:33Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.1.96.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.18.188\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.18.188\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-08-05T15:37:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug  5 15:37:39.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5271 replace -f -'
Aug  5 15:37:39.541: INFO: stderr: ""
Aug  5 15:37:39.542: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-2
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1578
Aug  5 15:37:39.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=kubectl-5271 delete pods e2e-test-httpd-pod'
Aug  5 15:37:41.485: INFO: stderr: ""
Aug  5 15:37:41.485: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Aug  5 15:37:41.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5271" for this suite.

â€¢ [SLOW TEST:12.486 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1571
    should update a single-container pod's image  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":356,"completed":351,"skipped":6593,"failed":0}
SS
------------------------------
[sig-apps] CronJob 
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:37:41.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Aug  5 15:42:41.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4637" for this suite.

â€¢ [SLOW TEST:300.055 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":356,"completed":352,"skipped":6595,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:42:41.570: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Aug  5 15:42:41.587: INFO: Waiting up to 5m0s for pod "downwardapi-volume-28432d7b-ff84-4c83-9b41-17c2115220db" in namespace "projected-7496" to be "Succeeded or Failed"
Aug  5 15:42:41.589: INFO: Pod "downwardapi-volume-28432d7b-ff84-4c83-9b41-17c2115220db": Phase="Pending", Reason="", readiness=false. Elapsed: 1.448023ms
Aug  5 15:42:43.592: INFO: Pod "downwardapi-volume-28432d7b-ff84-4c83-9b41-17c2115220db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005158634s
Aug  5 15:42:45.600: INFO: Pod "downwardapi-volume-28432d7b-ff84-4c83-9b41-17c2115220db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01235754s
STEP: Saw pod success
Aug  5 15:42:45.600: INFO: Pod "downwardapi-volume-28432d7b-ff84-4c83-9b41-17c2115220db" satisfied condition "Succeeded or Failed"
Aug  5 15:42:45.601: INFO: Trying to get logs from node vke-automated-test-82a4b3cb9b0e pod downwardapi-volume-28432d7b-ff84-4c83-9b41-17c2115220db container client-container: <nil>
STEP: delete the pod
Aug  5 15:42:45.623: INFO: Waiting for pod downwardapi-volume-28432d7b-ff84-4c83-9b41-17c2115220db to disappear
Aug  5 15:42:45.624: INFO: Pod downwardapi-volume-28432d7b-ff84-4c83-9b41-17c2115220db no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Aug  5 15:42:45.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7496" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":356,"completed":353,"skipped":6596,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:42:45.629: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Aug  5 15:42:57.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9669" for this suite.

â€¢ [SLOW TEST:12.027 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":356,"completed":354,"skipped":6609,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:42:57.657: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Aug  5 15:42:58.144: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug  5 15:43:01.159: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
Aug  5 15:43:01.163: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Aug  5 15:43:04.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4073" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

â€¢ [SLOW TEST:6.622 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":356,"completed":355,"skipped":6611,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Aug  5 15:43:04.280: INFO: >>> kubeConfig: /tmp/kubeconfig-3056521695
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-3619
STEP: creating service affinity-clusterip-transition in namespace services-3619
STEP: creating replication controller affinity-clusterip-transition in namespace services-3619
I0805 15:43:04.351280      18 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3619, replica count: 3
I0805 15:43:07.403251      18 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  5 15:43:07.410: INFO: Creating new exec pod
Aug  5 15:43:10.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-3619 exec execpod-affinityng8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Aug  5 15:43:10.563: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Aug  5 15:43:10.563: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:43:10.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-3619 exec execpod-affinityng8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.90.131 80'
Aug  5 15:43:10.706: INFO: stderr: "+ nc -v -t -w 2 10.98.90.131 80\n+ echo hostName\nConnection to 10.98.90.131 80 port [tcp/http] succeeded!\n"
Aug  5 15:43:10.706: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug  5 15:43:10.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-3619 exec execpod-affinityng8jd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.98.90.131:80/ ; done'
Aug  5 15:43:10.926: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n"
Aug  5 15:43:10.926: INFO: stdout: "\naffinity-clusterip-transition-fh6fp\naffinity-clusterip-transition-fh6fp\naffinity-clusterip-transition-fh6fp\naffinity-clusterip-transition-fh6fp\naffinity-clusterip-transition-fh6fp\naffinity-clusterip-transition-qmzvp\naffinity-clusterip-transition-qmzvp\naffinity-clusterip-transition-qmzvp\naffinity-clusterip-transition-qmzvp\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-fh6fp\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-fh6fp\naffinity-clusterip-transition-qmzvp\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-qmzvp"
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-fh6fp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-fh6fp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-fh6fp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-fh6fp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-fh6fp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-qmzvp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-qmzvp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-qmzvp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-qmzvp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-fh6fp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-fh6fp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-qmzvp
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:10.926: INFO: Received response from host: affinity-clusterip-transition-qmzvp
Aug  5 15:43:10.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056521695 --namespace=services-3619 exec execpod-affinityng8jd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.98.90.131:80/ ; done'
Aug  5 15:43:11.146: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.98.90.131:80/\n"
Aug  5 15:43:11.146: INFO: stdout: "\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw\naffinity-clusterip-transition-9ljlw"
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Received response from host: affinity-clusterip-transition-9ljlw
Aug  5 15:43:11.146: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3619, will wait for the garbage collector to delete the pods
Aug  5 15:43:11.236: INFO: Deleting ReplicationController affinity-clusterip-transition took: 3.613634ms
Aug  5 15:43:11.338: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 102.056019ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Aug  5 15:43:13.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3619" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

â€¢ [SLOW TEST:9.075 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":356,"skipped":6614,"failed":0}
SAug  5 15:43:13.355: INFO: Running AfterSuite actions on all nodes
Aug  5 15:43:13.355: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func19.2
Aug  5 15:43:13.355: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Aug  5 15:43:13.355: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
Aug  5 15:43:13.355: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Aug  5 15:43:13.355: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Aug  5 15:43:13.355: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Aug  5 15:43:13.355: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
Aug  5 15:43:13.355: INFO: Running AfterSuite actions on node 1
Aug  5 15:43:13.355: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":356,"completed":356,"skipped":6615,"failed":0}

Ran 356 of 6971 Specs in 5434.480 seconds
SUCCESS! -- 356 Passed | 0 Failed | 0 Pending | 6615 Skipped
PASS

Ginkgo ran 1 suite in 1h30m36.023635331s
Test Suite Passed
